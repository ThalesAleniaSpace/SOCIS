{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "lXfPT7BuejLb",
    "outputId": "c6808d39-90c9-4ac3-a567-15d716059419"
   },
   "outputs": [],
   "source": [
    "# # Run this cell to mount your Google Drive.\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "819EGBI8fLUl",
    "outputId": "93d6fddc-7353-4a53-d34e-1427242fa67d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "# from keras.backend import manual_variable_initialization \n",
    "# # manual_variable_initialization(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N1bkqWDgXIbi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 246
    },
    "colab_type": "code",
    "id": "RgWz2tXdfNax",
    "outputId": "50345be1-3694-4638-a873-88697a7d0bc7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s.no</th>\n",
       "      <th>id</th>\n",
       "      <th>dir</th>\n",
       "      <th>path</th>\n",
       "      <th>date</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>x3</th>\n",
       "      <th>...</th>\n",
       "      <th>x9996</th>\n",
       "      <th>y9996</th>\n",
       "      <th>x9997</th>\n",
       "      <th>y9997</th>\n",
       "      <th>x9998</th>\n",
       "      <th>y9998</th>\n",
       "      <th>x9999</th>\n",
       "      <th>y9999</th>\n",
       "      <th>x10000</th>\n",
       "      <th>y10000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ON_1_20181031_173504_104</td>\n",
       "      <td>104</td>\n",
       "      <td>C:\\Hilink\\BB4A\\RESULT\\BBM2\\BBM2\\NOMINAL\\MANUAL...</td>\n",
       "      <td>31/10/2018</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>OFF_4_20181031_173921_104</td>\n",
       "      <td>104</td>\n",
       "      <td>C:\\Hilink\\BB4A\\RESULT\\BBM2\\BBM2\\NOMINAL\\MANUAL...</td>\n",
       "      <td>31/10/2018</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>OFF_2_20181031_173628_104</td>\n",
       "      <td>104</td>\n",
       "      <td>C:\\Hilink\\BB4A\\RESULT\\BBM2\\BBM2\\NOMINAL\\MANUAL...</td>\n",
       "      <td>31/10/2018</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>ON_3_20181031_173800_104</td>\n",
       "      <td>104</td>\n",
       "      <td>C:\\Hilink\\BB4A\\RESULT\\BBM2\\BBM2\\NOMINAL\\MANUAL...</td>\n",
       "      <td>31/10/2018</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>OFF_4_20181102_085018_103</td>\n",
       "      <td>103</td>\n",
       "      <td>C:\\Hilink\\BB4A\\RESULT\\BBM2\\BBM2\\NOMINAL\\MANUAL...</td>\n",
       "      <td>02/11/2018</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>25.2</td>\n",
       "      <td>0.05</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 20005 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  s.no                         id  dir  \\\n",
       "0    1   ON_1_20181031_173504_104  104   \n",
       "1    2  OFF_4_20181031_173921_104  104   \n",
       "2    3  OFF_2_20181031_173628_104  104   \n",
       "3    4   ON_3_20181031_173800_104  104   \n",
       "4    5  OFF_4_20181102_085018_103  103   \n",
       "\n",
       "                                                path        date   x1    y1  \\\n",
       "0  C:\\Hilink\\BB4A\\RESULT\\BBM2\\BBM2\\NOMINAL\\MANUAL...  31/10/2018  0.2  0.03   \n",
       "1  C:\\Hilink\\BB4A\\RESULT\\BBM2\\BBM2\\NOMINAL\\MANUAL...  31/10/2018  0.4  0.12   \n",
       "2  C:\\Hilink\\BB4A\\RESULT\\BBM2\\BBM2\\NOMINAL\\MANUAL...  31/10/2018  0.2  0.13   \n",
       "3  C:\\Hilink\\BB4A\\RESULT\\BBM2\\BBM2\\NOMINAL\\MANUAL...  31/10/2018  0.2  0.03   \n",
       "4  C:\\Hilink\\BB4A\\RESULT\\BBM2\\BBM2\\NOMINAL\\MANUAL...  02/11/2018  0.2  0.15   \n",
       "\n",
       "    x2    y2   x3  ... x9996 y9996 x9997 y9997 x9998 y9998 x9999 y9999 x10000  \\\n",
       "0  0.2  0.03  0.2  ...   0.2  0.14   0.2  0.14   0.2  0.14   0.2  0.14    0.2   \n",
       "1  0.2  0.12  0.2  ...  25.0  0.03  25.0  0.03  25.0  0.03  25.0  0.03   25.0   \n",
       "2  0.0  0.12  0.0  ...  25.0  0.03  25.0  0.03  25.0  0.02  25.0  0.02   25.0   \n",
       "3  0.4  0.02  0.4  ...   0.2  0.14   0.0  0.14   0.2  0.14   0.2  0.14    0.2   \n",
       "4  0.2  0.16  0.2  ...  25.0  0.05  25.0  0.06  25.0  0.05  25.2  0.05   25.0   \n",
       "\n",
       "  y10000  \n",
       "0   0.14  \n",
       "1   0.03  \n",
       "2   0.03  \n",
       "3   0.14  \n",
       "4   0.05  \n",
       "\n",
       "[5 rows x 20005 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_p = pd.read_csv(\"points.csv\",dtype=object,error_bad_lines=False) \n",
    "data_p.head()\n",
    "data_p[\"id\"] = data_p[\"id\"].map(str) +\"_\"+ data_p[\"dir\"]\n",
    "data_p.head()\n",
    "# data_p.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 234
    },
    "colab_type": "code",
    "id": "zRQG6QqkfPaM",
    "outputId": "7e2cdf06-3933-4496-c78e-813e4afed97b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s.no</th>\n",
       "      <th>id</th>\n",
       "      <th>dir</th>\n",
       "      <th>_file_</th>\n",
       "      <th>power_state_value</th>\n",
       "      <th>current_rise/fall_time_value (mS)</th>\n",
       "      <th>current_stabilised_value (mA)</th>\n",
       "      <th>current_max/min_value (mA)</th>\n",
       "      <th>power_state_spec</th>\n",
       "      <th>current_rise/fall_time_spec (mS)</th>\n",
       "      <th>current_stabilised_spec (mA)</th>\n",
       "      <th>current_max/min_spec (mA)</th>\n",
       "      <th>power_state_N/NC</th>\n",
       "      <th>current_rise/fall_time_C/NC</th>\n",
       "      <th>current_stabilised_C/NC</th>\n",
       "      <th>current_max/min_C/NC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ON_1_20181031_173504_104</td>\n",
       "      <td>104</td>\n",
       "      <td>HEGSE_72.HTM</td>\n",
       "      <td>1</td>\n",
       "      <td>89.990000000000</td>\n",
       "      <td>150.000000000000</td>\n",
       "      <td>405.992200000000</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>510.204</td>\n",
       "      <td>800</td>\n",
       "      <td>C</td>\n",
       "      <td>NC</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>OFF_2_20181031_173628_104</td>\n",
       "      <td>104</td>\n",
       "      <td>HEGSE_72.HTM</td>\n",
       "      <td>0</td>\n",
       "      <td>7.992000000000</td>\n",
       "      <td>30.000000000000</td>\n",
       "      <td>-56.000000000000</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>510.204</td>\n",
       "      <td>-100</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>ON_3_20181031_173800_104</td>\n",
       "      <td>104</td>\n",
       "      <td>HEGSE_72.HTM</td>\n",
       "      <td>1</td>\n",
       "      <td>89.950000000000</td>\n",
       "      <td>140.000000000000</td>\n",
       "      <td>405.992200000000</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>495.049</td>\n",
       "      <td>800</td>\n",
       "      <td>C</td>\n",
       "      <td>NC</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>OFF_4_20181031_173921_104</td>\n",
       "      <td>104</td>\n",
       "      <td>HEGSE_72.HTM</td>\n",
       "      <td>0</td>\n",
       "      <td>7.997000000000</td>\n",
       "      <td>30.000000000000</td>\n",
       "      <td>-58.000000000000</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>495.049</td>\n",
       "      <td>-100</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>ON_1_20181102_084600_103</td>\n",
       "      <td>103</td>\n",
       "      <td>HEGSE_72.HTM</td>\n",
       "      <td>1</td>\n",
       "      <td>56.650000000000</td>\n",
       "      <td>169.800000000000</td>\n",
       "      <td>405.992200000000</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>510.204</td>\n",
       "      <td>800</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  s.no                         id  dir         _file_  power_state_value  \\\n",
       "0    1   ON_1_20181031_173504_104  104   HEGSE_72.HTM                  1   \n",
       "1    2  OFF_2_20181031_173628_104  104   HEGSE_72.HTM                  0   \n",
       "2    3   ON_3_20181031_173800_104  104   HEGSE_72.HTM                  1   \n",
       "3    4  OFF_4_20181031_173921_104  104   HEGSE_72.HTM                  0   \n",
       "4    5   ON_1_20181102_084600_103  103   HEGSE_72.HTM                  1   \n",
       "\n",
       "  current_rise/fall_time_value (mS) current_stabilised_value (mA)  \\\n",
       "0                   89.990000000000              150.000000000000   \n",
       "1                    7.992000000000               30.000000000000   \n",
       "2                   89.950000000000              140.000000000000   \n",
       "3                    7.997000000000               30.000000000000   \n",
       "4                   56.650000000000              169.800000000000   \n",
       "\n",
       "  current_max/min_value (mA)  power_state_spec  \\\n",
       "0           405.992200000000                 1   \n",
       "1           -56.000000000000                 0   \n",
       "2           405.992200000000                 1   \n",
       "3           -58.000000000000                 0   \n",
       "4           405.992200000000                 1   \n",
       "\n",
       "  current_rise/fall_time_spec (mS) current_stabilised_spec (mA)  \\\n",
       "0                               60                      510.204   \n",
       "1                               10                      510.204   \n",
       "2                               60                      495.049   \n",
       "3                               10                      495.049   \n",
       "4                               60                      510.204   \n",
       "\n",
       "  current_max/min_spec (mA) power_state_N/NC current_rise/fall_time_C/NC  \\\n",
       "0                       800                C                          NC   \n",
       "1                      -100                C                           C   \n",
       "2                       800                C                          NC   \n",
       "3                      -100                C                           C   \n",
       "4                       800                C                           C   \n",
       "\n",
       "  current_stabilised_C/NC current_max/min_C/NC  \n",
       "0                       C                    C  \n",
       "1                       C                    C  \n",
       "2                       C                    C  \n",
       "3                       C                    C  \n",
       "4                       C                    C  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data_v = pd.read_csv(\"values.csv\",dtype=object,error_bad_lines=False )\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "data_v['power_state_spec'] = le.fit_transform(data_v['power_state_spec'].astype('str'))\n",
    "\n",
    "data_v['power_state_value'] = le.fit_transform(data_v['power_state_value'].astype('str'))\n",
    "data_v[\"id\"] = data_v[\"id\"].map(str) +\"_\"+data_v[\"dir\"]\n",
    "data_v.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SS5hHAvgfRzw"
   },
   "outputs": [],
   "source": [
    "arr_v = data_v.values\n",
    "arr_p = data_p.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TSE1FojVfUlN"
   },
   "outputs": [],
   "source": [
    "arr_v = arr_v[0:]\n",
    "# print(arr_v)\n",
    "arr_p = arr_p[0:]\n",
    "# print(arr_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "pZMozxZNfdAU",
    "outputId": "1371ad9a-922e-48c1-833a-a5cfa5c01b81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426 ON\n",
      "398 OFF\n"
     ]
    }
   ],
   "source": [
    "ON_list =[]\n",
    "OFF_list = []\n",
    "for i in range(len(arr_p)):\n",
    "    s = arr_p[i][1]\n",
    "    s = str(s)\n",
    "    \n",
    "#     print(type(st))\n",
    "    if s.find(\"N\") == -1:\n",
    "        OFF_list.append(arr_p[i])\n",
    "    \n",
    "    else:\n",
    "        ON_list.append(arr_p[i])\n",
    "# calculating for ON\n",
    "print(len(ON_list),\"ON\")\n",
    "print(len(OFF_list),\"OFF\")\n",
    "arr_on_p = np.array(OFF_list)\n",
    "# print(arr_on_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hbaq7jn6fde0"
   },
   "outputs": [],
   "source": [
    "arr_on_p = np.delete(arr_on_p, 3,  axis=1)\n",
    "arr_on_p_n = arr_on_p[:, 1::2]\n",
    "arr_on_p_f = np.delete(arr_on_p_n, 1,  axis=1)\n",
    "# print(len(arr_on_p_f))\n",
    "# print(len(arr_on_p_f[0]))\n",
    "# print(arr_on_p_f[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 246
    },
    "colab_type": "code",
    "id": "nntpfcxlgZsO",
    "outputId": "d43b0254-360c-4905-dc50-0c58612e00d8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y0</th>\n",
       "      <th>y1</th>\n",
       "      <th>y2</th>\n",
       "      <th>y3</th>\n",
       "      <th>y4</th>\n",
       "      <th>y5</th>\n",
       "      <th>y6</th>\n",
       "      <th>y7</th>\n",
       "      <th>y8</th>\n",
       "      <th>y9</th>\n",
       "      <th>...</th>\n",
       "      <th>y9991</th>\n",
       "      <th>y9992</th>\n",
       "      <th>y9993</th>\n",
       "      <th>y9994</th>\n",
       "      <th>y9995</th>\n",
       "      <th>y9996</th>\n",
       "      <th>y9997</th>\n",
       "      <th>y9998</th>\n",
       "      <th>y9999</th>\n",
       "      <th>y10000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OFF_4_20181031_173921_104</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OFF_2_20181031_173628_104</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OFF_4_20181102_085018_103</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.14</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OFF_2_20181102_084723_103</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OFF_4_20181102_090312_102</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 10001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          y0    y1    y2    y3    y4    y5    y6    y7    y8  \\\n",
       "0  OFF_4_20181031_173921_104  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12   \n",
       "1  OFF_2_20181031_173628_104  0.13  0.12  0.12  0.12  0.12  0.12  0.12  0.12   \n",
       "2  OFF_4_20181102_085018_103  0.15  0.16  0.15  0.15  0.15  0.15  0.15  0.15   \n",
       "3  OFF_2_20181102_084723_103  0.15  0.15  0.15  0.15  0.15  0.15  0.15  0.15   \n",
       "4  OFF_4_20181102_090312_102  0.15  0.14  0.14  0.15  0.15  0.15  0.14  0.14   \n",
       "\n",
       "     y9  ... y9991 y9992 y9993 y9994 y9995 y9996 y9997 y9998 y9999 y10000  \n",
       "0  0.12  ...  0.03  0.03  0.03  0.03  0.03  0.03  0.03  0.03  0.03   0.03  \n",
       "1  0.12  ...  0.03  0.03  0.03  0.03  0.03  0.03  0.03  0.02  0.02   0.03  \n",
       "2  0.14  ...  0.06  0.06  0.06  0.06  0.06  0.05  0.06  0.05  0.05   0.05  \n",
       "3  0.15  ...  0.06  0.06  0.06  0.06  0.06  0.06  0.06  0.05  0.05   0.05  \n",
       "4  0.14  ...  0.06  0.06  0.06  0.06  0.06  0.06  0.06  0.06  0.06   0.06  \n",
       "\n",
       "[5 rows x 10001 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = arr_on_p_f\n",
    "\n",
    "df=pd.DataFrame(data=data[0:,0:],index=[i for i in range(data.shape[0])],\n",
    "                columns=['y'+str(i) for i in range(data.shape[1])])\n",
    "df.head()\n",
    "# df.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "colab_type": "code",
    "id": "0SaXXr_ggcFp",
    "outputId": "ca27a21d-91be-4121-8efe-6dd58c9d8431"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(398, 10001)\n",
      "(397, 10001)\n",
      "(398, 10001)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y0</th>\n",
       "      <th>y1</th>\n",
       "      <th>y2</th>\n",
       "      <th>y3</th>\n",
       "      <th>y4</th>\n",
       "      <th>y5</th>\n",
       "      <th>y6</th>\n",
       "      <th>y7</th>\n",
       "      <th>y8</th>\n",
       "      <th>y9</th>\n",
       "      <th>...</th>\n",
       "      <th>y9991</th>\n",
       "      <th>y9992</th>\n",
       "      <th>y9993</th>\n",
       "      <th>y9994</th>\n",
       "      <th>y9995</th>\n",
       "      <th>y9996</th>\n",
       "      <th>y9997</th>\n",
       "      <th>y9998</th>\n",
       "      <th>y9999</th>\n",
       "      <th>y10000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OFF_4_20181031_173921_104</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OFF_2_20181031_173628_104</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OFF_4_20181102_085018_103</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.14</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OFF_2_20181102_084723_103</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OFF_4_20181102_090312_102</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 10001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          y0    y1    y2    y3    y4    y5    y6    y7    y8  \\\n",
       "0  OFF_4_20181031_173921_104  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12   \n",
       "1  OFF_2_20181031_173628_104  0.13  0.12  0.12  0.12  0.12  0.12  0.12  0.12   \n",
       "2  OFF_4_20181102_085018_103  0.15  0.16  0.15  0.15  0.15  0.15  0.15  0.15   \n",
       "3  OFF_2_20181102_084723_103  0.15  0.15  0.15  0.15  0.15  0.15  0.15  0.15   \n",
       "4  OFF_4_20181102_090312_102  0.15  0.14  0.14  0.15  0.15  0.15  0.14  0.14   \n",
       "\n",
       "     y9  ... y9991 y9992 y9993 y9994 y9995 y9996 y9997 y9998 y9999 y10000  \n",
       "0  0.12  ...  0.03  0.03  0.03  0.03  0.03  0.03  0.03  0.03  0.03   0.03  \n",
       "1  0.12  ...  0.03  0.03  0.03  0.03  0.03  0.03  0.03  0.02  0.02   0.03  \n",
       "2  0.14  ...  0.06  0.06  0.06  0.06  0.06  0.05  0.06  0.05  0.05   0.05  \n",
       "3  0.15  ...  0.06  0.06  0.06  0.06  0.06  0.06  0.06  0.05  0.05   0.05  \n",
       "4  0.14  ...  0.06  0.06  0.06  0.06  0.06  0.06  0.06  0.06  0.06   0.06  \n",
       "\n",
       "[5 rows x 10001 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "# for j in range(10000):\n",
    "#   var = \"y\"+str(j+1)\n",
    "#   df[var].fillna(df[var].mean(), inplace=True)\n",
    "df_no_miss = df.dropna()\n",
    "print(df_no_miss.shape)\n",
    "print(df.shape)\n",
    "df_no_miss.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "VMYfPRjHghm3",
    "outputId": "dbf33109-20a1-436e-c2b4-9fb1621e1d18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "397\n"
     ]
    }
   ],
   "source": [
    "arr_p_no = df_no_miss.values\n",
    "print(len(arr_p_no))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 246
    },
    "colab_type": "code",
    "id": "LGF8F0segjoF",
    "outputId": "26312138-8059-4a36-e75b-69b8b4b3f616"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>y1</th>\n",
       "      <th>y2</th>\n",
       "      <th>y3</th>\n",
       "      <th>y4</th>\n",
       "      <th>y5</th>\n",
       "      <th>y6</th>\n",
       "      <th>y7</th>\n",
       "      <th>y8</th>\n",
       "      <th>y9</th>\n",
       "      <th>...</th>\n",
       "      <th>y9991</th>\n",
       "      <th>y9992</th>\n",
       "      <th>y9993</th>\n",
       "      <th>y9994</th>\n",
       "      <th>y9995</th>\n",
       "      <th>y9996</th>\n",
       "      <th>y9997</th>\n",
       "      <th>y9998</th>\n",
       "      <th>y9999</th>\n",
       "      <th>y10000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OFF_4_20181031_173921_104</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OFF_2_20181031_173628_104</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OFF_4_20181102_085018_103</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.14</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OFF_2_20181102_084723_103</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OFF_4_20181102_090312_102</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 10001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          id    y1    y2    y3    y4    y5    y6    y7    y8  \\\n",
       "0  OFF_4_20181031_173921_104  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12   \n",
       "1  OFF_2_20181031_173628_104  0.13  0.12  0.12  0.12  0.12  0.12  0.12  0.12   \n",
       "2  OFF_4_20181102_085018_103  0.15  0.16  0.15  0.15  0.15  0.15  0.15  0.15   \n",
       "3  OFF_2_20181102_084723_103  0.15  0.15  0.15  0.15  0.15  0.15  0.15  0.15   \n",
       "4  OFF_4_20181102_090312_102  0.15  0.14  0.14  0.15  0.15  0.15  0.14  0.14   \n",
       "\n",
       "     y9  ... y9991 y9992 y9993 y9994 y9995 y9996 y9997 y9998 y9999 y10000  \n",
       "0  0.12  ...  0.03  0.03  0.03  0.03  0.03  0.03  0.03  0.03  0.03   0.03  \n",
       "1  0.12  ...  0.03  0.03  0.03  0.03  0.03  0.03  0.03  0.02  0.02   0.03  \n",
       "2  0.14  ...  0.06  0.06  0.06  0.06  0.06  0.05  0.06  0.05  0.05   0.05  \n",
       "3  0.15  ...  0.06  0.06  0.06  0.06  0.06  0.06  0.06  0.05  0.05   0.05  \n",
       "4  0.14  ...  0.06  0.06  0.06  0.06  0.06  0.06  0.06  0.06  0.06   0.06  \n",
       "\n",
       "[5 rows x 10001 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1= df_no_miss.rename(index=str, columns={\"y0\": \"id\"})\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "OgI9lWPHgl_2",
    "outputId": "a21663e5-9263-4230-fde2-1721c3984a23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(397, 10001)\n",
      "(397, 10016)\n"
     ]
    }
   ],
   "source": [
    "print(df1.shape)\n",
    "df2 = data_v\n",
    "# print(df2.shape)\n",
    "combine = (pd.merge(df1, df2, how='left', on='id'))\n",
    "# print(df1.unique)\n",
    "print(combine.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 263
    },
    "colab_type": "code",
    "id": "_Frd3KdYgoVN",
    "outputId": "11f0509c-a31b-436c-cd41-7b3ddb0d17be"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>y1</th>\n",
       "      <th>y2</th>\n",
       "      <th>y3</th>\n",
       "      <th>y4</th>\n",
       "      <th>y5</th>\n",
       "      <th>y6</th>\n",
       "      <th>y7</th>\n",
       "      <th>y8</th>\n",
       "      <th>y9</th>\n",
       "      <th>...</th>\n",
       "      <th>current_stabilised_value (mA)</th>\n",
       "      <th>current_max/min_value (mA)</th>\n",
       "      <th>power_state_spec</th>\n",
       "      <th>current_rise/fall_time_spec (mS)</th>\n",
       "      <th>current_stabilised_spec (mA)</th>\n",
       "      <th>current_max/min_spec (mA)</th>\n",
       "      <th>power_state_N/NC</th>\n",
       "      <th>current_rise/fall_time_C/NC</th>\n",
       "      <th>current_stabilised_C/NC</th>\n",
       "      <th>current_max/min_C/NC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OFF_4_20181031_173921_104</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>...</td>\n",
       "      <td>30.000000000000</td>\n",
       "      <td>-58.000000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>495.049</td>\n",
       "      <td>-100</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OFF_2_20181031_173628_104</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>...</td>\n",
       "      <td>30.000000000000</td>\n",
       "      <td>-56.000000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>510.204</td>\n",
       "      <td>-100</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OFF_4_20181102_085018_103</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.14</td>\n",
       "      <td>...</td>\n",
       "      <td>58.000000000000</td>\n",
       "      <td>-28.000000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>495.049</td>\n",
       "      <td>-100</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OFF_2_20181102_084723_103</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>...</td>\n",
       "      <td>56.400000000000</td>\n",
       "      <td>-32.000000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>510.204</td>\n",
       "      <td>-100</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OFF_4_20181102_090312_102</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>...</td>\n",
       "      <td>57.900000000000</td>\n",
       "      <td>-23.804700000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>495.049</td>\n",
       "      <td>-100</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 10016 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          id    y1    y2    y3    y4    y5    y6    y7    y8  \\\n",
       "0  OFF_4_20181031_173921_104  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12   \n",
       "1  OFF_2_20181031_173628_104  0.13  0.12  0.12  0.12  0.12  0.12  0.12  0.12   \n",
       "2  OFF_4_20181102_085018_103  0.15  0.16  0.15  0.15  0.15  0.15  0.15  0.15   \n",
       "3  OFF_2_20181102_084723_103  0.15  0.15  0.15  0.15  0.15  0.15  0.15  0.15   \n",
       "4  OFF_4_20181102_090312_102  0.15  0.14  0.14  0.15  0.15  0.15  0.14  0.14   \n",
       "\n",
       "     y9  ... current_stabilised_value (mA) current_max/min_value (mA)  \\\n",
       "0  0.12  ...               30.000000000000           -58.000000000000   \n",
       "1  0.12  ...               30.000000000000           -56.000000000000   \n",
       "2  0.14  ...               58.000000000000           -28.000000000000   \n",
       "3  0.15  ...               56.400000000000           -32.000000000000   \n",
       "4  0.14  ...               57.900000000000           -23.804700000000   \n",
       "\n",
       "  power_state_spec current_rise/fall_time_spec (mS)  \\\n",
       "0              0.0                               10   \n",
       "1              0.0                               10   \n",
       "2              0.0                               10   \n",
       "3              0.0                               10   \n",
       "4              0.0                               10   \n",
       "\n",
       "  current_stabilised_spec (mA) current_max/min_spec (mA) power_state_N/NC  \\\n",
       "0                      495.049                      -100                C   \n",
       "1                      510.204                      -100                C   \n",
       "2                      495.049                      -100                C   \n",
       "3                      510.204                      -100                C   \n",
       "4                      495.049                      -100                C   \n",
       "\n",
       "  current_rise/fall_time_C/NC current_stabilised_C/NC current_max/min_C/NC  \n",
       "0                           C                       C                    C  \n",
       "1                           C                       C                    C  \n",
       "2                           C                       C                    C  \n",
       "3                           C                       C                    C  \n",
       "4                           C                       C                    C  \n",
       "\n",
       "[5 rows x 10016 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 263
    },
    "colab_type": "code",
    "id": "djNeEIiPgq7w",
    "outputId": "d24ce3be-3c68-4aa6-ec6d-1bcd3bd0447d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>y1</th>\n",
       "      <th>y2</th>\n",
       "      <th>y3</th>\n",
       "      <th>y4</th>\n",
       "      <th>y5</th>\n",
       "      <th>y6</th>\n",
       "      <th>y7</th>\n",
       "      <th>y8</th>\n",
       "      <th>y9</th>\n",
       "      <th>...</th>\n",
       "      <th>current_stabilised_value (mA)</th>\n",
       "      <th>current_max/min_value (mA)</th>\n",
       "      <th>power_state_spec</th>\n",
       "      <th>current_rise/fall_time_spec (mS)</th>\n",
       "      <th>current_stabilised_spec (mA)</th>\n",
       "      <th>current_max/min_spec (mA)</th>\n",
       "      <th>power_state_N/NC</th>\n",
       "      <th>current_rise/fall_time_C/NC</th>\n",
       "      <th>current_stabilised_C/NC</th>\n",
       "      <th>current_max/min_C/NC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OFF_4_20181031_173921_104</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>...</td>\n",
       "      <td>30.000000000000</td>\n",
       "      <td>-58.000000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>495.049</td>\n",
       "      <td>-100</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OFF_2_20181031_173628_104</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>...</td>\n",
       "      <td>30.000000000000</td>\n",
       "      <td>-56.000000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>510.204</td>\n",
       "      <td>-100</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OFF_4_20181102_085018_103</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.14</td>\n",
       "      <td>...</td>\n",
       "      <td>58.000000000000</td>\n",
       "      <td>-28.000000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>495.049</td>\n",
       "      <td>-100</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OFF_2_20181102_084723_103</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>...</td>\n",
       "      <td>56.400000000000</td>\n",
       "      <td>-32.000000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>510.204</td>\n",
       "      <td>-100</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OFF_4_20181102_090312_102</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>...</td>\n",
       "      <td>57.900000000000</td>\n",
       "      <td>-23.804700000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>495.049</td>\n",
       "      <td>-100</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 10013 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          id    y1    y2    y3    y4    y5    y6    y7    y8  \\\n",
       "0  OFF_4_20181031_173921_104  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12   \n",
       "1  OFF_2_20181031_173628_104  0.13  0.12  0.12  0.12  0.12  0.12  0.12  0.12   \n",
       "2  OFF_4_20181102_085018_103  0.15  0.16  0.15  0.15  0.15  0.15  0.15  0.15   \n",
       "3  OFF_2_20181102_084723_103  0.15  0.15  0.15  0.15  0.15  0.15  0.15  0.15   \n",
       "4  OFF_4_20181102_090312_102  0.15  0.14  0.14  0.15  0.15  0.15  0.14  0.14   \n",
       "\n",
       "     y9  ... current_stabilised_value (mA) current_max/min_value (mA)  \\\n",
       "0  0.12  ...               30.000000000000           -58.000000000000   \n",
       "1  0.12  ...               30.000000000000           -56.000000000000   \n",
       "2  0.14  ...               58.000000000000           -28.000000000000   \n",
       "3  0.15  ...               56.400000000000           -32.000000000000   \n",
       "4  0.14  ...               57.900000000000           -23.804700000000   \n",
       "\n",
       "  power_state_spec current_rise/fall_time_spec (mS)  \\\n",
       "0              0.0                               10   \n",
       "1              0.0                               10   \n",
       "2              0.0                               10   \n",
       "3              0.0                               10   \n",
       "4              0.0                               10   \n",
       "\n",
       "  current_stabilised_spec (mA) current_max/min_spec (mA) power_state_N/NC  \\\n",
       "0                      495.049                      -100                C   \n",
       "1                      510.204                      -100                C   \n",
       "2                      495.049                      -100                C   \n",
       "3                      510.204                      -100                C   \n",
       "4                      495.049                      -100                C   \n",
       "\n",
       "  current_rise/fall_time_C/NC current_stabilised_C/NC current_max/min_C/NC  \n",
       "0                           C                       C                    C  \n",
       "1                           C                       C                    C  \n",
       "2                           C                       C                    C  \n",
       "3                           C                       C                    C  \n",
       "4                           C                       C                    C  \n",
       "\n",
       "[5 rows x 10013 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine.iloc[:,0:10010].head()\n",
    "k = combine.drop(['s.no','dir','_file_'], axis = 1) \n",
    "\n",
    "k.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 263
    },
    "colab_type": "code",
    "id": "2vbEb4-ogtJg",
    "outputId": "65d9c504-b261-4ecd-9102-3883bcdc8782"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y1</th>\n",
       "      <th>y2</th>\n",
       "      <th>y3</th>\n",
       "      <th>y4</th>\n",
       "      <th>y5</th>\n",
       "      <th>y6</th>\n",
       "      <th>y7</th>\n",
       "      <th>y8</th>\n",
       "      <th>y9</th>\n",
       "      <th>y10</th>\n",
       "      <th>...</th>\n",
       "      <th>y9999</th>\n",
       "      <th>y10000</th>\n",
       "      <th>power_state_value</th>\n",
       "      <th>current_rise/fall_time_value (mS)</th>\n",
       "      <th>current_stabilised_value (mA)</th>\n",
       "      <th>current_max/min_value (mA)</th>\n",
       "      <th>power_state_spec</th>\n",
       "      <th>current_rise/fall_time_spec (mS)</th>\n",
       "      <th>current_stabilised_spec (mA)</th>\n",
       "      <th>current_max/min_spec (mA)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.997000000000</td>\n",
       "      <td>30.000000000000</td>\n",
       "      <td>-58.000000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>495.049</td>\n",
       "      <td>-100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.13</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.13</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.992000000000</td>\n",
       "      <td>30.000000000000</td>\n",
       "      <td>-56.000000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>510.204</td>\n",
       "      <td>-100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.15</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.000000000000</td>\n",
       "      <td>58.000000000000</td>\n",
       "      <td>-28.000000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>495.049</td>\n",
       "      <td>-100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.000000000000</td>\n",
       "      <td>56.400000000000</td>\n",
       "      <td>-32.000000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>510.204</td>\n",
       "      <td>-100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.15</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.000000000000</td>\n",
       "      <td>57.900000000000</td>\n",
       "      <td>-23.804700000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>495.049</td>\n",
       "      <td>-100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 10008 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     y1    y2    y3    y4    y5    y6    y7    y8    y9   y10  ... y9999  \\\n",
       "0  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  ...  0.03   \n",
       "1  0.13  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.13  ...  0.02   \n",
       "2  0.15  0.16  0.15  0.15  0.15  0.15  0.15  0.15  0.14  0.15  ...  0.05   \n",
       "3  0.15  0.15  0.15  0.15  0.15  0.15  0.15  0.15  0.15  0.15  ...  0.05   \n",
       "4  0.15  0.14  0.14  0.15  0.15  0.15  0.14  0.14  0.14  0.15  ...  0.06   \n",
       "\n",
       "  y10000 power_state_value current_rise/fall_time_value (mS)  \\\n",
       "0   0.03               0.0                    7.997000000000   \n",
       "1   0.03               0.0                    7.992000000000   \n",
       "2   0.05               0.0                    8.000000000000   \n",
       "3   0.05               0.0                    8.000000000000   \n",
       "4   0.06               0.0                    8.000000000000   \n",
       "\n",
       "  current_stabilised_value (mA) current_max/min_value (mA) power_state_spec  \\\n",
       "0               30.000000000000           -58.000000000000              0.0   \n",
       "1               30.000000000000           -56.000000000000              0.0   \n",
       "2               58.000000000000           -28.000000000000              0.0   \n",
       "3               56.400000000000           -32.000000000000              0.0   \n",
       "4               57.900000000000           -23.804700000000              0.0   \n",
       "\n",
       "  current_rise/fall_time_spec (mS) current_stabilised_spec (mA)  \\\n",
       "0                               10                      495.049   \n",
       "1                               10                      510.204   \n",
       "2                               10                      495.049   \n",
       "3                               10                      510.204   \n",
       "4                               10                      495.049   \n",
       "\n",
       "  current_max/min_spec (mA)  \n",
       "0                      -100  \n",
       "1                      -100  \n",
       "2                      -100  \n",
       "3                      -100  \n",
       "4                      -100  \n",
       "\n",
       "[5 rows x 10008 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_1 = k.iloc[:,0:10009]\n",
    "# filling the missing values\n",
    "\n",
    "# print(input_1.iloc[:,10008])\n",
    "miss = input_1.iloc[:,1:]\n",
    "miss.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 263
    },
    "colab_type": "code",
    "id": "5i0q3j2zgvS1",
    "outputId": "d7bdae54-970a-43dc-ddb0-69ff22e33f91"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y1</th>\n",
       "      <th>y2</th>\n",
       "      <th>y3</th>\n",
       "      <th>y4</th>\n",
       "      <th>y5</th>\n",
       "      <th>y6</th>\n",
       "      <th>y7</th>\n",
       "      <th>y8</th>\n",
       "      <th>y9</th>\n",
       "      <th>y10</th>\n",
       "      <th>...</th>\n",
       "      <th>y9999</th>\n",
       "      <th>y10000</th>\n",
       "      <th>power_state_value</th>\n",
       "      <th>current_rise/fall_time_value (mS)</th>\n",
       "      <th>current_stabilised_value (mA)</th>\n",
       "      <th>current_max/min_value (mA)</th>\n",
       "      <th>power_state_spec</th>\n",
       "      <th>current_rise/fall_time_spec (mS)</th>\n",
       "      <th>current_stabilised_spec (mA)</th>\n",
       "      <th>current_max/min_spec (mA)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.997</td>\n",
       "      <td>30.0</td>\n",
       "      <td>-58.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>495.049</td>\n",
       "      <td>-100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.13</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.13</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.992</td>\n",
       "      <td>30.0</td>\n",
       "      <td>-56.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>510.204</td>\n",
       "      <td>-100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.15</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.000</td>\n",
       "      <td>58.0</td>\n",
       "      <td>-28.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>495.049</td>\n",
       "      <td>-100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.000</td>\n",
       "      <td>56.4</td>\n",
       "      <td>-32.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>510.204</td>\n",
       "      <td>-100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.15</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.000</td>\n",
       "      <td>57.9</td>\n",
       "      <td>-23.8047</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>495.049</td>\n",
       "      <td>-100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 10008 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     y1    y2    y3    y4    y5    y6    y7    y8    y9   y10  ...  y9999  \\\n",
       "0  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  ...   0.03   \n",
       "1  0.13  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.12  0.13  ...   0.02   \n",
       "2  0.15  0.16  0.15  0.15  0.15  0.15  0.15  0.15  0.14  0.15  ...   0.05   \n",
       "3  0.15  0.15  0.15  0.15  0.15  0.15  0.15  0.15  0.15  0.15  ...   0.05   \n",
       "4  0.15  0.14  0.14  0.15  0.15  0.15  0.14  0.14  0.14  0.15  ...   0.06   \n",
       "\n",
       "   y10000  power_state_value  current_rise/fall_time_value (mS)  \\\n",
       "0    0.03                0.0                              7.997   \n",
       "1    0.03                0.0                              7.992   \n",
       "2    0.05                0.0                              8.000   \n",
       "3    0.05                0.0                              8.000   \n",
       "4    0.06                0.0                              8.000   \n",
       "\n",
       "   current_stabilised_value (mA)  current_max/min_value (mA)  \\\n",
       "0                           30.0                    -58.0000   \n",
       "1                           30.0                    -56.0000   \n",
       "2                           58.0                    -28.0000   \n",
       "3                           56.4                    -32.0000   \n",
       "4                           57.9                    -23.8047   \n",
       "\n",
       "   power_state_spec  current_rise/fall_time_spec (mS)  \\\n",
       "0               0.0                              10.0   \n",
       "1               0.0                              10.0   \n",
       "2               0.0                              10.0   \n",
       "3               0.0                              10.0   \n",
       "4               0.0                              10.0   \n",
       "\n",
       "   current_stabilised_spec (mA)  current_max/min_spec (mA)  \n",
       "0                       495.049                     -100.0  \n",
       "1                       510.204                     -100.0  \n",
       "2                       495.049                     -100.0  \n",
       "3                       510.204                     -100.0  \n",
       "4                       495.049                     -100.0  \n",
       "\n",
       "[5 rows x 10008 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_1 = k.iloc[:,0:10009]\n",
    "# filling the missing values\n",
    "\n",
    "miss = input_1.iloc[:,1:]\n",
    "miss.head()\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "for column in (miss.iloc[:,10000:]):\n",
    "  su = 0\n",
    "  div = 0\n",
    "  for r in range(miss.shape[0]):\n",
    "    if (pd.isna(miss[column][r]))== False:\n",
    "      su = float(miss[column][r])+su\n",
    "\n",
    "      div = div+1\n",
    "\n",
    "  fin = float(su/div)\n",
    "\n",
    "  miss[column].fillna(float(fin),inplace=True)\n",
    "#########converting ever\n",
    "# thing into float\n",
    "miss =miss.astype('float64')\n",
    "# print(miss.dtypes)\n",
    "miss.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jBZnARyHgyfK"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble.forest import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import robust_scale\n",
    "\n",
    "scaler_min_x = MinMaxScaler()\n",
    "scaler_min_y = MinMaxScaler()\n",
    "\n",
    "scaler_norm_x = Normalizer()\n",
    "scaler_norm_y = Normalizer()\n",
    "\n",
    "scaler_stan_x = StandardScaler()\n",
    "scaler_stan_y = StandardScaler()\n",
    "\n",
    "scalar_qt_x =QuantileTransformer(output_distribution='uniform')\n",
    "scalar_qt_y =QuantileTransformer(output_distribution='uniform')\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 161
    },
    "colab_type": "code",
    "id": "eyHICz0yg2BJ",
    "outputId": "67294fc3-9c83-42a2-dc0a-261d494b5951"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/preprocessing/data.py:2239: UserWarning: n_quantiles (1000) is greater than the total number of samples (397). n_quantiles is set to n_samples.\n",
      "  % (self.n_quantiles, n_samples))\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/preprocessing/data.py:2239: UserWarning: n_quantiles (1000) is greater than the total number of samples (397). n_quantiles is set to n_samples.\n",
      "  % (self.n_quantiles, n_samples))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130.0\n",
      "30.0\n"
     ]
    }
   ],
   "source": [
    "rand_na = miss\n",
    "# print(miss.shape)\n",
    "input_1_arr = rand_na.values\n",
    "input_1_arr[:,:]= input_1_arr[:,:].astype('float64')\n",
    "\n",
    "X = input_1_arr[:,0:10000]*1000\n",
    "Y = input_1_arr[:,10002:10004]\n",
    "# print(X.shape)\n",
    "# print(Y.shape)\n",
    "# print(Y)\n",
    "y=np.reshape(Y, (-1,1))\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.20)\n",
    "X_train= X\n",
    "y_train= Y\n",
    "\n",
    "\n",
    "# ######minmax\n",
    "scaler_min_x = MinMaxScaler().fit(X_train)\n",
    "scaler_min_y = MinMaxScaler().fit(y_train)\n",
    "\n",
    "X_minmax_train = scaler_min_x.transform(X_train)\n",
    "Y_minmax_train = scaler_min_y.transform(y_train)\n",
    "\n",
    "\n",
    "# print(X)\n",
    "# print(Y)\n",
    "#####standard\n",
    "\n",
    "scaler_stan_x = StandardScaler().fit(X_train)\n",
    "scaler_stan_y = StandardScaler().fit(y_train)\n",
    "\n",
    "\n",
    "X_stan_train = scaler_stan_x.transform(X_train)\n",
    "Y_stan_train = scaler_stan_y.transform(y_train)\n",
    "\n",
    "#######normlised\n",
    "scaler_norm_x = Normalizer().fit(X_train)\n",
    "scaler_norm_y = Normalizer().fit(y_train)\n",
    "\n",
    "\n",
    "X_norm_train = scaler_norm_x.transform(X_train)\n",
    "Y_norm_train = scaler_norm_y.transform(y_train)\n",
    "\n",
    "\n",
    "# ################qt\n",
    "\n",
    "scaler_qt_x =  QuantileTransformer(output_distribution='normal').fit(X_train)\n",
    "scaler_qt_y =  QuantileTransformer(output_distribution='normal').fit(y_train)\n",
    "\n",
    "\n",
    "X_qt_train = scaler_qt_x.transform(X_train)\n",
    "Y_qt_train = scaler_qt_y.transform(y_train)\n",
    "\n",
    "\n",
    "##robust\n",
    "\n",
    "##robust\n",
    "print(np.amax(X_train[0,:]))\n",
    "print(np.amax(y_train[0,:]))\n",
    "\n",
    "X_train = np.concatenate((X_train, y_train), axis=1)\n",
    "# print(np.amax(X_train[0,:]))\n",
    "X_train_t = X_train.transpose()\n",
    "# y_train_t = y_train.transpose()\n",
    "# print(X_train,\"after\")\n",
    "# print(y_train.shape,\"after\")\n",
    "\n",
    "scaler_min_x = MinMaxScaler().fit(X_train_t)\n",
    "# scaler_rob_y = RobustScaler().fit(y_train_t)\n",
    "\n",
    "\n",
    "X_min_train = scaler_min_x.transform(X_train_t)\n",
    "# Y_rob_train = scaler_rob_x.transform(y_train_t)\n",
    "\n",
    "X_min_train = X_min_train.transpose()\n",
    "# Y_rob_train = Y_rob_train.transpose()\n",
    "\n",
    "# print(X_rob_train.shape)\n",
    "# print(Y_rob_train.shape)\n",
    "# print(Y_rob_train)\n",
    "\n",
    "Y_min_train = X_min_train[:,10000:10002]\n",
    "X_min_train = X_min_train[:,0:10000]\n",
    "# print(Y_rob_train)\n",
    "# print(X_rob_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "RlJlt7DghBIG",
    "outputId": "88bba53c-b75d-458f-cb84-41297679341b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(397, 30)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import FactorAnalysis\n",
    "\n",
    "transformer = FactorAnalysis(n_components=30, random_state=0)\n",
    "factor_fit = transformer.fit(X_min_train)\n",
    "X_new = factor_fit.transform(X_min_train)\n",
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D5rmicgppLVP"
   },
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "pickle.dump(factor_fit, open( \"./app/MODEL/factor_fit_off.pkl\", \"wb\" ) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1VKNQkEahFjV"
   },
   "outputs": [],
   "source": [
    "def baseline_model_30(optimizer='adam'):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(28, activation='relu', \n",
    "                    kernel_initializer = 'he_normal', \n",
    "                    input_shape=(30,)))\n",
    "    model.add(BatchNormalization())\n",
    "#     model.add(Dropout(0.5))\n",
    "#     model.add(Dense(30, activation='relu',\n",
    "#                     kernel_initializer = 'he_normal'))\n",
    "#       model.add(BatchNormalization())\n",
    "#     model.add(Dropout(0.5))\n",
    "    model.add(Dense(12, activation='relu',\n",
    "                    kernel_initializer = 'he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "#     model.add(Dropout(0.5))\n",
    "    model.add(Dense(9, activation='relu',\n",
    "                    kernel_initializer = 'he_normal'))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(Dropout(0.5))\n",
    "    model.add(Dense(2, activation='linear', \n",
    "                    kernel_initializer='he_normal'))\n",
    "    model.compile(loss = 'mse', optimizer=optimizer, metrics=['mae'])\n",
    "#     model.summary()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "4thveclshIbz",
    "outputId": "f1f13189-5035-4910-cd20-25a91590c6fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "[array([[ 5.26526235e-02,  3.72373648e-02,  2.61084080e-01,\n",
      "         2.79833674e-01,  5.34276217e-02,  6.13022558e-02,\n",
      "         1.80990738e-03,  6.25232756e-02,  1.14927270e-01,\n",
      "        -4.71740842e-01, -3.05925399e-01,  2.07358554e-01,\n",
      "         2.05327012e-02, -2.90686131e-01,  2.96071947e-01,\n",
      "         2.99449056e-01, -2.91352153e-01, -3.20955247e-01,\n",
      "        -3.53684127e-02,  3.61002773e-01, -2.37601563e-01,\n",
      "        -9.18572582e-03,  3.23766172e-02,  1.96157292e-01,\n",
      "         3.71659458e-01, -1.10144168e-01, -2.51680434e-01,\n",
      "         4.21309173e-01],\n",
      "       [ 5.56081254e-03,  2.40097344e-01,  1.32406861e-01,\n",
      "         3.78884673e-01,  4.20026928e-01, -2.39723742e-01,\n",
      "         1.55574664e-01,  5.52032232e-01, -1.69374608e-03,\n",
      "        -1.89622506e-01,  2.61649281e-01,  1.11239150e-01,\n",
      "         1.98178679e-01, -3.89303833e-01, -3.99449348e-01,\n",
      "         2.37465873e-01, -5.81020378e-02, -3.30289692e-01,\n",
      "        -6.48573413e-02, -4.20356542e-01,  1.36226088e-01,\n",
      "        -1.43761262e-01,  1.79525331e-01,  8.36032033e-02,\n",
      "        -7.22857788e-02,  9.70312729e-02,  1.84642263e-02,\n",
      "         3.24484676e-01],\n",
      "       [-2.45240238e-02,  4.12905604e-01,  4.98887062e-01,\n",
      "         2.12901890e-01, -1.72556058e-01,  2.41029069e-01,\n",
      "        -1.36848941e-01,  2.58596539e-01, -1.20407462e-01,\n",
      "        -1.43518835e-01, -9.24912989e-02, -2.30686739e-01,\n",
      "        -1.30956113e-01,  1.60972893e-01, -5.61660714e-02,\n",
      "        -4.96864319e-02,  3.08550835e-01, -1.98022380e-01,\n",
      "         4.81531292e-01, -1.37811095e-01,  2.26151288e-01,\n",
      "        -1.52750716e-01,  1.13360487e-01, -4.56185937e-01,\n",
      "        -1.72463223e-01, -2.31613860e-01,  8.75607431e-02,\n",
      "        -1.91621447e-03],\n",
      "       [ 1.66020811e-01, -2.75825799e-01,  5.52422702e-01,\n",
      "         2.12624907e-01,  6.63527697e-02, -4.28922743e-01,\n",
      "        -2.90786833e-01, -3.78124058e-01, -2.37104058e-01,\n",
      "         7.04990923e-02, -4.03170437e-01, -3.95939767e-01,\n",
      "         1.88557915e-02, -2.62434602e-01,  2.96945851e-02,\n",
      "         3.47434253e-01,  1.86395630e-01,  5.60742438e-01,\n",
      "         2.18171313e-01, -4.95599389e-01, -2.83657879e-01,\n",
      "         1.04551248e-01,  4.80602197e-02, -6.45116940e-02,\n",
      "         3.67999226e-01,  7.54720112e-03,  8.56379792e-02,\n",
      "         3.19542557e-01],\n",
      "       [ 5.04482128e-02,  2.23010089e-02,  2.89116241e-02,\n",
      "         1.05536431e-01,  5.27851760e-01,  1.81856379e-01,\n",
      "         7.85342082e-02, -2.00871214e-01,  5.30119613e-02,\n",
      "        -1.94045156e-01, -3.68755579e-01, -1.24555029e-01,\n",
      "         1.92481294e-01,  1.28674880e-01, -4.23265956e-02,\n",
      "        -2.50957549e-01,  1.68794230e-01, -2.05879077e-01,\n",
      "         2.55508691e-01, -9.55601223e-03,  1.80448461e-02,\n",
      "        -1.19229928e-01, -4.23846483e-01, -1.60078868e-01,\n",
      "         1.01235293e-01,  5.23671627e-01, -4.54534292e-01,\n",
      "        -4.62240353e-02],\n",
      "       [-2.88297474e-01, -4.97237742e-01,  1.26055166e-01,\n",
      "        -1.27967373e-01,  8.96491706e-02, -4.97859232e-02,\n",
      "         2.75339484e-01, -1.99577406e-01,  2.37660035e-01,\n",
      "         2.89532095e-01, -6.41094595e-02, -1.71733871e-01,\n",
      "        -3.84168416e-01,  2.50315480e-02, -3.06746483e-01,\n",
      "        -1.04236148e-01, -7.99320522e-04,  4.61835861e-01,\n",
      "         2.23155811e-01,  1.92074656e-01,  3.57870519e-01,\n",
      "         3.31335872e-01,  1.45005301e-01,  1.91665359e-03,\n",
      "        -2.31068712e-02,  1.60545513e-01,  8.40079859e-02,\n",
      "        -5.53867698e-01],\n",
      "       [-1.99528679e-01, -2.28943884e-01,  3.16851959e-02,\n",
      "        -1.76074937e-01,  4.37318869e-02, -1.11451507e-01,\n",
      "        -3.89039487e-01,  7.48877525e-02, -4.24465269e-01,\n",
      "         2.94406980e-01,  3.38101715e-01,  4.53446567e-01,\n",
      "        -8.51755142e-02, -2.97554612e-01, -2.34577194e-01,\n",
      "         2.41733298e-01,  1.09556645e-01,  1.02109611e-01,\n",
      "         1.76769793e-01,  4.36068118e-01, -1.19863220e-01,\n",
      "        -4.14425671e-01, -7.22435489e-02, -3.62679772e-02,\n",
      "        -4.17957366e-01, -1.41307890e-01, -3.98029424e-02,\n",
      "         1.40680909e-01],\n",
      "       [-2.34573334e-01, -3.19897546e-03,  8.71947333e-02,\n",
      "         2.05679506e-01, -4.44472849e-01, -5.76630756e-02,\n",
      "         4.25816774e-01, -3.27647030e-01,  1.48692861e-01,\n",
      "         5.06328754e-02,  2.77673990e-01,  2.89010555e-01,\n",
      "        -4.03740555e-02,  1.40292615e-01,  3.35695654e-01,\n",
      "         8.71150270e-02,  2.55484402e-01,  2.72768676e-01,\n",
      "        -2.50106454e-01,  2.18067199e-01, -1.38776690e-01,\n",
      "        -1.44607648e-01, -1.22978687e-01,  1.45142889e-02,\n",
      "        -1.92400873e-01,  7.27007985e-02,  2.40021124e-01,\n",
      "         2.00834438e-01],\n",
      "       [-7.89673775e-02,  3.35572332e-01, -9.37235355e-02,\n",
      "        -4.50899780e-01,  2.56621718e-01,  2.62977064e-01,\n",
      "         1.15865447e-01,  5.35958409e-01,  5.08144677e-01,\n",
      "        -3.15693766e-01, -4.49311078e-01,  3.49725217e-01,\n",
      "        -6.55176491e-02,  3.19686294e-01, -3.27534109e-01,\n",
      "        -3.26726437e-01, -5.04321933e-01,  2.07095370e-01,\n",
      "         1.23530596e-01, -3.63984436e-01,  1.64135192e-02,\n",
      "        -2.07931295e-01, -2.29796991e-01,  3.09688039e-02,\n",
      "         8.52518063e-03, -3.40006389e-02, -9.96395648e-02,\n",
      "         1.03950776e-01],\n",
      "       [ 5.39416492e-01, -2.31351972e-01,  4.13768776e-02,\n",
      "         8.12572539e-02, -2.08728209e-01,  4.44100350e-01,\n",
      "         4.24563847e-02,  1.48721591e-01, -5.05066253e-02,\n",
      "        -4.79409337e-01,  3.86972517e-01,  3.70727360e-01,\n",
      "        -6.78585991e-02, -2.32498735e-01, -1.22645810e-01,\n",
      "        -6.87711313e-02,  5.06598294e-01, -3.85550499e-01,\n",
      "        -1.87295541e-01, -8.44374746e-02, -2.88664490e-01,\n",
      "        -3.72320056e-01,  5.78790950e-03,  1.96357463e-02,\n",
      "         4.26370949e-01, -3.03132515e-02,  5.46540558e-01,\n",
      "         1.67232260e-01],\n",
      "       [ 2.55807966e-01,  3.82504761e-02,  3.83190006e-01,\n",
      "        -3.97711366e-01,  2.43770592e-02, -3.06727499e-01,\n",
      "        -1.70561731e-01,  3.05844814e-01, -1.82088137e-01,\n",
      "        -1.26355082e-01, -3.41657460e-01, -8.97031277e-02,\n",
      "        -5.23141861e-01,  1.12997629e-01, -3.79143268e-01,\n",
      "        -4.15133566e-01, -3.32818627e-02,  8.32490902e-03,\n",
      "         2.45283484e-01,  4.60304469e-01,  4.80361879e-01,\n",
      "         1.81904331e-01, -7.83502609e-02, -2.43830398e-01,\n",
      "        -3.37998182e-01, -4.90081832e-02, -1.23108074e-01,\n",
      "        -4.32180047e-01],\n",
      "       [ 1.75317898e-01,  5.56387305e-02, -2.69270003e-01,\n",
      "         2.49958381e-01,  5.86131401e-02, -4.90084916e-01,\n",
      "        -3.32098693e-01,  8.78712237e-02, -3.00221771e-01,\n",
      "         7.27347955e-02, -9.32617411e-02,  1.57991707e-01,\n",
      "        -2.33086243e-01, -1.22269511e-01,  3.48910466e-02,\n",
      "        -5.74825890e-03,  1.06682591e-01, -1.22891918e-01,\n",
      "         1.25963971e-01,  2.76699394e-01, -1.26313334e-02,\n",
      "         3.59907337e-02,  2.08753586e-01, -1.36066273e-01,\n",
      "         1.44815948e-02,  2.77161356e-02, -6.89656213e-02,\n",
      "        -1.35867387e-01],\n",
      "       [ 6.65012822e-02,  1.62773252e-01, -2.03159347e-01,\n",
      "        -3.32774185e-02, -3.22147548e-01, -2.05007210e-01,\n",
      "         1.14681885e-01,  1.88872308e-01, -1.45679444e-01,\n",
      "        -5.51272593e-02,  1.09717861e-01,  3.01964343e-01,\n",
      "        -3.64062369e-01, -9.42794383e-02,  1.26026496e-02,\n",
      "         8.49978998e-02, -1.36246055e-01,  5.59508502e-01,\n",
      "        -8.92731249e-02, -4.69528466e-01, -2.61348963e-01,\n",
      "         2.21068218e-01, -1.85891241e-02,  2.67639965e-01,\n",
      "        -1.10030845e-01, -3.68921489e-01, -3.58382463e-01,\n",
      "        -3.14973183e-02],\n",
      "       [-8.43175352e-02, -1.35243297e-01,  2.17297804e-02,\n",
      "         1.20186441e-01,  1.86772361e-01, -2.42275611e-01,\n",
      "        -2.65460521e-01,  8.53075162e-02, -4.81382795e-02,\n",
      "         3.18079323e-01, -1.62302211e-01,  6.25003129e-02,\n",
      "         3.40330243e-01,  1.33739263e-01,  7.76130557e-02,\n",
      "         2.00290963e-01,  1.21078745e-01, -1.54723033e-01,\n",
      "         8.39914829e-02, -1.02368161e-01, -1.23160273e-01,\n",
      "         1.10462092e-01,  9.64576006e-03, -7.64850229e-02,\n",
      "         4.02650505e-01, -2.18339920e-01,  2.20220581e-01,\n",
      "        -2.22568348e-01],\n",
      "       [ 1.15959169e-02, -2.81939715e-01, -2.47520193e-01,\n",
      "        -2.37791501e-02, -3.52079570e-02,  3.59468073e-01,\n",
      "        -1.87782809e-01,  3.99142236e-01,  4.96583700e-01,\n",
      "        -3.36789131e-01,  7.31647015e-02,  2.89537102e-01,\n",
      "        -2.39912599e-01,  2.68905044e-01,  1.77841067e-01,\n",
      "         9.47241485e-02,  1.57015696e-01, -1.40062138e-01,\n",
      "        -2.95758069e-01,  4.10805047e-01,  2.56598592e-02,\n",
      "         2.93568939e-01,  2.86818773e-01,  4.29145813e-01,\n",
      "         1.70036539e-01, -1.58702284e-01, -3.77445251e-01,\n",
      "        -7.85175636e-02],\n",
      "       [-5.12599885e-01,  1.45541448e-02,  1.72411799e-02,\n",
      "         3.73332858e-01, -4.61326152e-01, -6.65043592e-02,\n",
      "         3.01715136e-02, -1.27902523e-01, -5.28843179e-02,\n",
      "         6.81761578e-02, -1.80894472e-02, -3.46992075e-01,\n",
      "        -3.19201142e-01, -3.30928303e-02, -2.47846618e-01,\n",
      "        -1.53187022e-01,  6.89664632e-02,  3.19189250e-01,\n",
      "         1.28720894e-01,  4.60647255e-01,  3.59405205e-02,\n",
      "         1.16820537e-01,  4.21785980e-01,  8.68227184e-02,\n",
      "        -4.29241657e-01,  5.49627654e-02, -9.68433172e-03,\n",
      "        -2.71318287e-01],\n",
      "       [-2.83401102e-01, -1.84932336e-01, -3.94860446e-01,\n",
      "         7.94945657e-02,  3.00688464e-02,  5.48010245e-02,\n",
      "         3.42107445e-01,  3.72419208e-02, -4.13967520e-01,\n",
      "        -1.20690957e-01, -5.30845299e-02, -1.36215389e-01,\n",
      "        -1.01928767e-02,  1.39546320e-01,  3.17363858e-01,\n",
      "        -6.17337786e-02,  1.00488894e-01,  9.32314023e-02,\n",
      "        -3.35494429e-01,  4.22227204e-01, -2.10848719e-01,\n",
      "         1.43241420e-01,  2.61807263e-01, -1.05347455e-01,\n",
      "         2.20989203e-03, -3.64776820e-01, -5.57478368e-01,\n",
      "        -1.00982934e-01],\n",
      "       [ 2.23709360e-01, -1.25293106e-01, -9.77750421e-02,\n",
      "         7.58801936e-04,  3.44464749e-01, -9.37148705e-02,\n",
      "         4.31732386e-01, -4.12970573e-01,  7.07059056e-02,\n",
      "        -7.81674832e-02,  4.63992238e-01,  3.78522128e-02,\n",
      "         2.09563360e-01, -1.28506079e-01, -6.78903982e-02,\n",
      "        -1.27473667e-01, -2.90196985e-01, -4.90945190e-01,\n",
      "        -1.44823581e-01,  4.09788311e-01, -3.65039766e-01,\n",
      "        -2.40708187e-01, -1.01113610e-01,  4.36183095e-01,\n",
      "        -1.99028552e-01, -1.10279649e-01,  2.61111781e-02,\n",
      "         1.48518920e-01],\n",
      "       [-4.43047322e-02, -3.53621133e-02,  1.31763116e-01,\n",
      "        -5.64040124e-01,  2.96082705e-01,  3.00362170e-01,\n",
      "        -5.70262820e-02, -2.36887001e-02,  1.19882673e-01,\n",
      "         2.34881222e-01,  1.80831850e-01,  6.92898557e-02,\n",
      "         4.45911705e-01,  3.06728166e-02,  9.72846001e-02,\n",
      "         3.67858261e-01, -5.09904176e-02,  1.53514266e-01,\n",
      "        -4.81246620e-01, -9.83611792e-02,  3.13765407e-01,\n",
      "        -4.94537711e-01,  4.83424872e-01, -3.30352426e-01,\n",
      "         1.16133280e-01, -1.59462869e-01, -2.77019981e-02,\n",
      "        -1.08348377e-01],\n",
      "       [-1.21913522e-01, -1.63328350e-01,  4.63042557e-02,\n",
      "         2.89237462e-02,  2.66183764e-02, -5.47020793e-01,\n",
      "         3.81788127e-02, -1.80451244e-01, -1.32540867e-01,\n",
      "         6.87420741e-02, -2.54184663e-01, -1.28044084e-01,\n",
      "         3.20202887e-01,  2.54396737e-01, -3.71798463e-02,\n",
      "        -7.49098063e-02,  3.11392933e-01, -3.77105236e-01,\n",
      "        -5.30972669e-04, -1.74474299e-01,  2.37159818e-01,\n",
      "        -1.29441038e-01,  8.09017718e-02, -2.63256133e-02,\n",
      "         3.97881001e-01,  2.13326104e-02,  1.86911628e-01,\n",
      "        -5.53646944e-02],\n",
      "       [ 1.48628995e-01, -2.50745267e-01, -2.90179461e-01,\n",
      "        -1.75551414e-01, -1.99780446e-02,  2.64524966e-01,\n",
      "        -3.18913937e-01, -3.30832332e-01, -1.73349917e-01,\n",
      "         6.12208918e-02,  1.81918263e-01,  5.41129470e-01,\n",
      "         4.14227068e-01,  4.96400774e-01, -2.64286071e-01,\n",
      "         4.29641828e-02,  3.20069492e-01,  1.75888315e-01,\n",
      "         2.85520172e-03,  1.04432777e-02, -3.67181376e-02,\n",
      "         1.81900822e-02, -1.71349838e-01,  3.81618664e-02,\n",
      "         1.78660467e-01,  1.75235629e-01,  1.63524613e-01,\n",
      "        -9.60397348e-02],\n",
      "       [ 2.90712297e-01, -8.32313001e-02,  3.08534473e-01,\n",
      "        -2.50781570e-02,  2.78841317e-01, -4.33198847e-02,\n",
      "        -3.36892813e-01,  2.22903699e-01,  9.58865583e-02,\n",
      "        -2.65249014e-01,  5.43648064e-01, -4.06718329e-02,\n",
      "        -2.72022607e-03, -4.91774082e-01, -1.39324576e-01,\n",
      "        -2.72266537e-01, -2.11028576e-01,  3.06907862e-01,\n",
      "         1.95776284e-01,  1.52436167e-01,  3.09296578e-01,\n",
      "        -4.32725340e-01,  2.75145680e-01, -2.22406238e-02,\n",
      "         1.03893451e-01,  2.80871630e-01, -5.45647070e-02,\n",
      "         1.11199319e-01],\n",
      "       [ 1.29627615e-01, -2.24301815e-01,  1.23747967e-01,\n",
      "        -3.52175087e-01,  1.00421131e-01, -3.43055613e-02,\n",
      "        -3.75702709e-01,  1.73227027e-01, -7.16380328e-02,\n",
      "         4.40077335e-02,  7.85838068e-02, -1.10556372e-01,\n",
      "         1.51910111e-01, -2.03442484e-01, -5.19303009e-02,\n",
      "        -3.55382562e-01, -9.31517854e-02,  4.55254428e-02,\n",
      "        -2.69300938e-01, -4.67954427e-01,  5.72070062e-01,\n",
      "        -1.68375567e-01,  4.92990427e-02,  3.20495427e-01,\n",
      "         3.90354581e-02, -3.30154955e-01, -2.69934274e-02,\n",
      "         3.78311798e-03],\n",
      "       [-1.96610838e-01,  3.68621737e-01, -1.12502798e-01,\n",
      "        -5.12978017e-01, -1.32362828e-01,  1.90065131e-01,\n",
      "        -2.49348402e-01,  1.27333969e-01,  1.41984895e-01,\n",
      "         1.27688840e-01, -3.97924513e-01,  1.28008857e-01,\n",
      "        -4.19610329e-02,  5.18928051e-01,  8.16601887e-03,\n",
      "         2.00364050e-02,  2.98142195e-01,  2.56470349e-02,\n",
      "        -1.15864143e-01,  3.56652848e-02, -2.10784093e-01,\n",
      "         3.18012536e-01, -1.89776003e-01, -7.97063112e-02,\n",
      "         2.59881496e-01, -2.33585164e-02, -2.30182454e-01,\n",
      "        -1.62812531e-01],\n",
      "       [-1.82946712e-01,  2.36154631e-01, -6.27802014e-02,\n",
      "        -1.14830703e-01,  2.81599939e-01, -1.39737561e-01,\n",
      "        -1.18349381e-01, -1.91733781e-02,  1.04284085e-01,\n",
      "        -3.98293465e-01,  2.17278302e-01,  2.13352129e-01,\n",
      "         7.50113651e-03,  1.24235064e-01, -3.66712511e-02,\n",
      "        -3.44971091e-01,  2.31376424e-01, -2.39672110e-04,\n",
      "        -4.80544955e-01,  8.88542086e-02,  4.20568913e-01,\n",
      "         3.60052496e-01, -2.68510640e-01, -1.20099485e-02,\n",
      "         1.16711594e-01, -2.96435673e-02, -1.40855551e-01,\n",
      "         4.16459918e-01],\n",
      "       [-4.43873912e-01,  1.70131251e-01,  1.73570618e-01,\n",
      "        -1.58315733e-01,  1.91892013e-02,  2.06219465e-01,\n",
      "         2.34316275e-01, -1.32361844e-01, -2.98509926e-01,\n",
      "        -5.70767634e-02,  8.44961479e-02, -3.38000834e-01,\n",
      "        -1.84242740e-01, -3.62512201e-01, -1.08853363e-01,\n",
      "        -1.49539053e-01,  1.30112588e-01,  1.58564940e-01,\n",
      "        -4.76728350e-01, -1.79276004e-01, -2.81054765e-01,\n",
      "         1.27442360e-01,  5.23623712e-02, -2.82948446e-02,\n",
      "        -2.01369792e-01,  5.21037821e-03,  9.71206278e-02,\n",
      "        -7.27955997e-02],\n",
      "       [-1.36198178e-01, -1.79717660e-01,  1.11550115e-01,\n",
      "        -1.82068169e-01, -1.47503540e-01, -1.19138509e-01,\n",
      "         4.01205719e-01, -9.31355078e-03,  1.11001134e-01,\n",
      "        -3.63345444e-01, -8.14926773e-02, -9.03036147e-02,\n",
      "        -1.33359373e-01,  3.99289817e-01,  2.26377979e-01,\n",
      "         2.83154100e-01,  1.90348383e-02,  2.69572645e-01,\n",
      "        -2.42363349e-01, -6.65938482e-02, -3.64032477e-01,\n",
      "        -1.52462954e-02, -1.58800706e-01,  1.90360695e-02,\n",
      "         1.52731672e-01,  3.58473837e-01,  1.02508031e-01,\n",
      "         6.76923916e-02],\n",
      "       [ 2.17492431e-02, -3.62338930e-01, -4.47182357e-01,\n",
      "        -1.16896220e-01,  1.01251327e-01, -1.78036481e-01,\n",
      "         3.85235138e-02,  2.12497011e-01,  1.05145216e-01,\n",
      "        -1.95146918e-01, -2.42792472e-01, -1.18386494e-02,\n",
      "        -1.55773133e-01, -1.33044332e-01, -1.52793825e-02,\n",
      "         2.58723021e-01,  2.11553313e-02, -2.79609561e-01,\n",
      "         1.44032821e-01, -2.13876441e-01, -2.94655740e-01,\n",
      "        -4.25366797e-02, -3.08868974e-01,  5.11442125e-01,\n",
      "        -1.88657999e-01, -5.15323877e-03,  4.27798152e-01,\n",
      "         3.87538761e-01],\n",
      "       [ 2.71825254e-01,  1.21651530e-01, -9.47719067e-02,\n",
      "         4.69794869e-01, -5.29749036e-01, -3.82960103e-02,\n",
      "        -1.95592448e-01,  2.51763999e-01,  1.21952454e-02,\n",
      "         1.95740044e-01, -1.92771420e-01, -4.26874042e-01,\n",
      "         5.67702055e-01,  4.33361501e-01,  2.59343863e-01,\n",
      "        -1.69218063e-01,  1.78399488e-01, -2.18058273e-01,\n",
      "        -2.53450811e-01, -5.26872694e-01, -3.46582741e-01,\n",
      "        -1.72341436e-01,  9.80973691e-02, -3.86060715e-01,\n",
      "        -3.69640559e-01, -5.64148240e-02,  4.91514020e-02,\n",
      "        -9.02681239e-03],\n",
      "       [ 3.55225205e-01,  1.67501688e-01,  1.43205360e-01,\n",
      "         2.57501662e-01,  3.07385862e-01,  2.02342108e-01,\n",
      "        -4.68383916e-02, -1.82597384e-01, -5.04899681e-01,\n",
      "        -3.03149074e-01,  2.01595455e-01, -2.91005999e-01,\n",
      "         4.54166204e-01,  1.02465171e-02, -1.03108464e-02,\n",
      "        -2.77555943e-01, -1.03138238e-01, -2.44355753e-01,\n",
      "        -4.12281364e-01,  1.61924690e-01, -2.61244863e-01,\n",
      "         5.35627961e-01, -2.49458715e-01, -2.50877663e-02,\n",
      "        -1.78752244e-01,  1.43123120e-01, -1.33313462e-01,\n",
      "         2.39481717e-01]], dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), array([[-0.33315864, -0.39412072, -0.1669955 , -0.26197094,  0.3993159 ,\n",
      "         0.06488731, -0.4174816 , -0.1742568 , -0.5714957 , -0.05630215,\n",
      "        -0.54489446,  0.37778407],\n",
      "       [-0.31880045, -0.26423094, -0.01976471,  0.17388599,  0.21382904,\n",
      "        -0.05369724,  0.4839543 ,  0.17626694,  0.32779545,  0.04108518,\n",
      "        -0.38478702,  0.38078043],\n",
      "       [ 0.28324923, -0.29490006,  0.44713217, -0.14996547, -0.10310687,\n",
      "         0.11978588, -0.15482071,  0.3749909 , -0.30237   , -0.44877726,\n",
      "         0.1612008 , -0.07306161],\n",
      "       [ 0.26198438,  0.22219273, -0.12469003,  0.59885067, -0.10694169,\n",
      "        -0.29295984, -0.21018398, -0.21281433, -0.572727  , -0.27804857,\n",
      "         0.1120379 ,  0.12619728],\n",
      "       [ 0.23219539,  0.28790703, -0.16389029, -0.18300854, -0.37626308,\n",
      "         0.14291897,  0.34203893,  0.08735537, -0.5155713 , -0.47833952,\n",
      "        -0.36054963,  0.03072162],\n",
      "       [ 0.1095955 , -0.07245794,  0.01347943, -0.13738759, -0.11251131,\n",
      "        -0.2158959 ,  0.2237128 , -0.30705166,  0.10068032, -0.18519029,\n",
      "        -0.50634205,  0.13545932],\n",
      "       [-0.13664377, -0.04811021, -0.35280788, -0.11942561,  0.43852228,\n",
      "        -0.26821503,  0.44268614, -0.49882543, -0.20894566,  0.05674312,\n",
      "         0.17368913,  0.27496678],\n",
      "       [ 0.11726729,  0.40552294,  0.22567096, -0.14220853, -0.32531655,\n",
      "         0.24979335,  0.34964114, -0.16879454,  0.1478053 , -0.22818229,\n",
      "         0.5395396 ,  0.18269365],\n",
      "       [ 0.4680702 ,  0.49662593, -0.4809304 ,  0.17651048, -0.1944054 ,\n",
      "         0.06782477,  0.25560105, -0.0806914 ,  0.20393184, -0.06211668,\n",
      "         0.27292165,  0.5286897 ],\n",
      "       [ 0.07615938,  0.18411028, -0.4663995 , -0.4900835 ,  0.32267258,\n",
      "         0.20441988,  0.246069  , -0.17029396, -0.56737244,  0.44132054,\n",
      "        -0.24338782, -0.23963742],\n",
      "       [ 0.15558927,  0.04599107,  0.11960821,  0.56117815,  0.30479935,\n",
      "        -0.54925287,  0.1813789 , -0.38001627,  0.07065495,  0.25000852,\n",
      "        -0.2832788 , -0.52348   ],\n",
      "       [ 0.1994216 ,  0.23719761, -0.47117397,  0.19284783, -0.32888135,\n",
      "        -0.3367597 , -0.18109088, -0.0820454 , -0.4567904 , -0.06766231,\n",
      "        -0.22116926, -0.40093935],\n",
      "       [ 0.44061983, -0.2792007 ,  0.06559411, -0.31454605,  0.31861785,\n",
      "        -0.11295235, -0.25692812, -0.05445485,  0.04660084, -0.32786557,\n",
      "        -0.17875491, -0.1979318 ],\n",
      "       [-0.521264  ,  0.10738108,  0.00842115,  0.0658941 ,  0.14091228,\n",
      "        -0.18918161, -0.15845662,  0.04401339,  0.19079669,  0.06185927,\n",
      "        -0.60520643,  0.07652576],\n",
      "       [-0.45623383,  0.02376414, -0.04362368, -0.18759784,  0.21083567,\n",
      "         0.27222717,  0.09435995, -0.15802944, -0.00348668,  0.02430945,\n",
      "        -0.40140402,  0.14711392],\n",
      "       [ 0.05964786,  0.21096337,  0.3153016 ,  0.1659033 , -0.18098792,\n",
      "        -0.2346446 , -0.14620878,  0.56363237,  0.02884145, -0.17356904,\n",
      "         0.25564107, -0.17077155],\n",
      "       [-0.23949909,  0.17877236, -0.49674916, -0.34891653,  0.04966643,\n",
      "        -0.2610693 ,  0.26572007,  0.01431319,  0.09001364, -0.40589866,\n",
      "         0.06087136, -0.24743368],\n",
      "       [ 0.01567875,  0.06776274,  0.10383911,  0.34266734, -0.26969928,\n",
      "        -0.31089604,  0.32722637, -0.10379176,  0.23171546, -0.0075144 ,\n",
      "        -0.27747503,  0.12337738],\n",
      "       [-0.5480308 , -0.50165325, -0.30918512, -0.03819011, -0.35322765,\n",
      "         0.12438998,  0.4636415 , -0.03696755,  0.11197832, -0.10816224,\n",
      "        -0.09669207, -0.24818079],\n",
      "       [ 0.19589558, -0.48026946,  0.59422886, -0.3574854 , -0.32062063,\n",
      "        -0.10486098,  0.02729531,  0.06403522,  0.33976418, -0.09904537,\n",
      "         0.28042883,  0.1771766 ],\n",
      "       [ 0.08639693, -0.0394985 , -0.34486312,  0.31121337, -0.3810896 ,\n",
      "        -0.38614628,  0.27356318,  0.21996614, -0.4883557 , -0.09126473,\n",
      "        -0.4992415 ,  0.05762899],\n",
      "       [-0.03887342,  0.3879339 ,  0.5239242 ,  0.35296527, -0.17164528,\n",
      "         0.26047924, -0.16173321, -0.16892675, -0.43304458, -0.20327371,\n",
      "        -0.28542513, -0.52398604],\n",
      "       [-0.02491504, -0.19011731,  0.2857148 ,  0.47568738,  0.14450198,\n",
      "        -0.09973487, -0.03551491, -0.3585325 , -0.40761784,  0.24074338,\n",
      "         0.34812382, -0.09683166],\n",
      "       [ 0.12532456, -0.11037556,  0.42833957, -0.1955601 ,  0.45040703,\n",
      "        -0.52876115, -0.41200203, -0.06466259, -0.4634842 ,  0.164669  ,\n",
      "        -0.29965353,  0.11847553],\n",
      "       [ 0.19067478,  0.04299496,  0.5197462 ,  0.14675647,  0.336001  ,\n",
      "        -0.21462254, -0.29244632,  0.079144  ,  0.21250457, -0.12885624,\n",
      "         0.53625244, -0.2379038 ],\n",
      "       [ 0.46202052,  0.24991827, -0.40133718, -0.0161044 , -0.1722262 ,\n",
      "        -0.2611571 , -0.36760458, -0.3493688 , -0.5084702 , -0.03919276,\n",
      "        -0.3491045 ,  0.23916474],\n",
      "       [ 0.51139534,  0.4376012 , -0.08911272, -0.32341015, -0.4137649 ,\n",
      "        -0.13893762, -0.03384434, -0.27403438,  0.1194924 , -0.00428492,\n",
      "         0.12924014,  0.26956168],\n",
      "       [-0.17745557, -0.12281653,  0.01654679, -0.3793104 ,  0.14146326,\n",
      "         0.23957495, -0.16405395, -0.27665225, -0.16311625,  0.4857629 ,\n",
      "        -0.16849144,  0.21575613]], dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), array([[ 0.6102319 ,  0.555334  , -0.36973327,  0.08913759, -0.02912939,\n",
      "         0.63154453, -0.471251  ,  0.82339334,  0.16735749],\n",
      "       [-0.6758378 ,  0.08149854, -0.3442696 , -0.55993587,  0.17647156,\n",
      "        -0.14937715,  0.16326104,  0.13775209, -0.56514436],\n",
      "       [-0.08598521, -0.17079622,  0.25874576, -0.07763732, -0.60822767,\n",
      "        -0.13349314,  0.78010553,  0.16961782,  0.44377944],\n",
      "       [-0.19705649,  0.5266491 ,  0.48652208,  0.0142194 ,  0.38512018,\n",
      "        -0.31769815,  0.45025647, -0.11628396, -0.42995912],\n",
      "       [ 0.0644094 , -0.18717928,  0.05388772,  0.3024086 ,  0.48618165,\n",
      "         0.44790375, -0.36185682,  0.07569992, -0.45350638],\n",
      "       [-0.73121643,  0.15992808, -0.00314398, -0.43806982, -0.46477842,\n",
      "         0.04311839, -0.09921687,  0.29273063, -0.38279623],\n",
      "       [ 0.06061394,  0.13398403, -0.13640575, -0.07753586,  0.0299016 ,\n",
      "         0.35885784,  0.09616644,  0.84699166,  0.12931384],\n",
      "       [ 0.14886509,  0.03606045,  0.05290176, -0.08653124,  0.2599766 ,\n",
      "        -0.37848157,  0.09836292, -0.5312941 ,  0.06080272],\n",
      "       [ 0.88844854, -0.45654175,  0.39907947, -0.11515138, -0.4792037 ,\n",
      "        -0.8320776 ,  0.07636695,  0.29743293,  0.7337387 ],\n",
      "       [-0.27954462, -0.48859346,  0.32947338,  0.70071155, -0.34895056,\n",
      "        -0.11873639,  0.65062517,  0.442803  ,  0.7339777 ],\n",
      "       [-0.2658305 , -0.5764024 , -0.86083186, -0.1833837 , -0.46529812,\n",
      "         0.47759175, -0.8733078 , -0.7406294 , -0.26698303],\n",
      "       [ 0.4621785 ,  0.0113141 ,  0.19582807,  0.09501051,  0.3182902 ,\n",
      "        -0.01637978,  0.47423437,  0.43359947,  0.6620639 ]],\n",
      "      dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), array([[ 0.4310743 , -0.2192223 ],\n",
      "       [-0.6167353 , -0.43119645],\n",
      "       [-0.07541354, -0.0680297 ],\n",
      "       [-0.15399651,  0.34899545],\n",
      "       [ 0.7687172 ,  0.12114488],\n",
      "       [ 0.06723185, -0.21759595],\n",
      "       [-0.27294385, -0.07483718],\n",
      "       [-0.3967407 , -0.12412298],\n",
      "       [-0.03256571,  0.8883581 ]], dtype=float32), array([0., 0.], dtype=float32)]\n",
      "(397, 30)\n",
      "(397, 2)\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "397/397 [==============================] - 1s 2ms/step - loss: 0.5484 - mean_absolute_error: 0.5558\n",
      "Epoch 2/200\n",
      "397/397 [==============================] - 0s 289us/step - loss: 0.2728 - mean_absolute_error: 0.3938\n",
      "Epoch 3/200\n",
      "397/397 [==============================] - 0s 288us/step - loss: 0.1694 - mean_absolute_error: 0.3081\n",
      "Epoch 4/200\n",
      "397/397 [==============================] - 0s 308us/step - loss: 0.1433 - mean_absolute_error: 0.2862\n",
      "Epoch 5/200\n",
      "397/397 [==============================] - 0s 339us/step - loss: 0.1070 - mean_absolute_error: 0.2461\n",
      "Epoch 6/200\n",
      "397/397 [==============================] - 0s 300us/step - loss: 0.0965 - mean_absolute_error: 0.2366\n",
      "Epoch 7/200\n",
      "397/397 [==============================] - 0s 286us/step - loss: 0.0790 - mean_absolute_error: 0.2095\n",
      "Epoch 8/200\n",
      "397/397 [==============================] - 0s 326us/step - loss: 0.0714 - mean_absolute_error: 0.1991\n",
      "Epoch 9/200\n",
      "397/397 [==============================] - 0s 338us/step - loss: 0.0686 - mean_absolute_error: 0.1923\n",
      "Epoch 10/200\n",
      "397/397 [==============================] - 0s 369us/step - loss: 0.0632 - mean_absolute_error: 0.1871\n",
      "Epoch 11/200\n",
      "397/397 [==============================] - 0s 335us/step - loss: 0.0577 - mean_absolute_error: 0.1754\n",
      "Epoch 12/200\n",
      "397/397 [==============================] - 0s 270us/step - loss: 0.0559 - mean_absolute_error: 0.1753\n",
      "Epoch 13/200\n",
      "397/397 [==============================] - 0s 358us/step - loss: 0.0515 - mean_absolute_error: 0.1685\n",
      "Epoch 14/200\n",
      "397/397 [==============================] - 0s 457us/step - loss: 0.0489 - mean_absolute_error: 0.1632\n",
      "Epoch 15/200\n",
      "397/397 [==============================] - 0s 265us/step - loss: 0.0452 - mean_absolute_error: 0.1551\n",
      "Epoch 16/200\n",
      "397/397 [==============================] - 0s 290us/step - loss: 0.0445 - mean_absolute_error: 0.1560\n",
      "Epoch 17/200\n",
      "397/397 [==============================] - 0s 336us/step - loss: 0.0409 - mean_absolute_error: 0.1481\n",
      "Epoch 18/200\n",
      "397/397 [==============================] - 0s 330us/step - loss: 0.0438 - mean_absolute_error: 0.1509\n",
      "Epoch 19/200\n",
      "397/397 [==============================] - 0s 324us/step - loss: 0.0424 - mean_absolute_error: 0.1495\n",
      "Epoch 20/200\n",
      "397/397 [==============================] - 0s 284us/step - loss: 0.0416 - mean_absolute_error: 0.1491\n",
      "Epoch 21/200\n",
      "397/397 [==============================] - 0s 359us/step - loss: 0.0437 - mean_absolute_error: 0.1529\n",
      "Epoch 22/200\n",
      "397/397 [==============================] - 0s 271us/step - loss: 0.0434 - mean_absolute_error: 0.1519\n",
      "Epoch 23/200\n",
      "397/397 [==============================] - 0s 304us/step - loss: 0.0418 - mean_absolute_error: 0.1484\n",
      "Epoch 24/200\n",
      "397/397 [==============================] - 0s 302us/step - loss: 0.0375 - mean_absolute_error: 0.1392\n",
      "Epoch 25/200\n",
      "397/397 [==============================] - 0s 300us/step - loss: 0.0388 - mean_absolute_error: 0.1422\n",
      "Epoch 26/200\n",
      "397/397 [==============================] - 0s 289us/step - loss: 0.0371 - mean_absolute_error: 0.1390\n",
      "Epoch 27/200\n",
      "397/397 [==============================] - 0s 298us/step - loss: 0.0347 - mean_absolute_error: 0.1342\n",
      "Epoch 28/200\n",
      "397/397 [==============================] - 0s 318us/step - loss: 0.0382 - mean_absolute_error: 0.1387\n",
      "Epoch 29/200\n",
      "397/397 [==============================] - 0s 341us/step - loss: 0.0354 - mean_absolute_error: 0.1350\n",
      "Epoch 30/200\n",
      "397/397 [==============================] - 0s 370us/step - loss: 0.0366 - mean_absolute_error: 0.1358\n",
      "Epoch 31/200\n",
      "397/397 [==============================] - 0s 278us/step - loss: 0.0342 - mean_absolute_error: 0.1350\n",
      "Epoch 32/200\n",
      "397/397 [==============================] - 0s 284us/step - loss: 0.0347 - mean_absolute_error: 0.1320\n",
      "Epoch 33/200\n",
      "397/397 [==============================] - 0s 285us/step - loss: 0.0357 - mean_absolute_error: 0.1359\n",
      "Epoch 34/200\n",
      "397/397 [==============================] - 0s 290us/step - loss: 0.0338 - mean_absolute_error: 0.1304\n",
      "Epoch 35/200\n",
      "397/397 [==============================] - 0s 284us/step - loss: 0.0322 - mean_absolute_error: 0.1247\n",
      "Epoch 36/200\n",
      "397/397 [==============================] - 0s 286us/step - loss: 0.0328 - mean_absolute_error: 0.1281\n",
      "Epoch 37/200\n",
      "397/397 [==============================] - 0s 286us/step - loss: 0.0350 - mean_absolute_error: 0.1340\n",
      "Epoch 38/200\n",
      "397/397 [==============================] - 0s 354us/step - loss: 0.0321 - mean_absolute_error: 0.1264\n",
      "Epoch 39/200\n",
      "397/397 [==============================] - 0s 304us/step - loss: 0.0317 - mean_absolute_error: 0.1270\n",
      "Epoch 40/200\n",
      "397/397 [==============================] - 0s 312us/step - loss: 0.0309 - mean_absolute_error: 0.1253\n",
      "Epoch 41/200\n",
      "397/397 [==============================] - 0s 268us/step - loss: 0.0307 - mean_absolute_error: 0.1230\n",
      "Epoch 42/200\n",
      "397/397 [==============================] - 0s 268us/step - loss: 0.0312 - mean_absolute_error: 0.1232\n",
      "Epoch 43/200\n",
      "397/397 [==============================] - 0s 265us/step - loss: 0.0320 - mean_absolute_error: 0.1249\n",
      "Epoch 44/200\n",
      "397/397 [==============================] - 0s 299us/step - loss: 0.0324 - mean_absolute_error: 0.1266\n",
      "Epoch 45/200\n",
      "397/397 [==============================] - 0s 293us/step - loss: 0.0315 - mean_absolute_error: 0.1243\n",
      "Epoch 46/200\n",
      "397/397 [==============================] - 0s 302us/step - loss: 0.0321 - mean_absolute_error: 0.1246\n",
      "Epoch 47/200\n",
      "397/397 [==============================] - 0s 306us/step - loss: 0.0329 - mean_absolute_error: 0.1268\n",
      "Epoch 48/200\n",
      "397/397 [==============================] - 0s 288us/step - loss: 0.0297 - mean_absolute_error: 0.1200\n",
      "Epoch 49/200\n",
      "397/397 [==============================] - 0s 316us/step - loss: 0.0301 - mean_absolute_error: 0.1210\n",
      "Epoch 50/200\n",
      "397/397 [==============================] - 0s 281us/step - loss: 0.0310 - mean_absolute_error: 0.1231\n",
      "Epoch 51/200\n",
      "397/397 [==============================] - 0s 285us/step - loss: 0.0294 - mean_absolute_error: 0.1176\n",
      "Epoch 52/200\n",
      "397/397 [==============================] - 0s 290us/step - loss: 0.0309 - mean_absolute_error: 0.1203\n",
      "Epoch 53/200\n",
      "397/397 [==============================] - 0s 287us/step - loss: 0.0307 - mean_absolute_error: 0.1220\n",
      "Epoch 54/200\n",
      "397/397 [==============================] - 0s 284us/step - loss: 0.0297 - mean_absolute_error: 0.1189\n",
      "Epoch 55/200\n",
      "397/397 [==============================] - 0s 284us/step - loss: 0.0313 - mean_absolute_error: 0.1211\n",
      "Epoch 56/200\n",
      "397/397 [==============================] - 0s 290us/step - loss: 0.0309 - mean_absolute_error: 0.1217\n",
      "Epoch 57/200\n",
      "397/397 [==============================] - 0s 324us/step - loss: 0.0273 - mean_absolute_error: 0.1153\n",
      "Epoch 58/200\n",
      "397/397 [==============================] - 0s 309us/step - loss: 0.0302 - mean_absolute_error: 0.1208\n",
      "Epoch 59/200\n",
      "397/397 [==============================] - 0s 312us/step - loss: 0.0312 - mean_absolute_error: 0.1206\n",
      "Epoch 60/200\n",
      "397/397 [==============================] - 0s 279us/step - loss: 0.0289 - mean_absolute_error: 0.1157\n",
      "Epoch 61/200\n",
      "397/397 [==============================] - 0s 268us/step - loss: 0.0280 - mean_absolute_error: 0.1145\n",
      "Epoch 62/200\n",
      "397/397 [==============================] - 0s 279us/step - loss: 0.0286 - mean_absolute_error: 0.1177\n",
      "Epoch 63/200\n",
      "397/397 [==============================] - 0s 316us/step - loss: 0.0293 - mean_absolute_error: 0.1149\n",
      "Epoch 64/200\n",
      "397/397 [==============================] - 0s 297us/step - loss: 0.0286 - mean_absolute_error: 0.1166\n",
      "Epoch 65/200\n",
      "397/397 [==============================] - 0s 323us/step - loss: 0.0282 - mean_absolute_error: 0.1139\n",
      "Epoch 66/200\n",
      "397/397 [==============================] - 0s 303us/step - loss: 0.0290 - mean_absolute_error: 0.1168\n",
      "Epoch 67/200\n",
      "397/397 [==============================] - 0s 308us/step - loss: 0.0290 - mean_absolute_error: 0.1156\n",
      "Epoch 68/200\n",
      "397/397 [==============================] - 0s 286us/step - loss: 0.0301 - mean_absolute_error: 0.1176\n",
      "Epoch 69/200\n",
      "397/397 [==============================] - 0s 281us/step - loss: 0.0304 - mean_absolute_error: 0.1199\n",
      "Epoch 70/200\n",
      "397/397 [==============================] - 0s 287us/step - loss: 0.0279 - mean_absolute_error: 0.1135\n",
      "Epoch 71/200\n",
      "397/397 [==============================] - 0s 286us/step - loss: 0.0290 - mean_absolute_error: 0.1173\n",
      "Epoch 72/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "397/397 [==============================] - 0s 282us/step - loss: 0.0299 - mean_absolute_error: 0.1164\n",
      "Epoch 73/200\n",
      "397/397 [==============================] - 0s 285us/step - loss: 0.0285 - mean_absolute_error: 0.1149\n",
      "Epoch 74/200\n",
      "397/397 [==============================] - 0s 282us/step - loss: 0.0267 - mean_absolute_error: 0.1116\n",
      "Epoch 75/200\n",
      "397/397 [==============================] - 0s 278us/step - loss: 0.0295 - mean_absolute_error: 0.1143\n",
      "Epoch 76/200\n",
      "397/397 [==============================] - 0s 285us/step - loss: 0.0294 - mean_absolute_error: 0.1131\n",
      "Epoch 77/200\n",
      "397/397 [==============================] - 0s 363us/step - loss: 0.0286 - mean_absolute_error: 0.1140\n",
      "Epoch 78/200\n",
      "397/397 [==============================] - 0s 326us/step - loss: 0.0278 - mean_absolute_error: 0.1131\n",
      "Epoch 79/200\n",
      "397/397 [==============================] - 0s 278us/step - loss: 0.0278 - mean_absolute_error: 0.1122\n",
      "Epoch 80/200\n",
      "397/397 [==============================] - 0s 268us/step - loss: 0.0283 - mean_absolute_error: 0.1146\n",
      "Epoch 81/200\n",
      "397/397 [==============================] - 0s 264us/step - loss: 0.0284 - mean_absolute_error: 0.1139\n",
      "Epoch 82/200\n",
      "397/397 [==============================] - 0s 267us/step - loss: 0.0275 - mean_absolute_error: 0.1122\n",
      "Epoch 83/200\n",
      "397/397 [==============================] - 0s 266us/step - loss: 0.0289 - mean_absolute_error: 0.1143\n",
      "Epoch 84/200\n",
      "397/397 [==============================] - 0s 285us/step - loss: 0.0268 - mean_absolute_error: 0.1106\n",
      "Epoch 85/200\n",
      "397/397 [==============================] - 0s 301us/step - loss: 0.0270 - mean_absolute_error: 0.1105\n",
      "Epoch 86/200\n",
      "397/397 [==============================] - 0s 310us/step - loss: 0.0286 - mean_absolute_error: 0.1163\n",
      "Epoch 87/200\n",
      "397/397 [==============================] - 0s 316us/step - loss: 0.0270 - mean_absolute_error: 0.1084\n",
      "Epoch 88/200\n",
      "397/397 [==============================] - 0s 281us/step - loss: 0.0285 - mean_absolute_error: 0.1146\n",
      "Epoch 89/200\n",
      "397/397 [==============================] - 0s 293us/step - loss: 0.0285 - mean_absolute_error: 0.1117\n",
      "Epoch 90/200\n",
      "397/397 [==============================] - 0s 282us/step - loss: 0.0271 - mean_absolute_error: 0.1125\n",
      "Epoch 91/200\n",
      "397/397 [==============================] - 0s 320us/step - loss: 0.0262 - mean_absolute_error: 0.1091\n",
      "Epoch 92/200\n",
      "397/397 [==============================] - 0s 289us/step - loss: 0.0262 - mean_absolute_error: 0.1106\n",
      "Epoch 93/200\n",
      "397/397 [==============================] - 0s 271us/step - loss: 0.0285 - mean_absolute_error: 0.1120\n",
      "Epoch 94/200\n",
      "397/397 [==============================] - 0s 298us/step - loss: 0.0287 - mean_absolute_error: 0.1119\n",
      "Epoch 95/200\n",
      "397/397 [==============================] - 0s 285us/step - loss: 0.0271 - mean_absolute_error: 0.1104\n",
      "Epoch 96/200\n",
      "397/397 [==============================] - 0s 270us/step - loss: 0.0274 - mean_absolute_error: 0.1108\n",
      "Epoch 97/200\n",
      "397/397 [==============================] - 0s 271us/step - loss: 0.0281 - mean_absolute_error: 0.1133\n",
      "Epoch 98/200\n",
      "397/397 [==============================] - 0s 275us/step - loss: 0.0264 - mean_absolute_error: 0.1093\n",
      "Epoch 99/200\n",
      "397/397 [==============================] - 0s 282us/step - loss: 0.0287 - mean_absolute_error: 0.1114\n",
      "Epoch 100/200\n",
      "397/397 [==============================] - 0s 283us/step - loss: 0.0281 - mean_absolute_error: 0.1111\n",
      "Epoch 101/200\n",
      "397/397 [==============================] - 0s 263us/step - loss: 0.0282 - mean_absolute_error: 0.1147\n",
      "Epoch 102/200\n",
      "397/397 [==============================] - 0s 267us/step - loss: 0.0272 - mean_absolute_error: 0.1093\n",
      "Epoch 103/200\n",
      "397/397 [==============================] - 0s 279us/step - loss: 0.0284 - mean_absolute_error: 0.1142\n",
      "Epoch 104/200\n",
      "397/397 [==============================] - 0s 313us/step - loss: 0.0275 - mean_absolute_error: 0.1091\n",
      "Epoch 105/200\n",
      "397/397 [==============================] - 0s 297us/step - loss: 0.0276 - mean_absolute_error: 0.1103\n",
      "Epoch 106/200\n",
      "397/397 [==============================] - 0s 330us/step - loss: 0.0265 - mean_absolute_error: 0.1071\n",
      "Epoch 107/200\n",
      "397/397 [==============================] - 0s 297us/step - loss: 0.0268 - mean_absolute_error: 0.1098\n",
      "Epoch 108/200\n",
      "397/397 [==============================] - 0s 278us/step - loss: 0.0271 - mean_absolute_error: 0.1128\n",
      "Epoch 109/200\n",
      "397/397 [==============================] - 0s 310us/step - loss: 0.0282 - mean_absolute_error: 0.1109\n",
      "Epoch 110/200\n",
      "397/397 [==============================] - 0s 296us/step - loss: 0.0251 - mean_absolute_error: 0.1065\n",
      "Epoch 111/200\n",
      "397/397 [==============================] - 0s 309us/step - loss: 0.0266 - mean_absolute_error: 0.1054\n",
      "Epoch 112/200\n",
      "397/397 [==============================] - 0s 305us/step - loss: 0.0267 - mean_absolute_error: 0.1097\n",
      "Epoch 113/200\n",
      "397/397 [==============================] - 0s 317us/step - loss: 0.0262 - mean_absolute_error: 0.1077\n",
      "Epoch 114/200\n",
      "397/397 [==============================] - 0s 291us/step - loss: 0.0252 - mean_absolute_error: 0.1056\n",
      "Epoch 115/200\n",
      "397/397 [==============================] - 0s 310us/step - loss: 0.0283 - mean_absolute_error: 0.1104\n",
      "Epoch 116/200\n",
      "397/397 [==============================] - 0s 279us/step - loss: 0.0264 - mean_absolute_error: 0.1067\n",
      "Epoch 117/200\n",
      "397/397 [==============================] - 0s 299us/step - loss: 0.0268 - mean_absolute_error: 0.1061\n",
      "Epoch 118/200\n",
      "397/397 [==============================] - 0s 304us/step - loss: 0.0251 - mean_absolute_error: 0.1050\n",
      "Epoch 119/200\n",
      "397/397 [==============================] - 0s 352us/step - loss: 0.0285 - mean_absolute_error: 0.1089\n",
      "Epoch 120/200\n",
      "397/397 [==============================] - 0s 304us/step - loss: 0.0280 - mean_absolute_error: 0.1087\n",
      "Epoch 121/200\n",
      "397/397 [==============================] - 0s 300us/step - loss: 0.0266 - mean_absolute_error: 0.1049\n",
      "Epoch 122/200\n",
      "397/397 [==============================] - 0s 314us/step - loss: 0.0255 - mean_absolute_error: 0.1066\n",
      "Epoch 123/200\n",
      "397/397 [==============================] - 0s 330us/step - loss: 0.0268 - mean_absolute_error: 0.1054\n",
      "Epoch 124/200\n",
      "397/397 [==============================] - 0s 288us/step - loss: 0.0242 - mean_absolute_error: 0.1014\n",
      "Epoch 125/200\n",
      "397/397 [==============================] - 0s 314us/step - loss: 0.0258 - mean_absolute_error: 0.1046\n",
      "Epoch 126/200\n",
      "397/397 [==============================] - 0s 301us/step - loss: 0.0259 - mean_absolute_error: 0.1034\n",
      "Epoch 127/200\n",
      "397/397 [==============================] - 0s 352us/step - loss: 0.0272 - mean_absolute_error: 0.1078\n",
      "Epoch 128/200\n",
      "397/397 [==============================] - 0s 309us/step - loss: 0.0259 - mean_absolute_error: 0.1062\n",
      "Epoch 129/200\n",
      "397/397 [==============================] - 0s 341us/step - loss: 0.0269 - mean_absolute_error: 0.1040\n",
      "Epoch 130/200\n",
      "397/397 [==============================] - 0s 296us/step - loss: 0.0248 - mean_absolute_error: 0.1032\n",
      "Epoch 131/200\n",
      "397/397 [==============================] - 0s 298us/step - loss: 0.0254 - mean_absolute_error: 0.1023\n",
      "Epoch 132/200\n",
      "397/397 [==============================] - 0s 299us/step - loss: 0.0248 - mean_absolute_error: 0.1027\n",
      "Epoch 133/200\n",
      "397/397 [==============================] - 0s 298us/step - loss: 0.0254 - mean_absolute_error: 0.1056\n",
      "Epoch 134/200\n",
      "397/397 [==============================] - 0s 303us/step - loss: 0.0264 - mean_absolute_error: 0.1053\n",
      "Epoch 135/200\n",
      "397/397 [==============================] - 0s 295us/step - loss: 0.0249 - mean_absolute_error: 0.1009\n",
      "Epoch 136/200\n",
      "397/397 [==============================] - 0s 298us/step - loss: 0.0254 - mean_absolute_error: 0.1045\n",
      "Epoch 137/200\n",
      "397/397 [==============================] - 0s 295us/step - loss: 0.0252 - mean_absolute_error: 0.1028\n",
      "Epoch 138/200\n",
      "397/397 [==============================] - 0s 316us/step - loss: 0.0251 - mean_absolute_error: 0.1035\n",
      "Epoch 139/200\n",
      "397/397 [==============================] - 0s 334us/step - loss: 0.0260 - mean_absolute_error: 0.1034\n",
      "Epoch 140/200\n",
      "397/397 [==============================] - 0s 323us/step - loss: 0.0246 - mean_absolute_error: 0.1011\n",
      "Epoch 141/200\n",
      "397/397 [==============================] - 0s 327us/step - loss: 0.0263 - mean_absolute_error: 0.1046\n",
      "Epoch 142/200\n",
      "397/397 [==============================] - 0s 311us/step - loss: 0.0253 - mean_absolute_error: 0.1021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 143/200\n",
      "397/397 [==============================] - 0s 310us/step - loss: 0.0255 - mean_absolute_error: 0.1018\n",
      "Epoch 144/200\n",
      "397/397 [==============================] - 0s 311us/step - loss: 0.0254 - mean_absolute_error: 0.1015\n",
      "Epoch 145/200\n",
      "397/397 [==============================] - 0s 301us/step - loss: 0.0248 - mean_absolute_error: 0.1023\n",
      "Epoch 146/200\n",
      "397/397 [==============================] - 0s 326us/step - loss: 0.0260 - mean_absolute_error: 0.1046\n",
      "Epoch 147/200\n",
      "397/397 [==============================] - 0s 296us/step - loss: 0.0236 - mean_absolute_error: 0.0990\n",
      "Epoch 148/200\n",
      "397/397 [==============================] - 0s 283us/step - loss: 0.0239 - mean_absolute_error: 0.0998\n",
      "Epoch 149/200\n",
      "397/397 [==============================] - 0s 283us/step - loss: 0.0257 - mean_absolute_error: 0.1030\n",
      "Epoch 150/200\n",
      "397/397 [==============================] - 0s 281us/step - loss: 0.0251 - mean_absolute_error: 0.1012\n",
      "Epoch 151/200\n",
      "397/397 [==============================] - 0s 357us/step - loss: 0.0250 - mean_absolute_error: 0.1008\n",
      "Epoch 152/200\n",
      "397/397 [==============================] - 0s 295us/step - loss: 0.0239 - mean_absolute_error: 0.0987\n",
      "Epoch 153/200\n",
      "397/397 [==============================] - 0s 274us/step - loss: 0.0236 - mean_absolute_error: 0.0979\n",
      "Epoch 154/200\n",
      "397/397 [==============================] - 0s 270us/step - loss: 0.0243 - mean_absolute_error: 0.0990\n",
      "Epoch 155/200\n",
      "397/397 [==============================] - 0s 277us/step - loss: 0.0240 - mean_absolute_error: 0.0996\n",
      "Epoch 156/200\n",
      "397/397 [==============================] - 0s 282us/step - loss: 0.0248 - mean_absolute_error: 0.1006\n",
      "Epoch 157/200\n",
      "397/397 [==============================] - 0s 311us/step - loss: 0.0230 - mean_absolute_error: 0.0942\n",
      "Epoch 158/200\n",
      "397/397 [==============================] - 0s 335us/step - loss: 0.0238 - mean_absolute_error: 0.0978\n",
      "Epoch 159/200\n",
      "397/397 [==============================] - 0s 297us/step - loss: 0.0240 - mean_absolute_error: 0.0984\n",
      "Epoch 160/200\n",
      "397/397 [==============================] - 0s 304us/step - loss: 0.0239 - mean_absolute_error: 0.0995\n",
      "Epoch 161/200\n",
      "397/397 [==============================] - 0s 297us/step - loss: 0.0246 - mean_absolute_error: 0.0984\n",
      "Epoch 162/200\n",
      "397/397 [==============================] - 0s 295us/step - loss: 0.0241 - mean_absolute_error: 0.0996\n",
      "Epoch 163/200\n",
      "397/397 [==============================] - 0s 299us/step - loss: 0.0234 - mean_absolute_error: 0.0983\n",
      "Epoch 164/200\n",
      "397/397 [==============================] - 0s 301us/step - loss: 0.0247 - mean_absolute_error: 0.0973\n",
      "Epoch 165/200\n",
      "397/397 [==============================] - 0s 301us/step - loss: 0.0256 - mean_absolute_error: 0.1028\n",
      "Epoch 166/200\n",
      "397/397 [==============================] - 0s 287us/step - loss: 0.0234 - mean_absolute_error: 0.0973\n",
      "Epoch 167/200\n",
      "397/397 [==============================] - 0s 294us/step - loss: 0.0236 - mean_absolute_error: 0.0991\n",
      "Epoch 168/200\n",
      "397/397 [==============================] - 0s 306us/step - loss: 0.0240 - mean_absolute_error: 0.0963\n",
      "Epoch 169/200\n",
      "397/397 [==============================] - 0s 299us/step - loss: 0.0246 - mean_absolute_error: 0.1000\n",
      "Epoch 170/200\n",
      "397/397 [==============================] - 0s 289us/step - loss: 0.0245 - mean_absolute_error: 0.0995\n",
      "Epoch 171/200\n",
      "397/397 [==============================] - 0s 292us/step - loss: 0.0234 - mean_absolute_error: 0.0979\n",
      "Epoch 172/200\n",
      "397/397 [==============================] - 0s 301us/step - loss: 0.0241 - mean_absolute_error: 0.0990\n",
      "Epoch 173/200\n",
      "397/397 [==============================] - 0s 299us/step - loss: 0.0263 - mean_absolute_error: 0.1023\n",
      "Epoch 174/200\n",
      "397/397 [==============================] - 0s 301us/step - loss: 0.0235 - mean_absolute_error: 0.0981\n",
      "Epoch 175/200\n",
      "397/397 [==============================] - 0s 308us/step - loss: 0.0235 - mean_absolute_error: 0.0975\n",
      "Epoch 176/200\n",
      "397/397 [==============================] - 0s 302us/step - loss: 0.0228 - mean_absolute_error: 0.0949\n",
      "Epoch 177/200\n",
      "397/397 [==============================] - 0s 298us/step - loss: 0.0242 - mean_absolute_error: 0.1002\n",
      "Epoch 178/200\n",
      "397/397 [==============================] - 0s 301us/step - loss: 0.0233 - mean_absolute_error: 0.0969\n",
      "Epoch 179/200\n",
      "397/397 [==============================] - 0s 304us/step - loss: 0.0242 - mean_absolute_error: 0.0953\n",
      "Epoch 180/200\n",
      "397/397 [==============================] - 0s 293us/step - loss: 0.0243 - mean_absolute_error: 0.0980\n",
      "Epoch 181/200\n",
      "397/397 [==============================] - 0s 300us/step - loss: 0.0225 - mean_absolute_error: 0.0934\n",
      "Epoch 182/200\n",
      "397/397 [==============================] - 0s 300us/step - loss: 0.0242 - mean_absolute_error: 0.0989\n",
      "Epoch 183/200\n",
      "397/397 [==============================] - 0s 298us/step - loss: 0.0219 - mean_absolute_error: 0.0941\n",
      "Epoch 184/200\n",
      "397/397 [==============================] - 0s 304us/step - loss: 0.0227 - mean_absolute_error: 0.0956\n",
      "Epoch 185/200\n",
      "397/397 [==============================] - 0s 311us/step - loss: 0.0213 - mean_absolute_error: 0.0914\n",
      "Epoch 186/200\n",
      "397/397 [==============================] - 0s 306us/step - loss: 0.0230 - mean_absolute_error: 0.0946\n",
      "Epoch 187/200\n",
      "397/397 [==============================] - 0s 299us/step - loss: 0.0225 - mean_absolute_error: 0.0942\n",
      "Epoch 188/200\n",
      "397/397 [==============================] - 0s 307us/step - loss: 0.0235 - mean_absolute_error: 0.0962\n",
      "Epoch 189/200\n",
      "397/397 [==============================] - 0s 307us/step - loss: 0.0239 - mean_absolute_error: 0.0967\n",
      "Epoch 190/200\n",
      "397/397 [==============================] - 0s 305us/step - loss: 0.0221 - mean_absolute_error: 0.0917\n",
      "Epoch 191/200\n",
      "397/397 [==============================] - 0s 308us/step - loss: 0.0228 - mean_absolute_error: 0.0939\n",
      "Epoch 192/200\n",
      "397/397 [==============================] - 0s 293us/step - loss: 0.0221 - mean_absolute_error: 0.0937\n",
      "Epoch 193/200\n",
      "397/397 [==============================] - 0s 297us/step - loss: 0.0229 - mean_absolute_error: 0.0948\n",
      "Epoch 194/200\n",
      "397/397 [==============================] - 0s 283us/step - loss: 0.0220 - mean_absolute_error: 0.0917\n",
      "Epoch 195/200\n",
      "397/397 [==============================] - 0s 282us/step - loss: 0.0216 - mean_absolute_error: 0.0915\n",
      "Epoch 196/200\n",
      "397/397 [==============================] - 0s 300us/step - loss: 0.0218 - mean_absolute_error: 0.0928\n",
      "Epoch 197/200\n",
      "397/397 [==============================] - 0s 288us/step - loss: 0.0215 - mean_absolute_error: 0.0902\n",
      "Epoch 198/200\n",
      "397/397 [==============================] - 0s 283us/step - loss: 0.0210 - mean_absolute_error: 0.0903\n",
      "Epoch 199/200\n",
      "397/397 [==============================] - 0s 276us/step - loss: 0.0212 - mean_absolute_error: 0.0891\n",
      "Epoch 200/200\n",
      "397/397 [==============================] - 0s 270us/step - loss: 0.0227 - mean_absolute_error: 0.0950\n"
     ]
    }
   ],
   "source": [
    "model = baseline_model_30()\n",
    "\n",
    "print (model.get_weights())\n",
    "# estimator = train_data_nn(X_new, Y_rob_train)\n",
    "\n",
    "print(X_new.shape)\n",
    "print(y_train.shape)\n",
    "history = model.fit(X_new,  Y_min_train, epochs=200, batch_size=5,  verbose=1, validation_split=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2KIpX4xqhVAU"
   },
   "outputs": [],
   "source": [
    "def visualize_learning_curve(history):\n",
    "    # list all data in history\n",
    "    print(history.history.keys())\n",
    "    # summarize history for accuracy\n",
    "    plt.plot(history.history['loss'])\n",
    "#     plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.show()\n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['mean_absolute_error'])\n",
    "#     plt.plot(history.history['val_mean_absolute_error'])\n",
    "    plt.title('model mean_absolute_error')\n",
    "    plt.ylabel('mean_absolute_error')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I65fooUhhsKq"
   },
   "outputs": [],
   "source": [
    "\n",
    "# print(X_test.shape)\n",
    "# X_test_t = X_test.transpose()\n",
    "# print(X_test_t.shape)\n",
    "# scaler_rob_x = MinMaxScaler().fit(X_test_t)\n",
    "# X_new_test_t = scaler_rob_x.transform(X_test_t)\n",
    "# X_new_test = X_new_test_t.transpose()\n",
    "# print(X_new_test.shape)\n",
    "\n",
    "# y_test_t = y_test.transpose()\n",
    "# # scaler_rob_y = RobustScaler().fit(y_test_t)\n",
    "# Y_new_test_t = scaler_rob_x.transform(y_test_t)\n",
    "# Y_new_test = Y_new_test_t.transpose()\n",
    "\n",
    "# X_new_test = factor_fit.transform(X_new_test)\n",
    "# print(X_new_test.shape)\n",
    "\n",
    "# visualize_learning_curve(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "colab_type": "code",
    "id": "46dPn9dGh0Cz",
    "outputId": "24cd3972-a178-4a49-b029-9d8e02fccd99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02424251576406297\n",
      "dict_keys(['loss', 'mean_absolute_error'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "import math\n",
    "# from sklearn.metrics import max_error\n",
    "\n",
    "pred = model.predict((X_new))\n",
    "# print(pred)\n",
    "\n",
    "mse = (mean_squared_error(Y_min_train,pred))\n",
    "\n",
    "print(mse)\n",
    "visualize_learning_curve(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "pRkF_i2xh6JG",
    "outputId": "b5293546-9fcf-403c-c146-8c2746a0bc84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 30. -58.] y\n",
      "[ 13.369384 -47.665356]\n",
      "[ 30. -56.] y\n",
      "[ 12.976942 -46.868614]\n",
      "[ 58. -28.] y\n",
      "[ 52.513042 -19.214937]\n",
      "[ 56.4 -32. ] y\n",
      "[ 45.667747 -18.431555]\n",
      "[ 57.9    -23.8047] y\n",
      "[ 59.483803 -10.486419]\n",
      "[ 55.1    -26.4219] y\n",
      "[ 52.59641 -16.28153]\n",
      "[ 0.02      -0.0688594] y\n",
      "[-11.583254 -65.27382 ]\n",
      "[ 0.03      -0.0549297] y\n",
      "[ 25.576973 -39.314766]\n",
      "[  0.     -39.3672] y\n",
      "[ -3.8570192 -37.523605 ]\n",
      "[  0.     -39.2578] y\n",
      "[ -1.9668388 -37.51948  ]\n",
      "[ -5.     -39.9766] y\n",
      "[  2.953199 -35.747673]\n",
      "[  0.     -36.9063] y\n",
      "[  2.9489422 -35.625412 ]\n",
      "[ -5.     -40.9297] y\n",
      "[  0.4808855 -35.56383  ]\n",
      "[-10.     -41.7813] y\n",
      "[  1.9640497 -35.719425 ]\n",
      "[  0.     -27.8281] y\n",
      "[ 11.896692 -17.676266]\n",
      "[  0.     -30.0469] y\n",
      "[ 12.6525545 -17.441996 ]\n",
      "[ 0.     12.2813] y\n",
      "[50.20587  22.381397]\n",
      "[0.     7.0469] y\n",
      "[40.206585  12.3816185]\n",
      "[ 54.7    -24.8047] y\n",
      "[ 56.84318  -11.474515]\n",
      "[ 59.9    -23.0938] y\n",
      "[ 57.52563 -13.49755]\n",
      "[ 57.8    -24.9219] y\n",
      "[ 57.327854 -15.856696]\n",
      "[ 60.     -23.2578] y\n",
      "[ 55.862667 -11.96979 ]\n",
      "[ 59.3    -23.7813] y\n",
      "[ 57.89738  -10.148306]\n",
      "[ 59.1    -23.4219] y\n",
      "[54.86616  -7.055621]\n",
      "[-250.     -251.9297] y\n",
      "[-250.21571 -250.05228]\n",
      "[-250.     -251.9297] y\n",
      "[-250.21571 -250.05228]\n",
      "[-17.3    -52.5469] y\n",
      "[-19.184763 -46.119648]\n",
      "[-19.4    -51.2109] y\n",
      "[ -2.913347 -42.46434 ]\n",
      "[-16.7    -52.1875] y\n",
      "[ -5.6335716 -44.815372 ]\n",
      "[-20.     -51.8359] y\n",
      "[ -8.763321 -45.944866]\n",
      "[-19.6    -52.5938] y\n",
      "[-14.429425 -47.70102 ]\n",
      "[-15.3    -52.4297] y\n",
      "[ -7.0361834 -45.40956  ]\n",
      "[-60.     -91.9688] y\n",
      "[-46.285828 -81.91664 ]\n",
      "[-70.     -95.7109] y\n",
      "[-71.03913 -98.00448]\n",
      "[ 40.     -41.7969] y\n",
      "[ 36.75704  -33.637936]\n",
      "[ 40.     -40.9453] y\n",
      "[ 34.31464 -32.3743 ]\n",
      "[ 38.5    -42.9609] y\n",
      "[ 36.94428  -30.410118]\n",
      "[ 40.     -40.8906] y\n",
      "[ 36.31471 -30.10868]\n",
      "[ 40.     -42.0859] y\n",
      "[ 34.908672 -32.73371 ]\n",
      "[ 39.4    -42.9219] y\n",
      "[ 37.729904 -31.940891]\n",
      "[  0.     -33.8828] y\n",
      "[  6.103783 -27.535755]\n",
      "[  0.     -32.6797] y\n",
      "[ 11.24406 -25.62121]\n",
      "[  0.     -32.9922] y\n",
      "[ 12.571704 -25.531092]\n",
      "[  0.     -31.7656] y\n",
      "[  5.9981956 -27.56848  ]\n",
      "[  0.     -32.2109] y\n",
      "[ 11.700165 -25.509039]\n",
      "[  0.     -33.7734] y\n",
      "[ 12.548972 -25.538137]\n",
      "[  0.     -34.6328] y\n",
      "[ 11.425359 -25.576622]\n",
      "[ -5.     -43.4453] y\n",
      "[ -0.35338402 -37.01941   ]\n",
      "[  0.     -38.1875] y\n",
      "[  2.5367994 -35.54191  ]\n",
      "[  0.     -35.7031] y\n",
      "[  4.2567253 -35.31551  ]\n",
      "[-10.     -47.9141] y\n",
      "[ -4.1574  -45.09903]\n",
      "[  0.     -36.4219] y\n",
      "[ -2.403121 -37.6547  ]\n",
      "[-83.45878378 -38.91072023] y\n",
      "[ 11.806228 -25.482958]\n",
      "[55.2    23.7656] y\n",
      "[24.171724 35.63598 ]\n",
      "[58.5    24.7813] y\n",
      "[49.574768 22.277548]\n",
      "[60.     26.7656] y\n",
      "[61.980534 32.34972 ]\n",
      "[57.3    23.6875] y\n",
      "[52.206726 22.419827]\n",
      "[60.     29.5703] y\n",
      "[60.34857  32.294964]\n",
      "[60.     23.8906] y\n",
      "[54.502113 24.007885]\n",
      "[  0.     -28.1328] y\n",
      "[-25.592644 -64.62435 ]\n",
      "[  0.     -36.6719] y\n",
      "[-19.41439  -38.476562]\n",
      "[  0.     -31.6172] y\n",
      "[-16.661936 -47.229527]\n",
      "[  0.     -33.1719] y\n",
      "[-17.378933 -47.45175 ]\n",
      "[  0.     -37.4531] y\n",
      "[ -3.0065455 -31.98194  ]\n",
      "[-10.     -51.4141] y\n",
      "[ -3.7179818 -45.544548 ]\n",
      "[ 20.     -24.5547] y\n",
      "[ 26.412598 -16.085796]\n",
      "[-30.     -71.5156] y\n",
      "[-26.837658 -65.92975 ]\n",
      "[-20.     -65.8281] y\n",
      "[-24.592995 -65.81575 ]\n",
      "[-15.     -59.4531] y\n",
      "[-16.87493 -56.52301]\n",
      "[ 20.     -13.8516] y\n",
      "[34.39337   -6.1299167]\n",
      "[ 25.     -13.8125] y\n",
      "[36.686443  -5.4192033]\n",
      "[ 20.     -12.9766] y\n",
      "[39.233402  -4.6298013]\n",
      "[ 20.     -12.3125] y\n",
      "[33.03377 -6.55131]\n",
      "[ 25.     -12.6094] y\n",
      "[31.830956 -6.924111]\n",
      "[ 20.     -12.7578] y\n",
      "[35.784214 -5.698839]\n",
      "[ 50.     -31.0391] y\n",
      "[ 45.824978 -21.221466]\n",
      "[ 50.     -30.5469] y\n",
      "[ 46.648365 -19.441761]\n",
      "[ 50.   -32.25] y\n",
      "[ 50.175873 -19.753155]\n",
      "[ 50.     -30.1172] y\n",
      "[ 43.39328  -18.471024]\n",
      "[ 50.     -30.0234] y\n",
      "[ 42.861435 -24.074884]\n",
      "[ 50.     -31.0156] y\n",
      "[ 46.653893 -21.336172]\n",
      "[  0.     -35.3047] y\n",
      "[  0.6386137 -35.604168 ]\n",
      "[ 15.     -21.2109] y\n",
      "[ 21.947193 -15.832577]\n",
      "[ 10.     -27.9297] y\n",
      "[ 14.314232 -25.57273 ]\n",
      "[ 10.     -23.8906] y\n",
      "[ 16.789215 -17.32331 ]\n",
      "[  0.     -35.3438] y\n",
      "[ -1.7134666 -37.440952 ]\n",
      "[  0.     -33.7422] y\n",
      "[ 12.241474 -25.375917]\n",
      "[-60.     -87.7891] y\n",
      "[-53.06996  -84.967964]\n",
      "[-60.     -89.8672] y\n",
      "[-49.114536 -83.49279 ]\n",
      "[ 30.     -48.6484] y\n",
      "[ 20.237606 -36.316856]\n",
      "[ 30.     -48.2266] y\n",
      "[ 21.10754 -35.94829]\n",
      "[ 30.     -49.6875] y\n",
      "[ 22.208778 -37.61877 ]\n",
      "[ 30. -48.] y\n",
      "[ 26.768036 -40.752335]\n",
      "[ 30.     -49.0547] y\n",
      "[ 31.117231 -40.13226 ]\n",
      "[ 30.     -47.4063] y\n",
      "[ 18.503454 -35.610462]\n",
      "[70.    -7.375] y\n",
      "[61.656303    0.21020414]\n",
      "[70.    -5.875] y\n",
      "[61.42655    2.2556539]\n",
      "[70.     -5.8516] y\n",
      "[70.76891   -1.1296653]\n",
      "[70.     -5.1641] y\n",
      "[66.16192    -0.09317786]\n",
      "[70.     -5.2031] y\n",
      "[66.20915    0.6448655]\n",
      "[70.     -5.8672] y\n",
      "[72.14372     0.16232803]\n",
      "[-11.3    -51.1016] y\n",
      "[ -6.3195195 -45.18744  ]\n",
      "[-11.9    -51.4063] y\n",
      "[-13.462734 -47.4014  ]\n",
      "[-10.     -49.8047] y\n",
      "[-12.466307 -47.674286]\n",
      "[-10.     -49.3359] y\n",
      "[ -8.700585 -45.99189 ]\n",
      "[-10.1    -49.1406] y\n",
      "[-10.486528 -46.046814]\n",
      "[-10.     -50.3359] y\n",
      "[ -6.170416 -45.178818]\n",
      "[ 50.     -31.2031] y\n",
      "[ 43.22954  -23.471252]\n",
      "[ 49.9    -32.4375] y\n",
      "[ 46.304874 -19.731665]\n",
      "[ 50.     -31.3359] y\n",
      "[ 45.929462 -21.416979]\n",
      "[ 50.     -32.1328] y\n",
      "[ 42.669724 -22.458023]\n",
      "[ 50.     -30.9531] y\n",
      "[ 46.748203 -25.361588]\n",
      "[ 50.    -31.875] y\n",
      "[ 46.71475  -20.514618]\n",
      "[-68.    -95.125] y\n",
      "[-37.35674 -59.62668]\n",
      "[-69.3    -95.5859] y\n",
      "[-27.20024  -35.491882]\n",
      "[  0.     -31.6641] y\n",
      "[  6.231941 -27.496033]\n",
      "[  0.     -31.4453] y\n",
      "[  5.9034576 -27.597843 ]\n",
      "[41.3    14.4844] y\n",
      "[42.129154 12.395783]\n",
      "[41.1    14.0391] y\n",
      "[42.022713 12.362793]\n",
      "[-110.     -151.1641] y\n",
      "[-119.96558 -147.67174]\n",
      "[-10.     -44.7266] y\n",
      "[ -6.4119487 -37.15205  ]\n",
      "[-50.     -53.3047] y\n",
      "[-50.21571  -50.052277]\n",
      "[-50.     -54.0859] y\n",
      "[-50.21571  -50.052277]\n",
      "[-250.     -251.9297] y\n",
      "[-250.21571 -250.05228]\n",
      "[-250.     -251.9297] y\n",
      "[-250.21571 -250.05228]\n",
      "[ 46.8    -32.5859] y\n",
      "[ 47.293102 -22.909336]\n",
      "[ 49.3    -34.3281] y\n",
      "[ 47.23001  -22.431974]\n",
      "[-10.     -45.5781] y\n",
      "[-11.760501 -45.71038 ]\n",
      "[-10.     -41.9063] y\n",
      "[ -8.715589 -37.866035]\n",
      "[-18.5    -46.7188] y\n",
      "[ 12.640085 -10.400578]\n",
      "[-12.1    -46.6797] y\n",
      "[  4.1930456 -41.50498  ]\n",
      "[-10.     -44.2813] y\n",
      "[  5.3198624 -31.66641  ]\n",
      "[-10.     -38.8516] y\n",
      "[ -1.8098167 -35.710636 ]\n",
      "[  0.     -27.2891] y\n",
      "[ -4.06024 -36.42316]\n",
      "[  0.    -29.625] y\n",
      "[ -8.206327 -37.7082  ]\n",
      "[  0.     -27.5156] y\n",
      "[ -3.6625001 -36.299885 ]\n",
      "[  0.     -26.4219] y\n",
      "[ -6.468878 -37.169693]\n",
      "[  0.1    -27.6328] y\n",
      "[ -9.051414 -37.523167]\n",
      "[  0.     -29.1016] y\n",
      "[ -5.1063867 -36.431534 ]\n",
      "[-11.    -46.125] y\n",
      "[-16.41558 -47.15317]\n",
      "[-16.3    -47.0078] y\n",
      "[-38.69272 -39.50465]\n",
      "[ -8.4    -37.2891] y\n",
      "[ -4.06024 -36.42316]\n",
      "[-10.    -39.625] y\n",
      "[ -8.206327 -37.7082  ]\n",
      "[ -8.9    -37.5156] y\n",
      "[ -3.6625001 -36.299885 ]\n",
      "[ -9.5    -36.4219] y\n",
      "[ -6.468878 -37.169693]\n",
      "[ -9.3    -37.6328] y\n",
      "[ -9.051414 -37.523167]\n",
      "[-10.     -39.1016] y\n",
      "[ -5.1063867 -36.431534 ]\n",
      "[-56.9    -88.1328] y\n",
      "[-25.592644 -64.62435 ]\n",
      "[-52.5    -86.6719] y\n",
      "[-19.41439  -38.476562]\n",
      "[ 50.     -30.6719] y\n",
      "[ 46.96103  -18.978306]\n",
      "[ 50.     -27.5781] y\n",
      "[ 45.77246  -19.719004]\n",
      "[-60.     -91.1641] y\n",
      "[-56.184826 -87.08165 ]\n",
      "[-60.     -92.8828] y\n",
      "[-56.83874  -87.284325]\n",
      "[-180.     -219.9844] y\n",
      "[-189.38593 -217.4921 ]\n",
      "[-250.     -251.9297] y\n",
      "[-236.53624 -248.14923]\n",
      "[-20.     -51.6172] y\n",
      "[-16.661936 -47.229527]\n",
      "[-20.     -53.1719] y\n",
      "[-17.378933 -47.45175 ]\n",
      "[-83.45878378 -38.91072023] y\n",
      "[-0.21570888 -0.05227814]\n",
      "[-2560.     0.] y\n",
      "[-2606.6663  1370.3442]\n",
      "[-2560.     0.] y\n",
      "[-2606.6663  1370.3442]\n",
      "[-2560.     0.] y\n",
      "[-2606.6663  1370.3442]\n",
      "[-2560.     0.] y\n",
      "[-2606.6663  1370.3442]\n",
      "[  0.     -31.5078] y\n",
      "[-30.154774 -75.286   ]\n",
      "[  0.     -32.6406] y\n",
      "[-44.880245 -79.588524]\n",
      "[  0.     -33.8828] y\n",
      "[-41.135185 -79.588196]\n",
      "[  0.     -30.9531] y\n",
      "[-34.976273 -79.64249 ]\n",
      "[  0.     -33.3984] y\n",
      "[-42.525574 -80.14941 ]\n",
      "[  0.     -35.1875] y\n",
      "[-28.852057 -47.39103 ]\n",
      "[-83.45878378 -38.91072023] y\n",
      "[-10.215709  -10.0522785]\n",
      "[-10.     -40.9141] y\n",
      "[ -0.67704827 -35.32509   ]\n",
      "[-19.7    -47.4844] y\n",
      "[-11.733543 -45.702026]\n",
      "[-10.     -41.7813] y\n",
      "[ -7.777197 -37.57519 ]\n",
      "[-83.45878378 -38.91072023] y\n",
      "[-1.6022646 35.17098  ]\n",
      "[-83.45878378 -38.91072023] y\n",
      "[-42.8718   -23.254282]\n",
      "[-10.8    -45.9922] y\n",
      "[-12.046514 -45.78164 ]\n",
      "[-10.   -44.75] y\n",
      "[ -4.2574406 -35.902565 ]\n",
      "[-12.5    -46.0938] y\n",
      "[-15.521897 -46.876186]\n",
      "[-19.7 -20.5] y\n",
      "[-14.209241 -18.273808]\n",
      "[-19.9    -19.5547] y\n",
      "[-22.396633 -16.248789]\n",
      "[-20.     -19.5391] y\n",
      "[-22.243084 -20.52162 ]\n",
      "[-18.2    -18.8047] y\n",
      "[-18.19037  -19.924309]\n",
      "[-19.9    -19.1484] y\n",
      "[-17.479372 -21.322363]\n",
      "[-20.     -20.5391] y\n",
      "[-22.222134 -20.533   ]\n",
      "[  0.     -35.5781] y\n",
      "[-11.760501 -45.71038 ]\n",
      "[  0.     -31.9063] y\n",
      "[ -8.715589 -37.866035]\n",
      "[  0.     -26.7188] y\n",
      "[ 12.640085 -10.400578]\n",
      "[  0.     -36.6797] y\n",
      "[  4.1930456 -41.50498  ]\n",
      "[  0.     -34.2813] y\n",
      "[  5.3198624 -31.66641  ]\n",
      "[  0.     -28.8516] y\n",
      "[ -1.8098167 -35.710636 ]\n",
      "[77.9    -4.7734] y\n",
      "[76.85415    6.4049907]\n",
      "[75.8    -5.2422] y\n",
      "[70.09558    -0.31338856]\n",
      "[-8.34587838e+01  3.12009000e-05] y\n",
      "[ 33.466736 -26.71653 ]\n",
      "[-8.34587838e+01  2.99842000e-05] y\n",
      "[ 34.16736  -27.712835]\n",
      "[-83.45878378 -38.91072023] y\n",
      "[ 41.09388  -24.259077]\n",
      "[-83.45878378 -38.91072023] y\n",
      "[ 42.41112 -22.21634]\n",
      "[70.     -6.2813] y\n",
      "[65.6957     1.7493334]\n",
      "[70.     -7.8594] y\n",
      "[69.646996  -1.8247919]\n",
      "[-8.34587838e+01  3.11882000e-05] y\n",
      "[ 41.078747 -18.611319]\n",
      "[-8.34587838e+01  3.24124000e-05] y\n",
      "[ 49.410576 -19.807562]\n",
      "[50.      3.7109] y\n",
      "[48.71347   3.463904]\n",
      "[50.     18.9063] y\n",
      "[52.401714 23.061977]\n",
      "[  0.3    -29.6797] y\n",
      "[ 10.202308 -26.265461]\n",
      "[  0.     -28.6953] y\n",
      "[ 11.3540745 -25.594154 ]\n",
      "[  0.7    -29.0469] y\n",
      "[  6.412742 -27.439997]\n",
      "[  2.8    -29.8984] y\n",
      "[  6.0285115 -28.1408   ]\n",
      "[  0.1    -31.5234] y\n",
      "[ 10.552602 -25.68139 ]\n",
      "[-20.     -58.6172] y\n",
      "[-13.431416 -54.69604 ]\n",
      "[ 10.    -20.125] y\n",
      "[ 12.899185 -17.13749 ]\n",
      "[ 10.     -22.3984] y\n",
      "[ 10.932318 -17.975164]\n",
      "[ 50.     -31.6484] y\n",
      "[ 48.168266 -23.210375]\n",
      "[ 50.     -32.3359] y\n",
      "[ 45.00898  -21.141325]\n",
      "[ 50.     -31.2969] y\n",
      "[ 44.13971  -24.471886]\n",
      "[ 48.4    -32.3516] y\n",
      "[ 48.66016  -20.280733]\n",
      "[ 50.     -33.1094] y\n",
      "[ 47.871796 -21.332787]\n",
      "[ 49.7    -32.5547] y\n",
      "[ 46.021584 -24.445644]\n",
      "[ 30. -50.] y\n",
      "[ 29.746244 -39.601086]\n",
      "[ 30. -54.] y\n",
      "[ 34.488846 -39.519047]\n",
      "[ 40. -64.] y\n",
      "[ 45.49354 -45.19433]\n",
      "[ 40. -50.] y\n",
      "[ 24.397287 -34.639004]\n",
      "[ 30. -52.] y\n",
      "[ 23.169952 -35.94847 ]\n",
      "[ 30. -66.] y\n",
      "[ 28.530828 -49.94265 ]\n",
      "[  0.    -30.125] y\n",
      "[ 12.899185 -17.13749 ]\n",
      "[  0.     -32.3984] y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 10.932318 -17.975164]\n",
      "[-25.     -59.9766] y\n",
      "[-25.412592 -58.005737]\n",
      "[-20.     -53.1953] y\n",
      "[ -6.5579796 -45.843063 ]\n",
      "[-20.     -55.5547] y\n",
      "[-19.808025 -56.512215]\n",
      "[-10.     -44.4453] y\n",
      "[ -2.462664 -37.091442]\n",
      "[-30.     -60.3516] y\n",
      "[-16.926695 -55.375626]\n",
      "[  0.     -37.5391] y\n",
      "[  2.430234 -35.786514]\n",
      "[  0.     -31.1641] y\n",
      "[-56.184826 -87.08165 ]\n",
      "[  0.     -32.8828] y\n",
      "[-56.83874  -87.284325]\n",
      "[ 0.     15.1094] y\n",
      "[51.87134  22.315878]\n",
      "[ 0.     14.7422] y\n",
      "[53.11381  22.700966]\n",
      "[  0.     -25.0859] y\n",
      "[-56.31763 -86.54109]\n",
      "[  0.     -26.8906] y\n",
      "[-56.26344 -87.10602]\n",
      "[-30.     -62.3438] y\n",
      "[-19.177454 -55.72913 ]\n",
      "[-30.     -62.5391] y\n",
      "[-22.6204   -57.140327]\n",
      "[-20.     -56.3672] y\n",
      "[-16.210928 -55.379604]\n",
      "[-20.     -57.8906] y\n",
      "[-21.078625 -57.244186]\n",
      "[-25.     -61.8125] y\n",
      "[-18.731264 -55.934933]\n",
      "[-30.     -63.2891] y\n",
      "[-17.281218 -55.485508]\n",
      "[-83.45878378 -38.91072023] y\n",
      "[ 39.878437 -18.320436]\n",
      "[-83.45878378 -38.91072023] y\n",
      "[ 46.738453 -19.985775]\n",
      "[-83.45878378 -38.91072023] y\n",
      "[ 42.61648  -19.372622]\n",
      "[-83.45878378 -38.91072023] y\n",
      "[ 40.376896 -15.742839]\n",
      "[-83.45878378 -38.91072023] y\n",
      "[ 46.146236 -20.508087]\n",
      "[-83.45878378 -38.91072023] y\n",
      "[ 41.283474 -15.854253]\n",
      "[ 40.     -36.0313] y\n",
      "[ 32.017517 -26.461561]\n",
      "[ 40.     -36.3984] y\n",
      "[ 37.856018 -30.196478]\n",
      "[ 40.     -38.7969] y\n",
      "[ 38.7209   -29.140669]\n",
      "[ 40.     -35.8047] y\n",
      "[ 32.593876 -28.950914]\n",
      "[ 40.     -38.5078] y\n",
      "[ 36.482235 -28.632992]\n",
      "[ 40.     -38.8984] y\n",
      "[ 35.083786 -28.60222 ]\n",
      "[ 50.     -30.8281] y\n",
      "[ 43.456932 -18.371717]\n",
      "[ 50.     -31.0547] y\n",
      "[ 46.08095 -21.01002]\n",
      "[ 50.     -30.2813] y\n",
      "[ 47.176243 -18.948921]\n",
      "[ 50.     -29.5547] y\n",
      "[ 36.57422  -18.031742]\n",
      "[ 50.     -29.4063] y\n",
      "[ 47.4286   -19.532215]\n",
      "[ 50.     -28.5625] y\n",
      "[ 38.058704 -17.898376]\n",
      "[-35.     -72.8828] y\n",
      "[-23.735315 -64.38649 ]\n",
      "[-30.     -69.6484] y\n",
      "[-33.652683 -67.46027 ]\n",
      "[-35.     -72.7188] y\n",
      "[-33.40375 -67.38312]\n",
      "[-35.     -72.0938] y\n",
      "[-26.16209 -65.36759]\n",
      "[-35.     -70.0625] y\n",
      "[-26.903366 -65.36839 ]\n",
      "[-35.     -70.9688] y\n",
      "[-23.269098 -63.65868 ]\n",
      "[ 10.     -17.8281] y\n",
      "[ 11.896692 -17.676266]\n",
      "[ 10.     -20.0469] y\n",
      "[ 12.6525545 -17.441996 ]\n",
      "[50.     20.1094] y\n",
      "[51.87134  22.315878]\n",
      "[50.     19.7422] y\n",
      "[53.11381  22.700966]\n",
      "[-2560.     0.] y\n",
      "[-2606.6663  1370.3442]\n",
      "[-2560.     0.] y\n",
      "[-2606.6663  1370.3442]\n",
      "[  0.    -35.125] y\n",
      "[-37.35674 -59.62668]\n",
      "[  0.     -35.5859] y\n",
      "[-27.20024  -35.491882]\n",
      "[90.     58.1484] y\n",
      "[100.1511  64.11  ]\n",
      "[95.     58.0469] y\n",
      "[100.79872   63.545498]\n",
      "[95.     59.6563] y\n",
      "[100.12382   63.710213]\n",
      "[90.     56.2266] y\n",
      "[96.73764 62.6607 ]\n",
      "[90.     59.3281] y\n",
      "[103.94955  64.31424]\n",
      "[95.     57.6875] y\n",
      "[101.960686  64.913   ]\n",
      "[-83.45878378 -38.91072023] y\n",
      "[-22.671482 -41.172565]\n",
      "[-83.45878378 -38.91072023] y\n",
      "[-0.21570888 -0.05227814]\n",
      "[-83.45878378 -38.91072023] y\n",
      "[-0.21570888 -0.05227814]\n",
      "[-83.45878378 -38.91072023] y\n",
      "[54.76097  16.148203]\n",
      "[-83.45878378 -38.91072023] y\n",
      "[ 39.85805 -59.21962]\n",
      "[-83.45878378 -38.91072023] y\n",
      "[-0.21570888 -0.05227814]\n",
      "[-83.45878378 -38.91072023] y\n",
      "[-0.21570888 -0.05227814]\n",
      "[-83.45878378 -38.91072023] y\n",
      "[-80.9176   67.40938]\n",
      "[-83.45878378 -38.91072023] y\n",
      "[-0.21570888 -0.05227814]\n",
      "[  0.     -31.5078] y\n",
      "[-30.154774 -75.286   ]\n",
      "[  0.     -32.6406] y\n",
      "[-44.880245 -79.588524]\n",
      "[  0.     -33.8828] y\n",
      "[-41.135185 -79.588196]\n",
      "[  0.     -30.9531] y\n",
      "[-34.976273 -79.64249 ]\n",
      "[  0.     -33.3984] y\n",
      "[-42.525574 -80.14941 ]\n",
      "[  0.     -35.1875] y\n",
      "[-28.852057 -47.39103 ]\n",
      "[-30.     -65.5234] y\n",
      "[-30.6678  -66.53514]\n",
      "[-30.     -64.0234] y\n",
      "[-14.290004 -54.55841 ]\n",
      "[-30.     -63.6328] y\n",
      "[-17.720482 -55.039936]\n",
      "[-30.     -64.7813] y\n",
      "[-14.809418 -54.31564 ]\n",
      "[-30.     -64.5938] y\n",
      "[-16.819626 -54.760723]\n",
      "[-30.     -64.8359] y\n",
      "[-21.166746 -56.689785]\n",
      "[  0.     -32.0313] y\n",
      "[ -6.0352774 -37.0353   ]\n",
      "[  0.     -35.0469] y\n",
      "[-16.390625 -47.727158]\n",
      "[-2560.     0.] y\n",
      "[-2606.6663  1370.3442]\n",
      "[-2560.     0.] y\n",
      "[-2606.6663  1370.3442]\n",
      "[-2560.     0.] y\n",
      "[-2606.6663  1370.3442]\n",
      "[-2560.     0.] y\n",
      "[-2606.6663  1370.3442]\n",
      "[-2560.     0.] y\n",
      "[-2606.6663  1370.3442]\n",
      "[-2560.     0.] y\n",
      "[-2606.6663  1370.3442]\n",
      "[  0.     -37.4531] y\n",
      "[ -3.0065455 -31.98194  ]\n",
      "[-10.     -51.4141] y\n",
      "[ -3.7179818 -45.544548 ]\n",
      "[ 20.     -24.5547] y\n",
      "[ 26.412598 -16.085796]\n",
      "[-30.     -71.5156] y\n",
      "[-26.837658 -65.92975 ]\n",
      "[-20.     -65.8281] y\n",
      "[-24.592995 -65.81575 ]\n",
      "[-15.     -59.4531] y\n",
      "[-16.87493 -56.52301]\n",
      "[  0.     -32.7266] y\n",
      "[  0.84956867 -28.000813  ]\n",
      "[  0.     -34.1641] y\n",
      "[  1.0489869 -27.083923 ]\n",
      "[  0.     -26.3828] y\n",
      "[  8.888933 -30.742632]\n",
      "[  0.     -33.7344] y\n",
      "[  6.712221 -25.602028]\n",
      "[  0.     -29.6953] y\n",
      "[ 28.841417 -22.093328]\n",
      "[  0.     -33.5547] y\n",
      "[  7.980255 -22.32374 ]\n",
      "[  0.     -32.7266] y\n",
      "[  0.84956867 -28.000813  ]\n",
      "[ -0.3    -34.1641] y\n",
      "[  1.0489869 -27.083923 ]\n",
      "[-83.45878378 -38.91072023] y\n",
      "[-0.21570888 -0.05227814]\n",
      "[ -9.4    -36.3828] y\n",
      "[  8.888933 -30.742632]\n",
      "[  0.     -33.7344] y\n",
      "[  6.712221 -25.602028]\n",
      "[  0.     -29.6953] y\n",
      "[ 28.841417 -22.093328]\n",
      "[ -2.2    -33.5547] y\n",
      "[  7.980255 -22.32374 ]\n",
      "[-10.     -12.4766] y\n",
      "[-10.215709  -10.0522785]\n",
      "[-10.     -11.8594] y\n",
      "[-10.215709  -10.0522785]\n",
      "[  0.     -32.7656] y\n",
      "[ 14.33269  -24.985292]\n",
      "[  0.     -32.6406] y\n",
      "[ 12.726557 -25.25662 ]\n",
      "[  0.     -33.6016] y\n",
      "[ 13.132934 -25.357143]\n",
      "[  0.     -31.1172] y\n",
      "[ 12.035208 -25.426641]\n",
      "[  0.     -32.1797] y\n",
      "[  6.0985994 -27.537361 ]\n",
      "[  0.     -34.4844] y\n",
      "[  6.323268 -27.467728]\n",
      "[50.     17.2813] y\n",
      "[50.20587  22.381397]\n",
      "[40.     11.0469] y\n",
      "[40.206585  12.3816185]\n",
      "[-250.     -251.9297] y\n",
      "[-253.87671 -236.59178]\n",
      "[-228.9    -251.9297] y\n",
      "[-207.33257 -239.91368]\n",
      "[-60.     -85.0859] y\n",
      "[-56.31763 -86.54109]\n",
      "[-60.     -86.8906] y\n",
      "[-56.26344 -87.10602]\n",
      "[-10.     -42.0313] y\n",
      "[ -6.0352774 -37.0353   ]\n",
      "[-10.     -45.0469] y\n",
      "[-16.390625 -47.727158]\n",
      "[  0.     -33.6016] y\n",
      "[ 13.726618 -25.173138]\n",
      "[  0.     -36.9688] y\n",
      "[  4.0224504 -35.663162 ]\n",
      "[  0.     -33.8203] y\n",
      "[  6.156106 -27.519539]\n",
      "[  0.     -32.1953] y\n",
      "[ 11.583385 -25.5716  ]\n",
      "[  0.     -32.8438] y\n",
      "[ 11.178958 -25.63722 ]\n",
      "[  0.     -34.6172] y\n",
      "[  6.5043955 -27.411589 ]\n",
      "[-60.     -91.5078] y\n",
      "[-30.154774 -75.286   ]\n",
      "[-60.     -92.6406] y\n",
      "[-44.880245 -79.588524]\n",
      "[-60.     -93.8828] y\n",
      "[-41.135185 -79.588196]\n",
      "[-60.     -90.9531] y\n",
      "[-34.976273 -79.64249 ]\n",
      "[-60.     -93.3984] y\n",
      "[-42.525574 -80.14941 ]\n",
      "[-60.     -95.1875] y\n",
      "[-28.852057 -47.39103 ]\n",
      "[ 0.     -2.3359] y\n",
      "[-0.21570888 -0.05227814]\n",
      "[ 0.     -2.3359] y\n",
      "[-0.21570888 -0.05227814]\n",
      "[ 0.     -2.4609] y\n",
      "[-0.21570888 -0.05227814]\n",
      "[ 0.     -2.2734] y\n",
      "[-0.21570888 -0.05227814]\n",
      "[ 0.     -2.5781] y\n",
      "[-0.21570888 -0.05227814]\n",
      "[ 0.     -2.2188] y\n",
      "[-0.21570888 -0.05227814]\n",
      "[ 0.     29.7656] y\n",
      "[24.171724 35.63598 ]\n",
      "[ 0.     30.7813] y\n",
      "[49.574768 22.277548]\n",
      "[ 0.     32.7656] y\n",
      "[61.980534 32.34972 ]\n",
      "[ 0.     29.6875] y\n",
      "[52.206726 22.419827]\n",
      "[ 0.     35.5703] y\n",
      "[60.34857  32.294964]\n",
      "[ 0.     29.8906] y\n",
      "[54.502113 24.007885]\n",
      "[ -70.     -102.1719] y\n",
      "[-69.328606 -97.47432 ]\n",
      "[ -70.     -102.4531] y\n",
      "[-67.37146 -97.44943]\n",
      "[  0.     -32.0469] y\n",
      "[ 13.081801 -25.372992]\n",
      "[  0.     -31.3438] y\n",
      "[  5.830267 -27.620527]\n",
      "[  0.     -32.2734] y\n",
      "[  5.527613 -27.714334]\n",
      "[  0.     -34.4922] y\n",
      "[  9.710149 -25.658459]\n",
      "[  0.     -33.1953] y\n",
      "[ 11.9971075 -25.436014 ]\n",
      "[  0.     -31.2969] y\n",
      "[ 12.405205 -25.719938]\n",
      "[-190.     -219.1484] y\n",
      "[-187.96472 -217.05159]\n",
      "[-190.     -219.7422] y\n",
      "[-188.47774 -217.21059]\n",
      "[40.9    13.4922] y\n",
      "[44.40078  13.099849]\n",
      "[40.8    14.5469] y\n",
      "[41.563732 12.220536]\n",
      "[  0.     -33.7969] y\n",
      "[  5.578215 -27.69865 ]\n",
      "[  0.     -31.8281] y\n",
      "[ 12.947884 -25.414497]\n",
      "[  0.     -31.5078] y\n",
      "[  6.076829 -27.54411 ]\n",
      "[  0.     -33.8984] y\n",
      "[ 14.149285 -25.04214 ]\n",
      "[  0.     -31.3359] y\n",
      "[ 12.166372 -25.394386]\n",
      "[  0.     -31.7031] y\n",
      "[ 11.817515 -25.48018 ]\n",
      "[-250.     -251.9297] y\n",
      "[-245.0585  -249.63187]\n",
      "[-240.     -251.9297] y\n",
      "[-226.20253 -247.85968]\n",
      "[-10.     -10.9453] y\n",
      "[-10.215709  -10.0522785]\n",
      "[-10.     -11.8672] y\n",
      "[-10.215709  -10.0522785]\n",
      "[ 50.     -31.3047] y\n",
      "[ 46.717354 -23.309061]\n",
      "[ 49.7    -32.6875] y\n",
      "[ 50.12376  -22.678535]\n",
      "[ 30.     -49.0391] y\n",
      "[ 24.275764 -36.624744]\n",
      "[ 30.     -50.2969] y\n",
      "[ 23.01121  -37.798904]\n",
      "[ 40.2    -34.2891] y\n",
      "[ 45.510822 -23.024189]\n",
      "[ 41.1    -35.8047] y\n",
      "[ 34.67464  -27.834385]\n",
      "[ 50.     -28.7578] y\n",
      "[ 44.56543  -19.659935]\n",
      "[ 50.     -27.4766] y\n",
      "[ 45.689922 -20.506975]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X1 = input_1_arr[:,0:10000]*1000\n",
    "Y1 = input_1_arr[:,10000:10004]\n",
    "\n",
    "X=X1\n",
    "Y=Y1[:,2:4]\n",
    "# print(Y)\n",
    "Y_new = np.zeros((Y.shape[0],2))\n",
    "for i in range(len(Y)):\n",
    "  \n",
    "    print(Y[i],\"y\")\n",
    "  \n",
    "\n",
    "    X_t= X[i].transpose()\n",
    "\n",
    "    scaler_rob_x = MinMaxScaler().fit((X_t.reshape(-1, 1)))\n",
    "                        \n",
    "    Xi = (scaler_rob_x.transform(X_t.reshape(-1, 1)))\n",
    "\n",
    "    I = factor_fit.transform(Xi.transpose())\n",
    "\n",
    "    pred = model.predict(I)\n",
    "\n",
    "  \n",
    "    Y_ti =Y[i].transpose()\n",
    "\n",
    "#     scaler_rob_y = RobustScaler().fit(Y_ti.reshape(-1, 1))\n",
    "    final_t = scaler_rob_x.inverse_transform(pred.reshape(-1, 1))\n",
    "                                          \n",
    "\n",
    "    final = final_t.transpose()\n",
    "                                          \n",
    "    print(final[0])\n",
    "\n",
    "    h = abs(final-Y[i])\n",
    "#   print(h,\"h\")\n",
    "#     o=np.divide(h,Y[i])\n",
    "#   print(o*100,\"percentage\") \n",
    "  \n",
    "    Y_new[i]=final[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "oTEoOJ1WjJ9T",
    "outputId": "183b55c6-fbfe-4a6e-f2fe-a201c83249d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.0 13.369383811950684\n",
      "0.9946503499937274 -26.593061462686553\n"
     ]
    }
   ],
   "source": [
    "X1 = X1\n",
    "Y1 = Y1\n",
    "# print(Y1)\n",
    "\n",
    "# print(Y)\n",
    "from sklearn.metrics import r2_score\n",
    "print(Y1[0,2], Y_new[0,0])\n",
    "# print(Y_new[:,0])\n",
    "g = r2_score(Y1[:,2], Y_new[:,0])  \n",
    "g1 = r2_score(Y1[:,3], Y_new[:,1]) \n",
    "print(g,g1)\n",
    "Y1[:,2]= Y_new[:,0]\n",
    "Y1[:,3]= Y_new[:,1]\n",
    "# print(Y1[0,2], Y_new[0,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "-z59fc0rjqqp",
    "outputId": "6c9f781f-ff8a-4fb8-b8e7-126262f4b607"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(397, 10002)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X1_new = np.concatenate((X1,Y1[:,2:4]),axis=1)\n",
    "print(X1_new.shape)\n",
    "Y1_new = Y1[:,0:2]\n",
    "# print(Y1_new)\n",
    "# X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(X1_new, Y1_new, test_size=0.20)\n",
    "X_train_c= X1_new\n",
    "y_train_c = Y1_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w18N-Ahtj3zL"
   },
   "outputs": [],
   "source": [
    "#standardise\n",
    "\n",
    "\n",
    "# ######minmax\n",
    "scaler_min_x = MinMaxScaler().fit(X_train_c)\n",
    "scaler_min_y = MinMaxScaler().fit(y_train_c)\n",
    "\n",
    "X_minmax_train = scaler_min_x.transform(X_train_c)\n",
    "Y_minmax_train = scaler_min_y.transform(y_train_c)\n",
    "\n",
    "\n",
    "# print(X)\n",
    "# print(Y)\n",
    "#####standard\n",
    "\n",
    "scaler_stan_x = StandardScaler().fit(X_train_c)\n",
    "scaler_stan_y = StandardScaler().fit(y_train_c)\n",
    "\n",
    "\n",
    "X_stan_train = scaler_stan_x.transform(X_train_c)\n",
    "Y_stan_train = scaler_stan_y.transform(y_train_c)\n",
    "\n",
    "# #######normlised\n",
    "# scaler_norm_x = Normalizer().fit(X_train_c)\n",
    "# scaler_norm_y = Normalizer().fit(y_train_c)\n",
    "\n",
    "\n",
    "# X_norm_train = scaler_norm_x.transform(X_train_c)\n",
    "# Y_norm_train = scaler_norm_y.transform(y_train_c)\n",
    "\n",
    "\n",
    "# # ################qt\n",
    "\n",
    "# scaler_qt_x =  QuantileTransformer(output_distribution='normal').fit(X_train_c)\n",
    "# scaler_qt_y =  QuantileTransformer(output_distribution='normal').fit(y_train_c)\n",
    "\n",
    "\n",
    "# X_qt_train = scaler_qt_x.transform(X_train_c)\n",
    "# Y_qt_train = scaler_qt_y.transform(y_train_c)\n",
    "\n",
    "\n",
    "##robust\n",
    "# print(X_train.shape)\n",
    "# print(y_train.shape)\n",
    "# X_train_t = X_train.transpose()\n",
    "# y_train_t = y_train.transpose()\n",
    "# print(X_train.shape,\"after\")\n",
    "# print(y_train.shape,\"after\")\n",
    "scaler_rob_x = MinMaxScaler().fit(X_train_c)\n",
    "scaler_rob_y = MinMaxScaler().fit(y_train_c)\n",
    "\n",
    "\n",
    "# X_rob_train = scaler_rob_x.transform(X_train_c)\n",
    "# Y_rob_train = scaler_rob_y.transform(y_train_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gp-_qNnYplqA"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(scaler_rob_x, open( \"./app/MODEL/scaler_rob_x_1_OFF.pkl\", \"wb\" ) )\n",
    "pickle.dump(scaler_rob_y, open( \"./app/MODEL/scaler_rob_y_1_OFF.pkl\", \"wb\" ) )\n",
    "X_rob_train_c = scaler_rob_x.transform(X_train_c)\n",
    "Y_rob_train_c = scaler_rob_y.transform(y_train_c)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "7CFgOiZdkHbW",
    "outputId": "cc05189c-42ff-4c34-c3e2-5632f0ea9bcb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(397, 30)\n",
      "(397, 32)\n"
     ]
    }
   ],
   "source": [
    "#apply PCA on X1_new\n",
    "transformer = FactorAnalysis(n_components=30, random_state=0)\n",
    "factor_fit = transformer.fit(X_rob_train_c[:,0:10000])\n",
    "X_new1 = factor_fit.transform(X_rob_train_c[:,0:10000])\n",
    "print(X_new1.shape)\n",
    "X_new1 = np.concatenate((X_new1,X_rob_train_c[:,10000:10002]),axis=1)\n",
    "print(X_new1.shape)\n",
    "# print((X_rob_train[:,0:10000].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d7y6ga_Ap3xd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tk0ehMK0psFc"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(factor_fit, open( \"./app/MODEL/factor_fit_1_OFF.pkl\", \"wb\" ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l-vIsEvckQiI"
   },
   "outputs": [],
   "source": [
    "def baseline_model_31(optimizer='adam'):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(30, activation='relu', \n",
    "                    kernel_initializer = 'he_normal', \n",
    "                    input_shape=(32,)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "#     model.add(Dense(30, activation='relu',\n",
    "#                     kernel_initializer = 'he_normal'))\n",
    "#       model.add(BatchNormalization())\n",
    "#     model.add(Dropout(0.5))\n",
    "    model.add(Dense(12, activation='relu',\n",
    "                    kernel_initializer = 'he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "#     model.add(Dropout(0.5))\n",
    "    model.add(Dense(9, activation='relu',\n",
    "                    kernel_initializer = 'he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "#     model.add(Dropout(0.5))\n",
    "    model.add(Dense(2, activation='linear', \n",
    "                    kernel_initializer='he_normal'))\n",
    "    model.compile(loss = 'mse', optimizer=optimizer, metrics=['mae'])\n",
    "#     model.summary()\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "nXZHDnp-kTGe",
    "outputId": "fa1ed4a9-2620-4af9-b2b6-9fb859f265e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Epoch 1/400\n",
      "397/397 [==============================] - 1s 2ms/step - loss: 1.1849 - mean_absolute_error: 0.8655\n",
      "Epoch 2/400\n",
      "397/397 [==============================] - 0s 332us/step - loss: 0.7079 - mean_absolute_error: 0.6745\n",
      "Epoch 3/400\n",
      "397/397 [==============================] - 0s 343us/step - loss: 0.5185 - mean_absolute_error: 0.5720\n",
      "Epoch 4/400\n",
      "397/397 [==============================] - 0s 331us/step - loss: 0.4028 - mean_absolute_error: 0.5144\n",
      "Epoch 5/400\n",
      "397/397 [==============================] - 0s 334us/step - loss: 0.3174 - mean_absolute_error: 0.4416\n",
      "Epoch 6/400\n",
      "397/397 [==============================] - 0s 330us/step - loss: 0.2381 - mean_absolute_error: 0.3884\n",
      "Epoch 7/400\n",
      "397/397 [==============================] - 0s 337us/step - loss: 0.2157 - mean_absolute_error: 0.3715\n",
      "Epoch 8/400\n",
      "397/397 [==============================] - 0s 336us/step - loss: 0.1986 - mean_absolute_error: 0.3523\n",
      "Epoch 9/400\n",
      "397/397 [==============================] - 0s 337us/step - loss: 0.1804 - mean_absolute_error: 0.3377\n",
      "Epoch 10/400\n",
      "397/397 [==============================] - 0s 334us/step - loss: 0.1358 - mean_absolute_error: 0.2924\n",
      "Epoch 11/400\n",
      "397/397 [==============================] - 0s 339us/step - loss: 0.1339 - mean_absolute_error: 0.2906\n",
      "Epoch 12/400\n",
      "397/397 [==============================] - 0s 334us/step - loss: 0.1293 - mean_absolute_error: 0.2820\n",
      "Epoch 13/400\n",
      "397/397 [==============================] - 0s 337us/step - loss: 0.1049 - mean_absolute_error: 0.2528\n",
      "Epoch 14/400\n",
      "397/397 [==============================] - 0s 335us/step - loss: 0.1070 - mean_absolute_error: 0.2540\n",
      "Epoch 15/400\n",
      "397/397 [==============================] - 0s 340us/step - loss: 0.0943 - mean_absolute_error: 0.2344\n",
      "Epoch 16/400\n",
      "397/397 [==============================] - 0s 335us/step - loss: 0.0845 - mean_absolute_error: 0.2257\n",
      "Epoch 17/400\n",
      "397/397 [==============================] - 0s 335us/step - loss: 0.0813 - mean_absolute_error: 0.2215\n",
      "Epoch 18/400\n",
      "397/397 [==============================] - 0s 339us/step - loss: 0.0797 - mean_absolute_error: 0.2143\n",
      "Epoch 19/400\n",
      "397/397 [==============================] - 0s 334us/step - loss: 0.0709 - mean_absolute_error: 0.2014\n",
      "Epoch 20/400\n",
      "397/397 [==============================] - 0s 334us/step - loss: 0.0707 - mean_absolute_error: 0.2038\n",
      "Epoch 21/400\n",
      "397/397 [==============================] - 0s 342us/step - loss: 0.0682 - mean_absolute_error: 0.2011\n",
      "Epoch 22/400\n",
      "397/397 [==============================] - 0s 336us/step - loss: 0.0680 - mean_absolute_error: 0.1961\n",
      "Epoch 23/400\n",
      "397/397 [==============================] - 0s 335us/step - loss: 0.0646 - mean_absolute_error: 0.1914\n",
      "Epoch 24/400\n",
      "397/397 [==============================] - 0s 336us/step - loss: 0.0587 - mean_absolute_error: 0.1829\n",
      "Epoch 25/400\n",
      "397/397 [==============================] - 0s 340us/step - loss: 0.0607 - mean_absolute_error: 0.1865\n",
      "Epoch 26/400\n",
      "397/397 [==============================] - 0s 337us/step - loss: 0.0633 - mean_absolute_error: 0.1875\n",
      "Epoch 27/400\n",
      "397/397 [==============================] - 0s 339us/step - loss: 0.0625 - mean_absolute_error: 0.1837\n",
      "Epoch 28/400\n",
      "397/397 [==============================] - 0s 335us/step - loss: 0.0569 - mean_absolute_error: 0.1771\n",
      "Epoch 29/400\n",
      "397/397 [==============================] - 0s 335us/step - loss: 0.0583 - mean_absolute_error: 0.1771\n",
      "Epoch 30/400\n",
      "397/397 [==============================] - 0s 335us/step - loss: 0.0524 - mean_absolute_error: 0.1680\n",
      "Epoch 31/400\n",
      "397/397 [==============================] - 0s 354us/step - loss: 0.0544 - mean_absolute_error: 0.1682\n",
      "Epoch 32/400\n",
      "397/397 [==============================] - 0s 336us/step - loss: 0.0578 - mean_absolute_error: 0.1717\n",
      "Epoch 33/400\n",
      "397/397 [==============================] - 0s 352us/step - loss: 0.0541 - mean_absolute_error: 0.1679\n",
      "Epoch 34/400\n",
      "397/397 [==============================] - 0s 334us/step - loss: 0.0486 - mean_absolute_error: 0.1576\n",
      "Epoch 35/400\n",
      "397/397 [==============================] - 0s 338us/step - loss: 0.0525 - mean_absolute_error: 0.1660\n",
      "Epoch 36/400\n",
      "397/397 [==============================] - 0s 335us/step - loss: 0.0507 - mean_absolute_error: 0.1579\n",
      "Epoch 37/400\n",
      "397/397 [==============================] - 0s 335us/step - loss: 0.0506 - mean_absolute_error: 0.1580\n",
      "Epoch 38/400\n",
      "397/397 [==============================] - 0s 338us/step - loss: 0.0501 - mean_absolute_error: 0.1563\n",
      "Epoch 39/400\n",
      "397/397 [==============================] - 0s 339us/step - loss: 0.0468 - mean_absolute_error: 0.1500\n",
      "Epoch 40/400\n",
      "397/397 [==============================] - 0s 330us/step - loss: 0.0483 - mean_absolute_error: 0.1536\n",
      "Epoch 41/400\n",
      "397/397 [==============================] - 0s 342us/step - loss: 0.0482 - mean_absolute_error: 0.1519\n",
      "Epoch 42/400\n",
      "397/397 [==============================] - 0s 336us/step - loss: 0.0494 - mean_absolute_error: 0.1519\n",
      "Epoch 43/400\n",
      "397/397 [==============================] - 0s 336us/step - loss: 0.0481 - mean_absolute_error: 0.1507\n",
      "Epoch 44/400\n",
      "397/397 [==============================] - 0s 336us/step - loss: 0.0492 - mean_absolute_error: 0.1503\n",
      "Epoch 45/400\n",
      "397/397 [==============================] - 0s 335us/step - loss: 0.0478 - mean_absolute_error: 0.1484\n",
      "Epoch 46/400\n",
      "397/397 [==============================] - 0s 336us/step - loss: 0.0478 - mean_absolute_error: 0.1472\n",
      "Epoch 47/400\n",
      "397/397 [==============================] - 0s 337us/step - loss: 0.0495 - mean_absolute_error: 0.1492\n",
      "Epoch 48/400\n",
      "397/397 [==============================] - 0s 337us/step - loss: 0.0486 - mean_absolute_error: 0.1500\n",
      "Epoch 49/400\n",
      "397/397 [==============================] - 0s 336us/step - loss: 0.0469 - mean_absolute_error: 0.1448\n",
      "Epoch 50/400\n",
      "397/397 [==============================] - 0s 335us/step - loss: 0.0479 - mean_absolute_error: 0.1462\n",
      "Epoch 51/400\n",
      "397/397 [==============================] - 0s 338us/step - loss: 0.0467 - mean_absolute_error: 0.1441\n",
      "Epoch 52/400\n",
      "397/397 [==============================] - 0s 337us/step - loss: 0.0462 - mean_absolute_error: 0.1426\n",
      "Epoch 53/400\n",
      "397/397 [==============================] - 0s 335us/step - loss: 0.0450 - mean_absolute_error: 0.1410\n",
      "Epoch 54/400\n",
      "397/397 [==============================] - 0s 331us/step - loss: 0.0450 - mean_absolute_error: 0.1413\n",
      "Epoch 55/400\n",
      "397/397 [==============================] - 0s 332us/step - loss: 0.0469 - mean_absolute_error: 0.1436\n",
      "Epoch 56/400\n",
      "397/397 [==============================] - 0s 345us/step - loss: 0.0449 - mean_absolute_error: 0.1410\n",
      "Epoch 57/400\n",
      "397/397 [==============================] - 0s 337us/step - loss: 0.0449 - mean_absolute_error: 0.1403\n",
      "Epoch 58/400\n",
      "397/397 [==============================] - 0s 335us/step - loss: 0.0472 - mean_absolute_error: 0.1411\n",
      "Epoch 59/400\n",
      "397/397 [==============================] - 0s 332us/step - loss: 0.0457 - mean_absolute_error: 0.1398\n",
      "Epoch 60/400\n",
      "397/397 [==============================] - 0s 338us/step - loss: 0.0459 - mean_absolute_error: 0.1401\n",
      "Epoch 61/400\n",
      "397/397 [==============================] - 0s 343us/step - loss: 0.0470 - mean_absolute_error: 0.1388\n",
      "Epoch 62/400\n",
      "397/397 [==============================] - 0s 374us/step - loss: 0.0462 - mean_absolute_error: 0.1397\n",
      "Epoch 63/400\n",
      "397/397 [==============================] - 0s 334us/step - loss: 0.0463 - mean_absolute_error: 0.1403\n",
      "Epoch 64/400\n",
      "397/397 [==============================] - 0s 333us/step - loss: 0.0430 - mean_absolute_error: 0.1332\n",
      "Epoch 65/400\n",
      "397/397 [==============================] - 0s 339us/step - loss: 0.0455 - mean_absolute_error: 0.1373\n",
      "Epoch 66/400\n",
      "397/397 [==============================] - 0s 331us/step - loss: 0.0457 - mean_absolute_error: 0.1370\n",
      "Epoch 67/400\n",
      "397/397 [==============================] - 0s 332us/step - loss: 0.0434 - mean_absolute_error: 0.1322\n",
      "Epoch 68/400\n",
      "397/397 [==============================] - 0s 358us/step - loss: 0.0449 - mean_absolute_error: 0.1350\n",
      "Epoch 69/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "397/397 [==============================] - 0s 336us/step - loss: 0.0431 - mean_absolute_error: 0.1319\n",
      "Epoch 70/400\n",
      "397/397 [==============================] - 0s 332us/step - loss: 0.0445 - mean_absolute_error: 0.1344\n",
      "Epoch 71/400\n",
      "397/397 [==============================] - 0s 334us/step - loss: 0.0438 - mean_absolute_error: 0.1329\n",
      "Epoch 72/400\n",
      "397/397 [==============================] - 0s 329us/step - loss: 0.0420 - mean_absolute_error: 0.1283\n",
      "Epoch 73/400\n",
      "397/397 [==============================] - 0s 331us/step - loss: 0.0429 - mean_absolute_error: 0.1322\n",
      "Epoch 74/400\n",
      "397/397 [==============================] - 0s 333us/step - loss: 0.0435 - mean_absolute_error: 0.1314\n",
      "Epoch 75/400\n",
      "397/397 [==============================] - 0s 339us/step - loss: 0.0443 - mean_absolute_error: 0.1332\n",
      "Epoch 76/400\n",
      "397/397 [==============================] - 0s 347us/step - loss: 0.0444 - mean_absolute_error: 0.1359\n",
      "Epoch 77/400\n",
      "397/397 [==============================] - 0s 354us/step - loss: 0.0434 - mean_absolute_error: 0.1302\n",
      "Epoch 78/400\n",
      "397/397 [==============================] - 0s 349us/step - loss: 0.0429 - mean_absolute_error: 0.1314\n",
      "Epoch 79/400\n",
      "397/397 [==============================] - 0s 347us/step - loss: 0.0408 - mean_absolute_error: 0.1260\n",
      "Epoch 80/400\n",
      "397/397 [==============================] - 0s 349us/step - loss: 0.0398 - mean_absolute_error: 0.1245\n",
      "Epoch 81/400\n",
      "397/397 [==============================] - 0s 358us/step - loss: 0.0434 - mean_absolute_error: 0.1281\n",
      "Epoch 82/400\n",
      "397/397 [==============================] - 0s 367us/step - loss: 0.0390 - mean_absolute_error: 0.1201\n",
      "Epoch 83/400\n",
      "397/397 [==============================] - 0s 371us/step - loss: 0.0424 - mean_absolute_error: 0.1275\n",
      "Epoch 84/400\n",
      "397/397 [==============================] - 0s 378us/step - loss: 0.0431 - mean_absolute_error: 0.1301\n",
      "Epoch 85/400\n",
      "397/397 [==============================] - 0s 371us/step - loss: 0.0417 - mean_absolute_error: 0.1232\n",
      "Epoch 86/400\n",
      "397/397 [==============================] - 0s 374us/step - loss: 0.0399 - mean_absolute_error: 0.1233\n",
      "Epoch 87/400\n",
      "397/397 [==============================] - 0s 370us/step - loss: 0.0423 - mean_absolute_error: 0.1272\n",
      "Epoch 88/400\n",
      "397/397 [==============================] - 0s 370us/step - loss: 0.0413 - mean_absolute_error: 0.1223\n",
      "Epoch 89/400\n",
      "397/397 [==============================] - 0s 387us/step - loss: 0.0433 - mean_absolute_error: 0.1273\n",
      "Epoch 90/400\n",
      "397/397 [==============================] - 0s 402us/step - loss: 0.0411 - mean_absolute_error: 0.1243\n",
      "Epoch 91/400\n",
      "397/397 [==============================] - 0s 400us/step - loss: 0.0431 - mean_absolute_error: 0.1263\n",
      "Epoch 92/400\n",
      "397/397 [==============================] - 0s 405us/step - loss: 0.0414 - mean_absolute_error: 0.1259\n",
      "Epoch 93/400\n",
      "397/397 [==============================] - 0s 445us/step - loss: 0.0407 - mean_absolute_error: 0.1233\n",
      "Epoch 94/400\n",
      "397/397 [==============================] - 0s 398us/step - loss: 0.0415 - mean_absolute_error: 0.1235\n",
      "Epoch 95/400\n",
      "397/397 [==============================] - 0s 429us/step - loss: 0.0425 - mean_absolute_error: 0.1235\n",
      "Epoch 96/400\n",
      "397/397 [==============================] - 0s 420us/step - loss: 0.0400 - mean_absolute_error: 0.1239\n",
      "Epoch 97/400\n",
      "397/397 [==============================] - 0s 414us/step - loss: 0.0404 - mean_absolute_error: 0.1223\n",
      "Epoch 98/400\n",
      "397/397 [==============================] - 0s 417us/step - loss: 0.0395 - mean_absolute_error: 0.1201\n",
      "Epoch 99/400\n",
      "397/397 [==============================] - 0s 416us/step - loss: 0.0412 - mean_absolute_error: 0.1228\n",
      "Epoch 100/400\n",
      "397/397 [==============================] - 0s 415us/step - loss: 0.0381 - mean_absolute_error: 0.1180\n",
      "Epoch 101/400\n",
      "397/397 [==============================] - 0s 424us/step - loss: 0.0414 - mean_absolute_error: 0.1199\n",
      "Epoch 102/400\n",
      "397/397 [==============================] - 0s 432us/step - loss: 0.0398 - mean_absolute_error: 0.1209\n",
      "Epoch 103/400\n",
      "397/397 [==============================] - 0s 451us/step - loss: 0.0402 - mean_absolute_error: 0.1201\n",
      "Epoch 104/400\n",
      "397/397 [==============================] - 0s 440us/step - loss: 0.0387 - mean_absolute_error: 0.1177\n",
      "Epoch 105/400\n",
      "397/397 [==============================] - 0s 434us/step - loss: 0.0417 - mean_absolute_error: 0.1210\n",
      "Epoch 106/400\n",
      "397/397 [==============================] - 0s 430us/step - loss: 0.0407 - mean_absolute_error: 0.1203\n",
      "Epoch 107/400\n",
      "397/397 [==============================] - 0s 441us/step - loss: 0.0398 - mean_absolute_error: 0.1203\n",
      "Epoch 108/400\n",
      "397/397 [==============================] - 0s 469us/step - loss: 0.0396 - mean_absolute_error: 0.1194\n",
      "Epoch 109/400\n",
      "397/397 [==============================] - 0s 462us/step - loss: 0.0413 - mean_absolute_error: 0.1210\n",
      "Epoch 110/400\n",
      "397/397 [==============================] - 0s 448us/step - loss: 0.0369 - mean_absolute_error: 0.1160\n",
      "Epoch 111/400\n",
      "397/397 [==============================] - 0s 452us/step - loss: 0.0387 - mean_absolute_error: 0.1163\n",
      "Epoch 112/400\n",
      "397/397 [==============================] - 0s 453us/step - loss: 0.0388 - mean_absolute_error: 0.1152\n",
      "Epoch 113/400\n",
      "397/397 [==============================] - 0s 465us/step - loss: 0.0389 - mean_absolute_error: 0.1148\n",
      "Epoch 114/400\n",
      "397/397 [==============================] - 0s 466us/step - loss: 0.0395 - mean_absolute_error: 0.1181\n",
      "Epoch 115/400\n",
      "397/397 [==============================] - 0s 465us/step - loss: 0.0364 - mean_absolute_error: 0.1085\n",
      "Epoch 116/400\n",
      "397/397 [==============================] - 0s 464us/step - loss: 0.0397 - mean_absolute_error: 0.1165\n",
      "Epoch 117/400\n",
      "397/397 [==============================] - 0s 462us/step - loss: 0.0390 - mean_absolute_error: 0.1119\n",
      "Epoch 118/400\n",
      "397/397 [==============================] - 0s 480us/step - loss: 0.0385 - mean_absolute_error: 0.1159\n",
      "Epoch 119/400\n",
      "397/397 [==============================] - 0s 480us/step - loss: 0.0368 - mean_absolute_error: 0.1129\n",
      "Epoch 120/400\n",
      "397/397 [==============================] - 0s 480us/step - loss: 0.0406 - mean_absolute_error: 0.1170\n",
      "Epoch 121/400\n",
      "397/397 [==============================] - 0s 496us/step - loss: 0.0390 - mean_absolute_error: 0.1157\n",
      "Epoch 122/400\n",
      "397/397 [==============================] - 0s 485us/step - loss: 0.0400 - mean_absolute_error: 0.1175\n",
      "Epoch 123/400\n",
      "397/397 [==============================] - 0s 482us/step - loss: 0.0378 - mean_absolute_error: 0.1131\n",
      "Epoch 124/400\n",
      "397/397 [==============================] - 0s 537us/step - loss: 0.0393 - mean_absolute_error: 0.1137\n",
      "Epoch 125/400\n",
      "397/397 [==============================] - 0s 488us/step - loss: 0.0374 - mean_absolute_error: 0.1122\n",
      "Epoch 126/400\n",
      "397/397 [==============================] - 0s 480us/step - loss: 0.0377 - mean_absolute_error: 0.1134\n",
      "Epoch 127/400\n",
      "397/397 [==============================] - 0s 481us/step - loss: 0.0376 - mean_absolute_error: 0.1134\n",
      "Epoch 128/400\n",
      "397/397 [==============================] - 0s 487us/step - loss: 0.0381 - mean_absolute_error: 0.1112\n",
      "Epoch 129/400\n",
      "397/397 [==============================] - 0s 482us/step - loss: 0.0378 - mean_absolute_error: 0.1137\n",
      "Epoch 130/400\n",
      "397/397 [==============================] - 0s 482us/step - loss: 0.0383 - mean_absolute_error: 0.1152\n",
      "Epoch 131/400\n",
      "397/397 [==============================] - 0s 483us/step - loss: 0.0419 - mean_absolute_error: 0.1195\n",
      "Epoch 132/400\n",
      "397/397 [==============================] - 0s 481us/step - loss: 0.0390 - mean_absolute_error: 0.1133\n",
      "Epoch 133/400\n",
      "397/397 [==============================] - 0s 486us/step - loss: 0.0377 - mean_absolute_error: 0.1100\n",
      "Epoch 134/400\n",
      "397/397 [==============================] - 0s 479us/step - loss: 0.0372 - mean_absolute_error: 0.1107\n",
      "Epoch 135/400\n",
      "397/397 [==============================] - 0s 482us/step - loss: 0.0383 - mean_absolute_error: 0.1132\n",
      "Epoch 136/400\n",
      "397/397 [==============================] - 0s 482us/step - loss: 0.0398 - mean_absolute_error: 0.1169\n",
      "Epoch 137/400\n",
      "397/397 [==============================] - 0s 481us/step - loss: 0.0349 - mean_absolute_error: 0.1061\n",
      "Epoch 138/400\n",
      "397/397 [==============================] - 0s 480us/step - loss: 0.0396 - mean_absolute_error: 0.1150\n",
      "Epoch 139/400\n",
      "397/397 [==============================] - 0s 487us/step - loss: 0.0363 - mean_absolute_error: 0.1085\n",
      "Epoch 140/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "397/397 [==============================] - 0s 481us/step - loss: 0.0371 - mean_absolute_error: 0.1098\n",
      "Epoch 141/400\n",
      "397/397 [==============================] - 0s 483us/step - loss: 0.0365 - mean_absolute_error: 0.1076\n",
      "Epoch 142/400\n",
      "397/397 [==============================] - 0s 480us/step - loss: 0.0342 - mean_absolute_error: 0.1051\n",
      "Epoch 143/400\n",
      "397/397 [==============================] - 0s 482us/step - loss: 0.0371 - mean_absolute_error: 0.1079\n",
      "Epoch 144/400\n",
      "397/397 [==============================] - 0s 480us/step - loss: 0.0387 - mean_absolute_error: 0.1117\n",
      "Epoch 145/400\n",
      "397/397 [==============================] - 0s 478us/step - loss: 0.0359 - mean_absolute_error: 0.1086\n",
      "Epoch 146/400\n",
      "397/397 [==============================] - 0s 506us/step - loss: 0.0371 - mean_absolute_error: 0.1101\n",
      "Epoch 147/400\n",
      "397/397 [==============================] - 0s 480us/step - loss: 0.0345 - mean_absolute_error: 0.1043\n",
      "Epoch 148/400\n",
      "397/397 [==============================] - 0s 463us/step - loss: 0.0401 - mean_absolute_error: 0.1132\n",
      "Epoch 149/400\n",
      "397/397 [==============================] - 0s 475us/step - loss: 0.0373 - mean_absolute_error: 0.1085\n",
      "Epoch 150/400\n",
      "397/397 [==============================] - 0s 465us/step - loss: 0.0367 - mean_absolute_error: 0.1094\n",
      "Epoch 151/400\n",
      "397/397 [==============================] - 0s 464us/step - loss: 0.0373 - mean_absolute_error: 0.1093\n",
      "Epoch 152/400\n",
      "397/397 [==============================] - 0s 458us/step - loss: 0.0376 - mean_absolute_error: 0.1110\n",
      "Epoch 153/400\n",
      "397/397 [==============================] - 0s 445us/step - loss: 0.0354 - mean_absolute_error: 0.1083\n",
      "Epoch 154/400\n",
      "397/397 [==============================] - 0s 447us/step - loss: 0.0362 - mean_absolute_error: 0.1071\n",
      "Epoch 155/400\n",
      "397/397 [==============================] - 0s 445us/step - loss: 0.0381 - mean_absolute_error: 0.1108\n",
      "Epoch 156/400\n",
      "397/397 [==============================] - 0s 451us/step - loss: 0.0369 - mean_absolute_error: 0.1099\n",
      "Epoch 157/400\n",
      "397/397 [==============================] - 0s 445us/step - loss: 0.0376 - mean_absolute_error: 0.1093\n",
      "Epoch 158/400\n",
      "397/397 [==============================] - 0s 445us/step - loss: 0.0377 - mean_absolute_error: 0.1089\n",
      "Epoch 159/400\n",
      "397/397 [==============================] - 0s 439us/step - loss: 0.0364 - mean_absolute_error: 0.1096\n",
      "Epoch 160/400\n",
      "397/397 [==============================] - 0s 444us/step - loss: 0.0374 - mean_absolute_error: 0.1089\n",
      "Epoch 161/400\n",
      "397/397 [==============================] - 0s 428us/step - loss: 0.0371 - mean_absolute_error: 0.1098\n",
      "Epoch 162/400\n",
      "397/397 [==============================] - 0s 437us/step - loss: 0.0373 - mean_absolute_error: 0.1084\n",
      "Epoch 163/400\n",
      "397/397 [==============================] - 0s 441us/step - loss: 0.0353 - mean_absolute_error: 0.1056\n",
      "Epoch 164/400\n",
      "397/397 [==============================] - 0s 414us/step - loss: 0.0359 - mean_absolute_error: 0.1070\n",
      "Epoch 165/400\n",
      "397/397 [==============================] - 0s 413us/step - loss: 0.0369 - mean_absolute_error: 0.1070\n",
      "Epoch 166/400\n",
      "397/397 [==============================] - 0s 425us/step - loss: 0.0331 - mean_absolute_error: 0.1015\n",
      "Epoch 167/400\n",
      "397/397 [==============================] - 0s 430us/step - loss: 0.0356 - mean_absolute_error: 0.1064\n",
      "Epoch 168/400\n",
      "397/397 [==============================] - 0s 424us/step - loss: 0.0376 - mean_absolute_error: 0.1097\n",
      "Epoch 169/400\n",
      "397/397 [==============================] - 0s 400us/step - loss: 0.0364 - mean_absolute_error: 0.1078\n",
      "Epoch 170/400\n",
      "397/397 [==============================] - 0s 406us/step - loss: 0.0353 - mean_absolute_error: 0.1062\n",
      "Epoch 171/400\n",
      "397/397 [==============================] - 0s 417us/step - loss: 0.0356 - mean_absolute_error: 0.1070\n",
      "Epoch 172/400\n",
      "397/397 [==============================] - 0s 404us/step - loss: 0.0366 - mean_absolute_error: 0.1085\n",
      "Epoch 173/400\n",
      "397/397 [==============================] - 0s 402us/step - loss: 0.0340 - mean_absolute_error: 0.1044\n",
      "Epoch 174/400\n",
      "397/397 [==============================] - 0s 385us/step - loss: 0.0339 - mean_absolute_error: 0.1027\n",
      "Epoch 175/400\n",
      "397/397 [==============================] - 0s 386us/step - loss: 0.0345 - mean_absolute_error: 0.1011\n",
      "Epoch 176/400\n",
      "397/397 [==============================] - 0s 398us/step - loss: 0.0348 - mean_absolute_error: 0.1016\n",
      "Epoch 177/400\n",
      "397/397 [==============================] - 0s 385us/step - loss: 0.0358 - mean_absolute_error: 0.1054\n",
      "Epoch 178/400\n",
      "397/397 [==============================] - 0s 383us/step - loss: 0.0361 - mean_absolute_error: 0.1071\n",
      "Epoch 179/400\n",
      "397/397 [==============================] - 0s 380us/step - loss: 0.0358 - mean_absolute_error: 0.1063\n",
      "Epoch 180/400\n",
      "397/397 [==============================] - 0s 382us/step - loss: 0.0361 - mean_absolute_error: 0.1039\n",
      "Epoch 181/400\n",
      "397/397 [==============================] - 0s 386us/step - loss: 0.0353 - mean_absolute_error: 0.1045\n",
      "Epoch 182/400\n",
      "397/397 [==============================] - 0s 376us/step - loss: 0.0368 - mean_absolute_error: 0.1065\n",
      "Epoch 183/400\n",
      "397/397 [==============================] - 0s 368us/step - loss: 0.0360 - mean_absolute_error: 0.1068\n",
      "Epoch 184/400\n",
      "397/397 [==============================] - 0s 371us/step - loss: 0.0371 - mean_absolute_error: 0.1094\n",
      "Epoch 185/400\n",
      "397/397 [==============================] - 0s 372us/step - loss: 0.0355 - mean_absolute_error: 0.1068\n",
      "Epoch 186/400\n",
      "397/397 [==============================] - 0s 370us/step - loss: 0.0324 - mean_absolute_error: 0.0998\n",
      "Epoch 187/400\n",
      "397/397 [==============================] - 0s 370us/step - loss: 0.0367 - mean_absolute_error: 0.1068\n",
      "Epoch 188/400\n",
      "397/397 [==============================] - 0s 373us/step - loss: 0.0363 - mean_absolute_error: 0.1062\n",
      "Epoch 189/400\n",
      "397/397 [==============================] - 0s 372us/step - loss: 0.0339 - mean_absolute_error: 0.1014\n",
      "Epoch 190/400\n",
      "397/397 [==============================] - 0s 370us/step - loss: 0.0385 - mean_absolute_error: 0.1104\n",
      "Epoch 191/400\n",
      "397/397 [==============================] - 0s 370us/step - loss: 0.0378 - mean_absolute_error: 0.1098\n",
      "Epoch 192/400\n",
      "397/397 [==============================] - 0s 371us/step - loss: 0.0337 - mean_absolute_error: 0.1033\n",
      "Epoch 193/400\n",
      "397/397 [==============================] - 0s 420us/step - loss: 0.0355 - mean_absolute_error: 0.1053\n",
      "Epoch 194/400\n",
      "397/397 [==============================] - 0s 375us/step - loss: 0.0343 - mean_absolute_error: 0.1027\n",
      "Epoch 195/400\n",
      "397/397 [==============================] - 0s 363us/step - loss: 0.0330 - mean_absolute_error: 0.1005\n",
      "Epoch 196/400\n",
      "397/397 [==============================] - 0s 361us/step - loss: 0.0344 - mean_absolute_error: 0.1033\n",
      "Epoch 197/400\n",
      "397/397 [==============================] - 0s 361us/step - loss: 0.0372 - mean_absolute_error: 0.1068\n",
      "Epoch 198/400\n",
      "397/397 [==============================] - 0s 359us/step - loss: 0.0329 - mean_absolute_error: 0.1020\n",
      "Epoch 199/400\n",
      "397/397 [==============================] - 0s 363us/step - loss: 0.0374 - mean_absolute_error: 0.1074\n",
      "Epoch 200/400\n",
      "397/397 [==============================] - 0s 361us/step - loss: 0.0361 - mean_absolute_error: 0.1082\n",
      "Epoch 201/400\n",
      "397/397 [==============================] - 0s 363us/step - loss: 0.0357 - mean_absolute_error: 0.1056\n",
      "Epoch 202/400\n",
      "397/397 [==============================] - 0s 360us/step - loss: 0.0366 - mean_absolute_error: 0.1076\n",
      "Epoch 203/400\n",
      "397/397 [==============================] - 0s 358us/step - loss: 0.0341 - mean_absolute_error: 0.1032\n",
      "Epoch 204/400\n",
      "397/397 [==============================] - 0s 358us/step - loss: 0.0331 - mean_absolute_error: 0.1026\n",
      "Epoch 205/400\n",
      "397/397 [==============================] - 0s 359us/step - loss: 0.0351 - mean_absolute_error: 0.1038\n",
      "Epoch 206/400\n",
      "397/397 [==============================] - 0s 358us/step - loss: 0.0342 - mean_absolute_error: 0.1020\n",
      "Epoch 207/400\n",
      "397/397 [==============================] - 0s 362us/step - loss: 0.0335 - mean_absolute_error: 0.1024\n",
      "Epoch 208/400\n",
      "397/397 [==============================] - 0s 364us/step - loss: 0.0344 - mean_absolute_error: 0.1030\n",
      "Epoch 209/400\n",
      "397/397 [==============================] - 0s 363us/step - loss: 0.0346 - mean_absolute_error: 0.1015\n",
      "Epoch 210/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "397/397 [==============================] - 0s 348us/step - loss: 0.0355 - mean_absolute_error: 0.1054\n",
      "Epoch 211/400\n",
      "397/397 [==============================] - 0s 348us/step - loss: 0.0338 - mean_absolute_error: 0.1044\n",
      "Epoch 212/400\n",
      "397/397 [==============================] - 0s 350us/step - loss: 0.0341 - mean_absolute_error: 0.1051\n",
      "Epoch 213/400\n",
      "397/397 [==============================] - 0s 351us/step - loss: 0.0338 - mean_absolute_error: 0.1045\n",
      "Epoch 214/400\n",
      "397/397 [==============================] - 0s 352us/step - loss: 0.0355 - mean_absolute_error: 0.1053\n",
      "Epoch 215/400\n",
      "397/397 [==============================] - 0s 347us/step - loss: 0.0350 - mean_absolute_error: 0.1053\n",
      "Epoch 216/400\n",
      "397/397 [==============================] - 0s 368us/step - loss: 0.0336 - mean_absolute_error: 0.1026\n",
      "Epoch 217/400\n",
      "397/397 [==============================] - 0s 365us/step - loss: 0.0339 - mean_absolute_error: 0.1036\n",
      "Epoch 218/400\n",
      "397/397 [==============================] - 0s 361us/step - loss: 0.0315 - mean_absolute_error: 0.1002\n",
      "Epoch 219/400\n",
      "397/397 [==============================] - 0s 376us/step - loss: 0.0324 - mean_absolute_error: 0.0997\n",
      "Epoch 220/400\n",
      "397/397 [==============================] - 0s 363us/step - loss: 0.0332 - mean_absolute_error: 0.1024\n",
      "Epoch 221/400\n",
      "397/397 [==============================] - 0s 358us/step - loss: 0.0336 - mean_absolute_error: 0.1031\n",
      "Epoch 222/400\n",
      "397/397 [==============================] - 0s 359us/step - loss: 0.0340 - mean_absolute_error: 0.1055\n",
      "Epoch 223/400\n",
      "397/397 [==============================] - 0s 389us/step - loss: 0.0341 - mean_absolute_error: 0.1040\n",
      "Epoch 224/400\n",
      "397/397 [==============================] - 0s 391us/step - loss: 0.0320 - mean_absolute_error: 0.0988\n",
      "Epoch 225/400\n",
      "397/397 [==============================] - 0s 380us/step - loss: 0.0341 - mean_absolute_error: 0.1012\n",
      "Epoch 226/400\n",
      "397/397 [==============================] - 0s 395us/step - loss: 0.0339 - mean_absolute_error: 0.1002\n",
      "Epoch 227/400\n",
      "397/397 [==============================] - 0s 389us/step - loss: 0.0341 - mean_absolute_error: 0.1043\n",
      "Epoch 228/400\n",
      "397/397 [==============================] - 0s 394us/step - loss: 0.0346 - mean_absolute_error: 0.1058\n",
      "Epoch 229/400\n",
      "397/397 [==============================] - 0s 386us/step - loss: 0.0318 - mean_absolute_error: 0.0991\n",
      "Epoch 230/400\n",
      "397/397 [==============================] - 0s 373us/step - loss: 0.0343 - mean_absolute_error: 0.1023\n",
      "Epoch 231/400\n",
      "397/397 [==============================] - 0s 363us/step - loss: 0.0340 - mean_absolute_error: 0.1040\n",
      "Epoch 232/400\n",
      "397/397 [==============================] - 0s 360us/step - loss: 0.0338 - mean_absolute_error: 0.1026\n",
      "Epoch 233/400\n",
      "397/397 [==============================] - 0s 365us/step - loss: 0.0332 - mean_absolute_error: 0.1011\n",
      "Epoch 234/400\n",
      "397/397 [==============================] - 0s 398us/step - loss: 0.0329 - mean_absolute_error: 0.1014\n",
      "Epoch 235/400\n",
      "397/397 [==============================] - 0s 407us/step - loss: 0.0335 - mean_absolute_error: 0.1022\n",
      "Epoch 236/400\n",
      "397/397 [==============================] - 0s 406us/step - loss: 0.0318 - mean_absolute_error: 0.0995\n",
      "Epoch 237/400\n",
      "397/397 [==============================] - 0s 406us/step - loss: 0.0349 - mean_absolute_error: 0.1029\n",
      "Epoch 238/400\n",
      "397/397 [==============================] - 0s 403us/step - loss: 0.0318 - mean_absolute_error: 0.0991\n",
      "Epoch 239/400\n",
      "397/397 [==============================] - 0s 404us/step - loss: 0.0328 - mean_absolute_error: 0.0996\n",
      "Epoch 240/400\n",
      "397/397 [==============================] - 0s 372us/step - loss: 0.0335 - mean_absolute_error: 0.1020\n",
      "Epoch 241/400\n",
      "397/397 [==============================] - 0s 363us/step - loss: 0.0329 - mean_absolute_error: 0.1016\n",
      "Epoch 242/400\n",
      "397/397 [==============================] - 0s 462us/step - loss: 0.0342 - mean_absolute_error: 0.1025\n",
      "Epoch 243/400\n",
      "397/397 [==============================] - 0s 421us/step - loss: 0.0327 - mean_absolute_error: 0.1026\n",
      "Epoch 244/400\n",
      "397/397 [==============================] - 0s 423us/step - loss: 0.0352 - mean_absolute_error: 0.1026\n",
      "Epoch 245/400\n",
      "397/397 [==============================] - 0s 427us/step - loss: 0.0339 - mean_absolute_error: 0.1012\n",
      "Epoch 246/400\n",
      "397/397 [==============================] - 0s 424us/step - loss: 0.0334 - mean_absolute_error: 0.1019\n",
      "Epoch 247/400\n",
      "397/397 [==============================] - 0s 428us/step - loss: 0.0323 - mean_absolute_error: 0.1004\n",
      "Epoch 248/400\n",
      "397/397 [==============================] - 0s 387us/step - loss: 0.0314 - mean_absolute_error: 0.0984\n",
      "Epoch 249/400\n",
      "397/397 [==============================] - 0s 373us/step - loss: 0.0365 - mean_absolute_error: 0.1072\n",
      "Epoch 250/400\n",
      "397/397 [==============================] - 0s 376us/step - loss: 0.0327 - mean_absolute_error: 0.1022\n",
      "Epoch 251/400\n",
      "397/397 [==============================] - 0s 383us/step - loss: 0.0336 - mean_absolute_error: 0.1041\n",
      "Epoch 252/400\n",
      "397/397 [==============================] - 0s 408us/step - loss: 0.0314 - mean_absolute_error: 0.0986\n",
      "Epoch 253/400\n",
      "397/397 [==============================] - 0s 380us/step - loss: 0.0334 - mean_absolute_error: 0.1033\n",
      "Epoch 254/400\n",
      "397/397 [==============================] - 0s 385us/step - loss: 0.0320 - mean_absolute_error: 0.1015\n",
      "Epoch 255/400\n",
      "397/397 [==============================] - 0s 381us/step - loss: 0.0341 - mean_absolute_error: 0.1043\n",
      "Epoch 256/400\n",
      "397/397 [==============================] - 0s 382us/step - loss: 0.0319 - mean_absolute_error: 0.0984\n",
      "Epoch 257/400\n",
      "397/397 [==============================] - 0s 386us/step - loss: 0.0341 - mean_absolute_error: 0.1043\n",
      "Epoch 258/400\n",
      "397/397 [==============================] - 0s 384us/step - loss: 0.0330 - mean_absolute_error: 0.1006\n",
      "Epoch 259/400\n",
      "397/397 [==============================] - 0s 384us/step - loss: 0.0340 - mean_absolute_error: 0.1034\n",
      "Epoch 260/400\n",
      "397/397 [==============================] - 0s 468us/step - loss: 0.0322 - mean_absolute_error: 0.0997\n",
      "Epoch 261/400\n",
      "397/397 [==============================] - 0s 438us/step - loss: 0.0328 - mean_absolute_error: 0.1006\n",
      "Epoch 262/400\n",
      "397/397 [==============================] - 0s 463us/step - loss: 0.0322 - mean_absolute_error: 0.1013\n",
      "Epoch 263/400\n",
      "397/397 [==============================] - 0s 488us/step - loss: 0.0322 - mean_absolute_error: 0.1015\n",
      "Epoch 264/400\n",
      "397/397 [==============================] - 0s 447us/step - loss: 0.0325 - mean_absolute_error: 0.0987\n",
      "Epoch 265/400\n",
      "397/397 [==============================] - 0s 434us/step - loss: 0.0355 - mean_absolute_error: 0.1029\n",
      "Epoch 266/400\n",
      "397/397 [==============================] - 0s 441us/step - loss: 0.0335 - mean_absolute_error: 0.1014\n",
      "Epoch 267/400\n",
      "397/397 [==============================] - 0s 468us/step - loss: 0.0355 - mean_absolute_error: 0.1066\n",
      "Epoch 268/400\n",
      "397/397 [==============================] - 0s 468us/step - loss: 0.0325 - mean_absolute_error: 0.1013\n",
      "Epoch 269/400\n",
      "397/397 [==============================] - 0s 471us/step - loss: 0.0343 - mean_absolute_error: 0.1056\n",
      "Epoch 270/400\n",
      "397/397 [==============================] - 0s 459us/step - loss: 0.0307 - mean_absolute_error: 0.0981\n",
      "Epoch 271/400\n",
      "397/397 [==============================] - 0s 442us/step - loss: 0.0361 - mean_absolute_error: 0.1058\n",
      "Epoch 272/400\n",
      "397/397 [==============================] - 0s 471us/step - loss: 0.0295 - mean_absolute_error: 0.0951\n",
      "Epoch 273/400\n",
      "397/397 [==============================] - 0s 475us/step - loss: 0.0304 - mean_absolute_error: 0.0960\n",
      "Epoch 274/400\n",
      "397/397 [==============================] - 0s 465us/step - loss: 0.0322 - mean_absolute_error: 0.0981\n",
      "Epoch 275/400\n",
      "397/397 [==============================] - 0s 399us/step - loss: 0.0310 - mean_absolute_error: 0.0959\n",
      "Epoch 276/400\n",
      "397/397 [==============================] - 0s 453us/step - loss: 0.0336 - mean_absolute_error: 0.1007\n",
      "Epoch 277/400\n",
      "397/397 [==============================] - 0s 479us/step - loss: 0.0327 - mean_absolute_error: 0.0992\n",
      "Epoch 278/400\n",
      "397/397 [==============================] - 0s 449us/step - loss: 0.0344 - mean_absolute_error: 0.1021\n",
      "Epoch 279/400\n",
      "397/397 [==============================] - 0s 448us/step - loss: 0.0351 - mean_absolute_error: 0.1038\n",
      "Epoch 280/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "397/397 [==============================] - 0s 443us/step - loss: 0.0327 - mean_absolute_error: 0.1009\n",
      "Epoch 281/400\n",
      "397/397 [==============================] - 0s 461us/step - loss: 0.0296 - mean_absolute_error: 0.0949\n",
      "Epoch 282/400\n",
      "397/397 [==============================] - 0s 449us/step - loss: 0.0309 - mean_absolute_error: 0.0967\n",
      "Epoch 283/400\n",
      "397/397 [==============================] - 0s 446us/step - loss: 0.0339 - mean_absolute_error: 0.1003\n",
      "Epoch 284/400\n",
      "397/397 [==============================] - 0s 449us/step - loss: 0.0324 - mean_absolute_error: 0.1008\n",
      "Epoch 285/400\n",
      "397/397 [==============================] - 0s 415us/step - loss: 0.0336 - mean_absolute_error: 0.1004\n",
      "Epoch 286/400\n",
      "397/397 [==============================] - 0s 454us/step - loss: 0.0340 - mean_absolute_error: 0.0999\n",
      "Epoch 287/400\n",
      "397/397 [==============================] - 0s 466us/step - loss: 0.0332 - mean_absolute_error: 0.1007\n",
      "Epoch 288/400\n",
      "397/397 [==============================] - 0s 452us/step - loss: 0.0323 - mean_absolute_error: 0.0995\n",
      "Epoch 289/400\n",
      "397/397 [==============================] - 0s 451us/step - loss: 0.0307 - mean_absolute_error: 0.0977\n",
      "Epoch 290/400\n",
      "397/397 [==============================] - 0s 404us/step - loss: 0.0326 - mean_absolute_error: 0.0998\n",
      "Epoch 291/400\n",
      "397/397 [==============================] - 0s 398us/step - loss: 0.0362 - mean_absolute_error: 0.1060\n",
      "Epoch 292/400\n",
      "397/397 [==============================] - 0s 405us/step - loss: 0.0316 - mean_absolute_error: 0.1007\n",
      "Epoch 293/400\n",
      "397/397 [==============================] - 0s 504us/step - loss: 0.0341 - mean_absolute_error: 0.1032\n",
      "Epoch 294/400\n",
      "397/397 [==============================] - 0s 446us/step - loss: 0.0303 - mean_absolute_error: 0.0972\n",
      "Epoch 295/400\n",
      "397/397 [==============================] - 0s 407us/step - loss: 0.0332 - mean_absolute_error: 0.1030\n",
      "Epoch 296/400\n",
      "397/397 [==============================] - 0s 398us/step - loss: 0.0291 - mean_absolute_error: 0.0961\n",
      "Epoch 297/400\n",
      "397/397 [==============================] - 0s 397us/step - loss: 0.0312 - mean_absolute_error: 0.0991\n",
      "Epoch 298/400\n",
      "397/397 [==============================] - 0s 398us/step - loss: 0.0302 - mean_absolute_error: 0.0962\n",
      "Epoch 299/400\n",
      "397/397 [==============================] - 0s 495us/step - loss: 0.0337 - mean_absolute_error: 0.1011\n",
      "Epoch 300/400\n",
      "397/397 [==============================] - 0s 421us/step - loss: 0.0334 - mean_absolute_error: 0.1017\n",
      "Epoch 301/400\n",
      "397/397 [==============================] - 0s 394us/step - loss: 0.0308 - mean_absolute_error: 0.0968\n",
      "Epoch 302/400\n",
      "397/397 [==============================] - 0s 398us/step - loss: 0.0308 - mean_absolute_error: 0.0971\n",
      "Epoch 303/400\n",
      "397/397 [==============================] - 0s 393us/step - loss: 0.0300 - mean_absolute_error: 0.0957\n",
      "Epoch 304/400\n",
      "397/397 [==============================] - 0s 393us/step - loss: 0.0302 - mean_absolute_error: 0.0966\n",
      "Epoch 305/400\n",
      "397/397 [==============================] - 0s 392us/step - loss: 0.0309 - mean_absolute_error: 0.0983\n",
      "Epoch 306/400\n",
      "397/397 [==============================] - 0s 409us/step - loss: 0.0316 - mean_absolute_error: 0.0980\n",
      "Epoch 307/400\n",
      "397/397 [==============================] - 0s 408us/step - loss: 0.0298 - mean_absolute_error: 0.0943\n",
      "Epoch 308/400\n",
      "397/397 [==============================] - 0s 409us/step - loss: 0.0312 - mean_absolute_error: 0.0985\n",
      "Epoch 309/400\n",
      "397/397 [==============================] - 0s 410us/step - loss: 0.0312 - mean_absolute_error: 0.0985\n",
      "Epoch 310/400\n",
      "397/397 [==============================] - 0s 396us/step - loss: 0.0291 - mean_absolute_error: 0.0937\n",
      "Epoch 311/400\n",
      "397/397 [==============================] - 0s 396us/step - loss: 0.0326 - mean_absolute_error: 0.0964\n",
      "Epoch 312/400\n",
      "397/397 [==============================] - 0s 417us/step - loss: 0.0332 - mean_absolute_error: 0.0994\n",
      "Epoch 313/400\n",
      "397/397 [==============================] - 0s 390us/step - loss: 0.0306 - mean_absolute_error: 0.0955\n",
      "Epoch 314/400\n",
      "397/397 [==============================] - 0s 395us/step - loss: 0.0308 - mean_absolute_error: 0.0964\n",
      "Epoch 315/400\n",
      "397/397 [==============================] - 0s 398us/step - loss: 0.0321 - mean_absolute_error: 0.0972\n",
      "Epoch 316/400\n",
      "397/397 [==============================] - 0s 495us/step - loss: 0.0315 - mean_absolute_error: 0.0983\n",
      "Epoch 317/400\n",
      "397/397 [==============================] - 0s 430us/step - loss: 0.0305 - mean_absolute_error: 0.0956\n",
      "Epoch 318/400\n",
      "397/397 [==============================] - 0s 403us/step - loss: 0.0297 - mean_absolute_error: 0.0950\n",
      "Epoch 319/400\n",
      "397/397 [==============================] - 0s 395us/step - loss: 0.0308 - mean_absolute_error: 0.0974\n",
      "Epoch 320/400\n",
      "397/397 [==============================] - 0s 386us/step - loss: 0.0314 - mean_absolute_error: 0.0975\n",
      "Epoch 321/400\n",
      "397/397 [==============================] - 0s 403us/step - loss: 0.0346 - mean_absolute_error: 0.1057\n",
      "Epoch 322/400\n",
      "397/397 [==============================] - 0s 399us/step - loss: 0.0328 - mean_absolute_error: 0.1005\n",
      "Epoch 323/400\n",
      "397/397 [==============================] - 0s 386us/step - loss: 0.0302 - mean_absolute_error: 0.0958\n",
      "Epoch 324/400\n",
      "397/397 [==============================] - 0s 378us/step - loss: 0.0345 - mean_absolute_error: 0.1012\n",
      "Epoch 325/400\n",
      "397/397 [==============================] - 0s 377us/step - loss: 0.0310 - mean_absolute_error: 0.0972\n",
      "Epoch 326/400\n",
      "397/397 [==============================] - 0s 376us/step - loss: 0.0346 - mean_absolute_error: 0.1038\n",
      "Epoch 327/400\n",
      "397/397 [==============================] - 0s 369us/step - loss: 0.0292 - mean_absolute_error: 0.0952\n",
      "Epoch 328/400\n",
      "397/397 [==============================] - 0s 370us/step - loss: 0.0323 - mean_absolute_error: 0.1009\n",
      "Epoch 329/400\n",
      "397/397 [==============================] - 0s 370us/step - loss: 0.0289 - mean_absolute_error: 0.0954\n",
      "Epoch 330/400\n",
      "397/397 [==============================] - 0s 419us/step - loss: 0.0307 - mean_absolute_error: 0.0951\n",
      "Epoch 331/400\n",
      "397/397 [==============================] - 0s 378us/step - loss: 0.0310 - mean_absolute_error: 0.0972\n",
      "Epoch 332/400\n",
      "397/397 [==============================] - 0s 368us/step - loss: 0.0318 - mean_absolute_error: 0.0983\n",
      "Epoch 333/400\n",
      "397/397 [==============================] - 0s 370us/step - loss: 0.0290 - mean_absolute_error: 0.0924\n",
      "Epoch 334/400\n",
      "397/397 [==============================] - 0s 369us/step - loss: 0.0302 - mean_absolute_error: 0.0946\n",
      "Epoch 335/400\n",
      "397/397 [==============================] - 0s 366us/step - loss: 0.0299 - mean_absolute_error: 0.0953\n",
      "Epoch 336/400\n",
      "397/397 [==============================] - 0s 360us/step - loss: 0.0301 - mean_absolute_error: 0.0941\n",
      "Epoch 337/400\n",
      "397/397 [==============================] - 0s 358us/step - loss: 0.0344 - mean_absolute_error: 0.1030\n",
      "Epoch 338/400\n",
      "397/397 [==============================] - 0s 371us/step - loss: 0.0303 - mean_absolute_error: 0.0960\n",
      "Epoch 339/400\n",
      "397/397 [==============================] - 0s 359us/step - loss: 0.0303 - mean_absolute_error: 0.0955\n",
      "Epoch 340/400\n",
      "397/397 [==============================] - 0s 359us/step - loss: 0.0281 - mean_absolute_error: 0.0923\n",
      "Epoch 341/400\n",
      "397/397 [==============================] - 0s 359us/step - loss: 0.0314 - mean_absolute_error: 0.0979\n",
      "Epoch 342/400\n",
      "397/397 [==============================] - 0s 355us/step - loss: 0.0323 - mean_absolute_error: 0.0986\n",
      "Epoch 343/400\n",
      "397/397 [==============================] - 0s 349us/step - loss: 0.0331 - mean_absolute_error: 0.1000\n",
      "Epoch 344/400\n",
      "397/397 [==============================] - 0s 349us/step - loss: 0.0315 - mean_absolute_error: 0.0995\n",
      "Epoch 345/400\n",
      "397/397 [==============================] - 0s 352us/step - loss: 0.0306 - mean_absolute_error: 0.0957\n",
      "Epoch 346/400\n",
      "397/397 [==============================] - 0s 346us/step - loss: 0.0327 - mean_absolute_error: 0.1003\n",
      "Epoch 347/400\n",
      "397/397 [==============================] - 0s 349us/step - loss: 0.0310 - mean_absolute_error: 0.0968\n",
      "Epoch 348/400\n",
      "397/397 [==============================] - 0s 349us/step - loss: 0.0298 - mean_absolute_error: 0.0961\n",
      "Epoch 349/400\n",
      "397/397 [==============================] - 0s 348us/step - loss: 0.0314 - mean_absolute_error: 0.0990\n",
      "Epoch 350/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "397/397 [==============================] - 0s 360us/step - loss: 0.0318 - mean_absolute_error: 0.0990\n",
      "Epoch 351/400\n",
      "397/397 [==============================] - 0s 349us/step - loss: 0.0320 - mean_absolute_error: 0.0998\n",
      "Epoch 352/400\n",
      "397/397 [==============================] - 0s 346us/step - loss: 0.0311 - mean_absolute_error: 0.0953\n",
      "Epoch 353/400\n",
      "397/397 [==============================] - 0s 342us/step - loss: 0.0296 - mean_absolute_error: 0.0931\n",
      "Epoch 354/400\n",
      "397/397 [==============================] - 0s 341us/step - loss: 0.0324 - mean_absolute_error: 0.1004\n",
      "Epoch 355/400\n",
      "397/397 [==============================] - 0s 336us/step - loss: 0.0292 - mean_absolute_error: 0.0915\n",
      "Epoch 356/400\n",
      "397/397 [==============================] - 0s 337us/step - loss: 0.0306 - mean_absolute_error: 0.0973\n",
      "Epoch 357/400\n",
      "397/397 [==============================] - 0s 338us/step - loss: 0.0301 - mean_absolute_error: 0.0957\n",
      "Epoch 358/400\n",
      "397/397 [==============================] - 0s 341us/step - loss: 0.0308 - mean_absolute_error: 0.0960\n",
      "Epoch 359/400\n",
      "397/397 [==============================] - 0s 343us/step - loss: 0.0312 - mean_absolute_error: 0.0964\n",
      "Epoch 360/400\n",
      "397/397 [==============================] - 0s 340us/step - loss: 0.0326 - mean_absolute_error: 0.0982\n",
      "Epoch 361/400\n",
      "397/397 [==============================] - 0s 339us/step - loss: 0.0319 - mean_absolute_error: 0.0974\n",
      "Epoch 362/400\n",
      "397/397 [==============================] - 0s 337us/step - loss: 0.0313 - mean_absolute_error: 0.0976\n",
      "Epoch 363/400\n",
      "397/397 [==============================] - 0s 341us/step - loss: 0.0331 - mean_absolute_error: 0.1013\n",
      "Epoch 364/400\n",
      "397/397 [==============================] - 0s 336us/step - loss: 0.0280 - mean_absolute_error: 0.0933\n",
      "Epoch 365/400\n",
      "397/397 [==============================] - 0s 339us/step - loss: 0.0297 - mean_absolute_error: 0.0940\n",
      "Epoch 366/400\n",
      "397/397 [==============================] - 0s 339us/step - loss: 0.0294 - mean_absolute_error: 0.0927\n",
      "Epoch 367/400\n",
      "397/397 [==============================] - 0s 344us/step - loss: 0.0296 - mean_absolute_error: 0.0946\n",
      "Epoch 368/400\n",
      "397/397 [==============================] - 0s 336us/step - loss: 0.0298 - mean_absolute_error: 0.0941\n",
      "Epoch 369/400\n",
      "397/397 [==============================] - 0s 340us/step - loss: 0.0318 - mean_absolute_error: 0.0981\n",
      "Epoch 370/400\n",
      "397/397 [==============================] - 0s 339us/step - loss: 0.0346 - mean_absolute_error: 0.1046\n",
      "Epoch 371/400\n",
      "397/397 [==============================] - 0s 339us/step - loss: 0.0289 - mean_absolute_error: 0.0948\n",
      "Epoch 372/400\n",
      "397/397 [==============================] - 0s 340us/step - loss: 0.0317 - mean_absolute_error: 0.0970\n",
      "Epoch 373/400\n",
      "397/397 [==============================] - 0s 344us/step - loss: 0.0288 - mean_absolute_error: 0.0936\n",
      "Epoch 374/400\n",
      "397/397 [==============================] - 0s 337us/step - loss: 0.0298 - mean_absolute_error: 0.0961\n",
      "Epoch 375/400\n",
      "397/397 [==============================] - 0s 337us/step - loss: 0.0294 - mean_absolute_error: 0.0928\n",
      "Epoch 376/400\n",
      "397/397 [==============================] - 0s 339us/step - loss: 0.0295 - mean_absolute_error: 0.0933\n",
      "Epoch 377/400\n",
      "397/397 [==============================] - 0s 340us/step - loss: 0.0307 - mean_absolute_error: 0.0952\n",
      "Epoch 378/400\n",
      "397/397 [==============================] - 0s 338us/step - loss: 0.0334 - mean_absolute_error: 0.1013\n",
      "Epoch 379/400\n",
      "397/397 [==============================] - 0s 339us/step - loss: 0.0295 - mean_absolute_error: 0.0952\n",
      "Epoch 380/400\n",
      "397/397 [==============================] - 0s 342us/step - loss: 0.0311 - mean_absolute_error: 0.0993\n",
      "Epoch 381/400\n",
      "397/397 [==============================] - 0s 341us/step - loss: 0.0283 - mean_absolute_error: 0.0905\n",
      "Epoch 382/400\n",
      "397/397 [==============================] - 0s 337us/step - loss: 0.0293 - mean_absolute_error: 0.0921\n",
      "Epoch 383/400\n",
      "397/397 [==============================] - 0s 337us/step - loss: 0.0291 - mean_absolute_error: 0.0915\n",
      "Epoch 384/400\n",
      "397/397 [==============================] - 0s 339us/step - loss: 0.0330 - mean_absolute_error: 0.1003\n",
      "Epoch 385/400\n",
      "397/397 [==============================] - 0s 340us/step - loss: 0.0317 - mean_absolute_error: 0.0971\n",
      "Epoch 386/400\n",
      "397/397 [==============================] - 0s 341us/step - loss: 0.0320 - mean_absolute_error: 0.0978\n",
      "Epoch 387/400\n",
      "397/397 [==============================] - 0s 338us/step - loss: 0.0321 - mean_absolute_error: 0.0984\n",
      "Epoch 388/400\n",
      "397/397 [==============================] - 0s 339us/step - loss: 0.0313 - mean_absolute_error: 0.0977\n",
      "Epoch 389/400\n",
      "397/397 [==============================] - 0s 344us/step - loss: 0.0320 - mean_absolute_error: 0.0983\n",
      "Epoch 390/400\n",
      "397/397 [==============================] - 0s 338us/step - loss: 0.0289 - mean_absolute_error: 0.0946\n",
      "Epoch 391/400\n",
      "397/397 [==============================] - 0s 337us/step - loss: 0.0293 - mean_absolute_error: 0.0927\n",
      "Epoch 392/400\n",
      "397/397 [==============================] - 0s 339us/step - loss: 0.0312 - mean_absolute_error: 0.0987\n",
      "Epoch 393/400\n",
      "397/397 [==============================] - 0s 338us/step - loss: 0.0306 - mean_absolute_error: 0.0962\n",
      "Epoch 394/400\n",
      "397/397 [==============================] - 0s 341us/step - loss: 0.0305 - mean_absolute_error: 0.0942\n",
      "Epoch 395/400\n",
      "397/397 [==============================] - 0s 339us/step - loss: 0.0277 - mean_absolute_error: 0.0896\n",
      "Epoch 396/400\n",
      "397/397 [==============================] - 0s 334us/step - loss: 0.0313 - mean_absolute_error: 0.0940\n",
      "Epoch 397/400\n",
      "397/397 [==============================] - 0s 337us/step - loss: 0.0299 - mean_absolute_error: 0.0935\n",
      "Epoch 398/400\n",
      "397/397 [==============================] - 0s 336us/step - loss: 0.0332 - mean_absolute_error: 0.0991\n",
      "Epoch 399/400\n",
      "397/397 [==============================] - 0s 339us/step - loss: 0.0287 - mean_absolute_error: 0.0916\n",
      "Epoch 400/400\n",
      "397/397 [==============================] - 0s 338us/step - loss: 0.0313 - mean_absolute_error: 0.0994\n"
     ]
    }
   ],
   "source": [
    "model1 = baseline_model_31()\n",
    "\n",
    "# estimator1 = train_data_nn_1(X_new1, Y_rob_train)\n",
    "\n",
    "# print(X_new.shape)\n",
    "# print(y_train.shape)\n",
    "history_1 = model1.fit(X_new1,  Y_rob_train_c, epochs=400, batch_size=5,  verbose=1, validation_split=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 625
    },
    "colab_type": "code",
    "id": "O1YTEBaakaUU",
    "outputId": "da7664ff-a38e-43cd-ff9a-d6874599cf22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(397, 2)\n",
      "0.027379716855218547\n",
      "dict_keys(['loss', 'mean_absolute_error'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "import math\n",
    "# from sklearn.metrics import max_error\n",
    "\n",
    "pred_c = model1.predict((X_new1))\n",
    "print(pred_c.shape)\n",
    "\n",
    "mse = (mean_squared_error(Y_rob_train_c,pred_c))\n",
    "\n",
    "print(mse)\n",
    "visualize_learning_curve(history_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "gXSgtNLckt4p",
    "outputId": "5a8d75e1-039a-4ec9-969d-35b75b4b4d4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.    7.997] ytest[i]\n",
      "[0.       4.216458] final\n",
      "[0.    7.992] ytest[i]\n",
      "[0.        3.5976193] final\n",
      "[0. 8.] ytest[i]\n",
      "[0.        6.4993176] final\n",
      "[0. 8.] ytest[i]\n",
      "[0.       7.599846] final\n",
      "[0. 8.] ytest[i]\n",
      "[0.        5.5021243] final\n",
      "[0.    4.377] ytest[i]\n",
      "[0.        5.0296597] final\n",
      "[0.       0.007997] ytest[i]\n",
      "[0.       3.958587] final\n",
      "[0.       0.007704] ytest[i]\n",
      "[0.       3.889696] final\n",
      "[0.    1.088] ytest[i]\n",
      "[0.        1.8448887] final\n",
      "[0.    1.088] ytest[i]\n",
      "[0.        1.8490009] final\n",
      "[0.    1.259] ytest[i]\n",
      "[0.        2.0752573] final\n",
      "[0.   1.26] ytest[i]\n",
      "[0.        2.3397508] final\n",
      "[0.    0.987] ytest[i]\n",
      "[0.        2.7763672] final\n",
      "[0.    7.734] ytest[i]\n",
      "[0.        3.3080847] final\n",
      "[0.    1.333] ytest[i]\n",
      "[0.        2.2272856] final\n",
      "[0.    1.335] ytest[i]\n",
      "[0.        2.0884726] final\n",
      "[0.    1.189] ytest[i]\n",
      "[0.        2.0804763] final\n",
      "[0.    1.317] ytest[i]\n",
      "[0.        2.1163728] final\n",
      "[0.    4.627] ytest[i]\n",
      "[0.       5.307812] final\n",
      "[0.    7.901] ytest[i]\n",
      "[0.       5.266311] final\n",
      "[0.    7.979] ytest[i]\n",
      "[0.        6.0480604] final\n",
      "[0.    6.868] ytest[i]\n",
      "[0.        5.4904933] final\n",
      "[0.    7.999] ytest[i]\n",
      "[0.        5.0849032] final\n",
      "[0.    7.999] ytest[i]\n",
      "[0.        4.5374384] final\n",
      "[ 0.    -1.906] ytest[i]\n",
      "[0.        0.6133225] final\n",
      "[ 0.    -1.906] ytest[i]\n",
      "[0.        0.6133225] final\n",
      "[0. 8.] ytest[i]\n",
      "[0.       6.515043] final\n",
      "[0.    7.994] ytest[i]\n",
      "[0.        4.1072006] final\n",
      "[0. 8.] ytest[i]\n",
      "[0.        5.5728188] final\n",
      "[0.   7.85] ytest[i]\n",
      "[0.       3.258613] final\n",
      "[0.    7.985] ytest[i]\n",
      "[0.       3.835248] final\n",
      "[0. 8.] ytest[i]\n",
      "[0.        5.5578194] final\n",
      "[0.    1.151] ytest[i]\n",
      "[0.        1.5327437] final\n",
      "[0.    1.134] ytest[i]\n",
      "[0.        2.0496147] final\n",
      "[0.    7.768] ytest[i]\n",
      "[0.       5.417723] final\n",
      "[0.   4.59] ytest[i]\n",
      "[0.        2.9790528] final\n",
      "[0.    7.997] ytest[i]\n",
      "[0.      4.81102] final\n",
      "[0.    4.449] ytest[i]\n",
      "[0.        4.0289397] final\n",
      "[0.   7.83] ytest[i]\n",
      "[0.        4.4382067] final\n",
      "[0. 8.] ytest[i]\n",
      "[0.        5.6033826] final\n",
      "[0.    1.243] ytest[i]\n",
      "[0.       1.939487] final\n",
      "[0.    1.455] ytest[i]\n",
      "[0.       2.633629] final\n",
      "[0.    1.151] ytest[i]\n",
      "[0.        2.7969856] final\n",
      "[0.   1.25] ytest[i]\n",
      "[0.       2.017075] final\n",
      "[0.    1.416] ytest[i]\n",
      "[0.        2.4758115] final\n",
      "[0.    1.109] ytest[i]\n",
      "[0.       2.788309] final\n",
      "[0.    1.294] ytest[i]\n",
      "[0.        2.4367847] final\n",
      "[0.    1.114] ytest[i]\n",
      "[0.        2.7383535] final\n",
      "[0.    0.989] ytest[i]\n",
      "[0.       2.795454] final\n",
      "[0.    1.262] ytest[i]\n",
      "[0.        2.5486345] final\n",
      "[0.    0.978] ytest[i]\n",
      "[0.        2.5897646] final\n",
      "[0.   1.09] ytest[i]\n",
      "[0.       1.867648] final\n",
      "[0.         3.17820033] ytest[i]\n",
      "[0.        2.4959087] final\n",
      "[0.    1.072] ytest[i]\n",
      "[0.        1.6231556] final\n",
      "[0.    1.356] ytest[i]\n",
      "[0.        2.1065123] final\n",
      "[0.    1.189] ytest[i]\n",
      "[0.       2.037654] final\n",
      "[0.    1.199] ytest[i]\n",
      "[0.        1.7540945] final\n",
      "[0.    1.345] ytest[i]\n",
      "[0.        1.9246781] final\n",
      "[0.    1.072] ytest[i]\n",
      "[0.        2.2939842] final\n",
      "[0.    1.236] ytest[i]\n",
      "[0.        2.8804693] final\n",
      "[0.    1.235] ytest[i]\n",
      "[0.        2.6364598] final\n",
      "[0.    1.295] ytest[i]\n",
      "[0.        1.7680802] final\n",
      "[0.    1.292] ytest[i]\n",
      "[0.       1.864883] final\n",
      "[0.   1.12] ytest[i]\n",
      "[0.       0.898523] final\n",
      "[0.    1.006] ytest[i]\n",
      "[0.       2.339199] final\n",
      "[0.    1.311] ytest[i]\n",
      "[0.        2.4599593] final\n",
      "[0.    1.009] ytest[i]\n",
      "[0.        2.3520532] final\n",
      "[0.    1.142] ytest[i]\n",
      "[0.        2.3511386] final\n",
      "[0.    1.334] ytest[i]\n",
      "[0.        1.9316831] final\n",
      "[0.    7.889] ytest[i]\n",
      "[0.       3.499536] final\n",
      "[0.    1.147] ytest[i]\n",
      "[0.       2.793973] final\n",
      "[0.   6.99] ytest[i]\n",
      "[0.       3.227243] final\n",
      "[0.    7.811] ytest[i]\n",
      "[0.       3.150504] final\n",
      "[0.    1.328] ytest[i]\n",
      "[0.        2.6815856] final\n",
      "[0.    3.378] ytest[i]\n",
      "[0.        3.0745199] final\n",
      "[0.    4.561] ytest[i]\n",
      "[0.        4.6324096] final\n",
      "[0.    4.817] ytest[i]\n",
      "[0.       3.112032] final\n",
      "[0.    5.181] ytest[i]\n",
      "[0.       5.566163] final\n",
      "[0.    4.595] ytest[i]\n",
      "[0.        2.9747229] final\n",
      "[0.    4.675] ytest[i]\n",
      "[0.        3.6548357] final\n",
      "[0.    6.533] ytest[i]\n",
      "[0.       4.810034] final\n",
      "[0.    0.973] ytest[i]\n",
      "[0.        2.6231363] final\n",
      "[0.    1.275] ytest[i]\n",
      "[0.       2.946398] final\n",
      "[0.    0.986] ytest[i]\n",
      "[0.        2.7955425] final\n",
      "[0.    1.232] ytest[i]\n",
      "[0.        1.9525937] final\n",
      "[0.    1.091] ytest[i]\n",
      "[0.        1.8927265] final\n",
      "[0.    1.278] ytest[i]\n",
      "[0.        2.5108202] final\n",
      "[0.    1.126] ytest[i]\n",
      "[0.        1.7131811] final\n",
      "[0.   1.13] ytest[i]\n",
      "[0.        1.6252724] final\n",
      "[0.    4.312] ytest[i]\n",
      "[0.        3.4724216] final\n",
      "[0.    4.339] ytest[i]\n",
      "[0.        3.5493996] final\n",
      "[0.   4.47] ytest[i]\n",
      "[0.        3.7198205] final\n",
      "[0.    4.602] ytest[i]\n",
      "[0.       3.026029] final\n",
      "[0.    4.688] ytest[i]\n",
      "[0.        2.9743724] final\n",
      "[0.    4.421] ytest[i]\n",
      "[0.       3.332895] final\n",
      "[0.    4.348] ytest[i]\n",
      "[0.        3.9314048] final\n",
      "[0.    5.626] ytest[i]\n",
      "[0.        3.9419324] final\n",
      "[0.    4.638] ytest[i]\n",
      "[0.       3.171058] final\n",
      "[0.    4.435] ytest[i]\n",
      "[0.        3.7513223] final\n",
      "[0.    6.804] ytest[i]\n",
      "[0.        3.5677304] final\n",
      "[0.    4.579] ytest[i]\n",
      "[0.        3.1918097] final\n",
      "[0.    7.985] ytest[i]\n",
      "[0.       3.152923] final\n",
      "[0. 8.] ytest[i]\n",
      "[0.        1.9792043] final\n",
      "[0.    4.138] ytest[i]\n",
      "[0.        1.8349105] final\n",
      "[0.    1.407] ytest[i]\n",
      "[0.        2.4686522] final\n",
      "[0.    7.944] ytest[i]\n",
      "[0.        2.7337146] final\n",
      "[0.   7.68] ytest[i]\n",
      "[0.        3.0677893] final\n",
      "[0.    6.327] ytest[i]\n",
      "[0.       4.219467] final\n",
      "[0.    7.952] ytest[i]\n",
      "[0.        5.1500106] final\n",
      "[0.    4.807] ytest[i]\n",
      "[0.        3.9964173] final\n",
      "[0.    4.819] ytest[i]\n",
      "[0.        3.9092567] final\n",
      "[0.    7.838] ytest[i]\n",
      "[0.       5.846565] final\n",
      "[0.    4.627] ytest[i]\n",
      "[0.        4.4091735] final\n",
      "[0.    1.132] ytest[i]\n",
      "[0.        0.9741042] final\n",
      "[0.    1.121] ytest[i]\n",
      "[0.        1.7628602] final\n",
      "[0.    1.387] ytest[i]\n",
      "[0.       2.452764] final\n",
      "[0.    1.391] ytest[i]\n",
      "[0.        2.2817898] final\n",
      "[0.    7.996] ytest[i]\n",
      "[0.        3.8173256] final\n",
      "[0.    7.983] ytest[i]\n",
      "[0.        3.3488688] final\n",
      "[0.    1.166] ytest[i]\n",
      "[0.        1.2815825] final\n",
      "[0.    1.226] ytest[i]\n",
      "[0.        1.8576884] final\n",
      "[ 0.    -1.906] ytest[i]\n",
      "[0.        1.5194663] final\n",
      "[ 0.    -1.906] ytest[i]\n",
      "[0.        1.5194663] final\n",
      "[ 0.    -1.906] ytest[i]\n",
      "[0.        0.6133225] final\n",
      "[ 0.    -1.906] ytest[i]\n",
      "[0.        0.6133225] final\n",
      "[0.    7.986] ytest[i]\n",
      "[0.       6.018214] final\n",
      "[0. 8.] ytest[i]\n",
      "[0.       5.831432] final\n",
      "[0.    3.232] ytest[i]\n",
      "[0.        2.2686458] final\n",
      "[0.    1.284] ytest[i]\n",
      "[0.        1.8373178] final\n",
      "[0.    7.999] ytest[i]\n",
      "[0.     4.8885] final\n",
      "[0. 8.] ytest[i]\n",
      "[0.        4.0205545] final\n",
      "[0.    7.346] ytest[i]\n",
      "[0.        3.1268663] final\n",
      "[0.    7.566] ytest[i]\n",
      "[0.        3.4849868] final\n",
      "[0.    1.031] ytest[i]\n",
      "[0.        3.5893312] final\n",
      "[0.    1.344] ytest[i]\n",
      "[0.        2.1751685] final\n",
      "[0.    1.047] ytest[i]\n",
      "[0.        3.1640441] final\n",
      "[0.    1.152] ytest[i]\n",
      "[0.        3.6040976] final\n",
      "[0.    1.328] ytest[i]\n",
      "[0.        2.2221742] final\n",
      "[0.    1.328] ytest[i]\n",
      "[0.       2.560404] final\n",
      "[0.    7.978] ytest[i]\n",
      "[0.        2.3201091] final\n",
      "[0.    7.993] ytest[i]\n",
      "[0.        5.8216743] final\n",
      "[0. 8.] ytest[i]\n",
      "[0.        3.5893312] final\n",
      "[0.    1.344] ytest[i]\n",
      "[0.        2.1751685] final\n",
      "[0.    7.997] ytest[i]\n",
      "[0.        3.1640441] final\n",
      "[0.    7.939] ytest[i]\n",
      "[0.        3.6040976] final\n",
      "[0.    7.915] ytest[i]\n",
      "[0.        2.2221742] final\n",
      "[0.    6.798] ytest[i]\n",
      "[0.       2.560404] final\n",
      "[0.    1.236] ytest[i]\n",
      "[0.        2.8804693] final\n",
      "[0.    1.235] ytest[i]\n",
      "[0.        2.6364598] final\n",
      "[0.    4.594] ytest[i]\n",
      "[0.        3.5227299] final\n",
      "[0.    4.499] ytest[i]\n",
      "[0.        3.7324948] final\n",
      "[0.    1.199] ytest[i]\n",
      "[0.       1.737895] final\n",
      "[0.    1.197] ytest[i]\n",
      "[0.        1.5273677] final\n",
      "[0.    1.132] ytest[i]\n",
      "[0.        0.9694415] final\n",
      "[0.    1.011] ytest[i]\n",
      "[0.        0.7216464] final\n",
      "[0.    1.295] ytest[i]\n",
      "[0.        1.7680802] final\n",
      "[0.    1.292] ytest[i]\n",
      "[0.       1.864883] final\n",
      "[0.         3.17820033] ytest[i]\n",
      "[0.        1.9834284] final\n",
      "[0. 8.] ytest[i]\n",
      "[0.       5.928163] final\n",
      "[0. 8.] ytest[i]\n",
      "[0.       5.928163] final\n",
      "[0. 8.] ytest[i]\n",
      "[0.       5.928163] final\n",
      "[0. 8.] ytest[i]\n",
      "[0.       5.928163] final\n",
      "[0.    1.037] ytest[i]\n",
      "[0.        1.5788118] final\n",
      "[0.    1.143] ytest[i]\n",
      "[0.        1.6853267] final\n",
      "[0.    1.045] ytest[i]\n",
      "[0.        2.0165932] final\n",
      "[0.    1.314] ytest[i]\n",
      "[0.        2.3442698] final\n",
      "[0.   1.15] ytest[i]\n",
      "[0.        1.6681265] final\n",
      "[0.   1.32] ytest[i]\n",
      "[0.        1.8262408] final\n",
      "[0.         3.17820033] ytest[i]\n",
      "[0.        1.9292579] final\n",
      "[0.   1.49] ytest[i]\n",
      "[0.        2.7293072] final\n",
      "[0.    7.968] ytest[i]\n",
      "[0.        2.8312511] final\n",
      "[0.    1.271] ytest[i]\n",
      "[0.        1.8056012] final\n",
      "[0.         3.17820033] ytest[i]\n",
      "[0.        1.5216787] final\n",
      "[0.         3.17820033] ytest[i]\n",
      "[0.        1.7950925] final\n",
      "[0.    7.991] ytest[i]\n",
      "[0.        3.0365562] final\n",
      "[0.    1.084] ytest[i]\n",
      "[0.      2.45654] final\n",
      "[0. 8.] ytest[i]\n",
      "[0.       4.780259] final\n",
      "[0.    7.999] ytest[i]\n",
      "[0.        2.2197886] final\n",
      "[0.    7.947] ytest[i]\n",
      "[0.        1.8678476] final\n",
      "[0.    7.873] ytest[i]\n",
      "[0.        1.8583603] final\n",
      "[0.    7.985] ytest[i]\n",
      "[0.        2.4018767] final\n",
      "[0.    7.985] ytest[i]\n",
      "[0.        1.9648843] final\n",
      "[0.    6.701] ytest[i]\n",
      "[0.        1.8618457] final\n",
      "[0.     1.1032] ytest[i]\n",
      "[0.        2.2686458] final\n",
      "[0.    1.284] ytest[i]\n",
      "[0.        1.8373178] final\n",
      "[0.    1.103] ytest[i]\n",
      "[0.     4.8885] final\n",
      "[0.    1.119] ytest[i]\n",
      "[0.        4.0205545] final\n",
      "[0.    1.291] ytest[i]\n",
      "[0.        3.1268663] final\n",
      "[0.    1.416] ytest[i]\n",
      "[0.        3.4849868] final\n",
      "[0.    4.359] ytest[i]\n",
      "[0.       3.774959] final\n",
      "[0.    4.411] ytest[i]\n",
      "[0.       6.034282] final\n",
      "[ 0.        -0.0357344] ytest[i]\n",
      "[0.        2.9559946] final\n",
      "[ 0.        -0.0363828] ytest[i]\n",
      "[0.       3.117415] final\n",
      "[0.   0.05] ytest[i]\n",
      "[0.        3.3608785] final\n",
      "[0.   0.05] ytest[i]\n",
      "[0.        3.8443727] final\n",
      "[0.    4.454] ytest[i]\n",
      "[0.        3.5460026] final\n",
      "[0.    4.515] ytest[i]\n",
      "[0.        3.8180566] final\n",
      "[ 0.        -0.0307969] ytest[i]\n",
      "[0.        3.2675707] final\n",
      "[ 0.        -0.0298594] ytest[i]\n",
      "[0.        3.4183376] final\n",
      "[0.    1.301] ytest[i]\n",
      "[0.        1.9359599] final\n",
      "[0.    1.128] ytest[i]\n",
      "[0.       1.817822] final\n",
      "[0. 8.] ytest[i]\n",
      "[0.       3.810496] final\n",
      "[0.    6.129] ytest[i]\n",
      "[0.        3.0926642] final\n",
      "[0. 8.] ytest[i]\n",
      "[0.        2.9301116] final\n",
      "[0. 8.] ytest[i]\n",
      "[0.       7.652622] final\n",
      "[0. 8.] ytest[i]\n",
      "[0.        3.6286895] final\n",
      "[0. 8.] ytest[i]\n",
      "[0.        2.8160827] final\n",
      "[0.   1.19] ytest[i]\n",
      "[0.        1.9884468] final\n",
      "[0.    1.178] ytest[i]\n",
      "[0.        1.8836726] final\n",
      "[0.    7.141] ytest[i]\n",
      "[0.       5.883476] final\n",
      "[0.    6.776] ytest[i]\n",
      "[0.        4.9452653] final\n",
      "[0.    7.415] ytest[i]\n",
      "[0.       4.234075] final\n",
      "[0.    7.987] ytest[i]\n",
      "[0.       5.387691] final\n",
      "[0.   7.87] ytest[i]\n",
      "[0.        5.0901465] final\n",
      "[0.    7.924] ytest[i]\n",
      "[0.        5.5442934] final\n",
      "[0.    7.999] ytest[i]\n",
      "[0.       4.130108] final\n",
      "[0.    7.997] ytest[i]\n",
      "[0.        3.8476303] final\n",
      "[0.    7.999] ytest[i]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.        5.0979724] final\n",
      "[0.    7.993] ytest[i]\n",
      "[0.       6.507432] final\n",
      "[0.    7.991] ytest[i]\n",
      "[0.        4.4756384] final\n",
      "[0.   7.99] ytest[i]\n",
      "[0.        3.9657962] final\n",
      "[0.   1.19] ytest[i]\n",
      "[0.        1.9884468] final\n",
      "[0.    1.178] ytest[i]\n",
      "[0.        1.8836726] final\n",
      "[0.    1.101] ytest[i]\n",
      "[0.       2.257595] final\n",
      "[0.    7.689] ytest[i]\n",
      "[0.        3.3865669] final\n",
      "[0.    1.263] ytest[i]\n",
      "[0.        2.3409686] final\n",
      "[0.    1.233] ytest[i]\n",
      "[0.        1.8500764] final\n",
      "[0.    7.805] ytest[i]\n",
      "[0.        3.2929688] final\n",
      "[0.    1.263] ytest[i]\n",
      "[0.        2.2353003] final\n",
      "[0.    1.199] ytest[i]\n",
      "[0.       1.737895] final\n",
      "[0.    1.197] ytest[i]\n",
      "[0.        1.5273677] final\n",
      "[0.  1.3] ytest[i]\n",
      "[0.        1.6921093] final\n",
      "[0.   1.28] ytest[i]\n",
      "[0.        1.8401065] final\n",
      "[0.    1.079] ytest[i]\n",
      "[0.        2.3543189] final\n",
      "[0.    1.082] ytest[i]\n",
      "[0.        2.5081098] final\n",
      "[0.    1.428] ytest[i]\n",
      "[0.        2.5379424] final\n",
      "[0.    1.246] ytest[i]\n",
      "[0.        2.0379593] final\n",
      "[0.    1.339] ytest[i]\n",
      "[0.        2.5754755] final\n",
      "[0.    1.086] ytest[i]\n",
      "[0.        1.9698304] final\n",
      "[0.    0.991] ytest[i]\n",
      "[0.        3.3312383] final\n",
      "[0.    6.784] ytest[i]\n",
      "[0.        3.2076998] final\n",
      "[0.   0.05] ytest[i]\n",
      "[0.        2.5590136] final\n",
      "[0.   0.05] ytest[i]\n",
      "[0.       3.118202] final\n",
      "[0.   0.05] ytest[i]\n",
      "[0.        3.3392353] final\n",
      "[0.   0.05] ytest[i]\n",
      "[0.        2.5275683] final\n",
      "[0.   0.05] ytest[i]\n",
      "[0.       2.981909] final\n",
      "[0.   0.05] ytest[i]\n",
      "[0.        2.9076884] final\n",
      "[0.    4.259] ytest[i]\n",
      "[0.        3.6742115] final\n",
      "[0.    4.557] ytest[i]\n",
      "[0.        3.1039817] final\n",
      "[0.    4.666] ytest[i]\n",
      "[0.        2.8858063] final\n",
      "[0.    4.396] ytest[i]\n",
      "[0.       3.174009] final\n",
      "[0.    4.476] ytest[i]\n",
      "[0.        3.4867687] final\n",
      "[0.    4.336] ytest[i]\n",
      "[0.        3.5698671] final\n",
      "[0.    4.483] ytest[i]\n",
      "[0.       3.340324] final\n",
      "[0.    4.617] ytest[i]\n",
      "[0.        3.6633835] final\n",
      "[0.    4.788] ytest[i]\n",
      "[0.       4.343599] final\n",
      "[0.    4.619] ytest[i]\n",
      "[0.        3.3302193] final\n",
      "[0.    4.726] ytest[i]\n",
      "[0.        2.8942025] final\n",
      "[0.    4.456] ytest[i]\n",
      "[0.        3.2400644] final\n",
      "[0.    0.992] ytest[i]\n",
      "[0.        3.7429488] final\n",
      "[0.    1.102] ytest[i]\n",
      "[0.       1.733591] final\n",
      "[0.    1.111] ytest[i]\n",
      "[0.        3.2277257] final\n",
      "[0.    1.268] ytest[i]\n",
      "[0.        1.3601921] final\n",
      "[0.    0.988] ytest[i]\n",
      "[0.        2.5315034] final\n",
      "[0.    1.269] ytest[i]\n",
      "[0.        4.0593224] final\n",
      "[0.    1.333] ytest[i]\n",
      "[0.        2.2272856] final\n",
      "[0.    1.335] ytest[i]\n",
      "[0.        2.0884726] final\n",
      "[0.  1.3] ytest[i]\n",
      "[0.        1.6921093] final\n",
      "[0.   1.28] ytest[i]\n",
      "[0.        1.8401065] final\n",
      "[0. 8.] ytest[i]\n",
      "[0.       5.928163] final\n",
      "[0. 8.] ytest[i]\n",
      "[0.       5.928163] final\n",
      "[0.    1.132] ytest[i]\n",
      "[0.        0.9741042] final\n",
      "[0.    1.121] ytest[i]\n",
      "[0.        1.7628602] final\n",
      "[0.    1.208] ytest[i]\n",
      "[0.        2.0306482] final\n",
      "[0.    1.234] ytest[i]\n",
      "[0.        1.1863377] final\n",
      "[0.    1.072] ytest[i]\n",
      "[0.        3.5785112] final\n",
      "[0.    1.053] ytest[i]\n",
      "[0.       2.061329] final\n",
      "[0.    0.934] ytest[i]\n",
      "[0.        2.1999624] final\n",
      "[0.    0.953] ytest[i]\n",
      "[0.        1.7794464] final\n",
      "[0.         3.17820033] ytest[i]\n",
      "[0.        3.6529539] final\n",
      "[0.         3.17820033] ytest[i]\n",
      "[0.        1.9834284] final\n",
      "[0.         3.17820033] ytest[i]\n",
      "[0.        1.9834284] final\n",
      "[0.         3.17820033] ytest[i]\n",
      "[0.        3.2911637] final\n",
      "[0.         3.17820033] ytest[i]\n",
      "[0.        3.9212584] final\n",
      "[0.         3.17820033] ytest[i]\n",
      "[0.        1.9834284] final\n",
      "[0.         3.17820033] ytest[i]\n",
      "[0.        1.9834284] final\n",
      "[0.         3.17820033] ytest[i]\n",
      "[0.        3.9926474] final\n",
      "[0.         3.17820033] ytest[i]\n",
      "[0.        1.9834284] final\n",
      "[0.    1.037] ytest[i]\n",
      "[0.        1.5788118] final\n",
      "[0.    1.143] ytest[i]\n",
      "[0.        1.6853267] final\n",
      "[0.    1.045] ytest[i]\n",
      "[0.        2.0165932] final\n",
      "[0.    1.314] ytest[i]\n",
      "[0.        2.3442698] final\n",
      "[0.   1.15] ytest[i]\n",
      "[0.        1.6681265] final\n",
      "[0.   1.32] ytest[i]\n",
      "[0.        1.8262408] final\n",
      "[0.   1.04] ytest[i]\n",
      "[0.        1.9613482] final\n",
      "[0.    1.235] ytest[i]\n",
      "[0.        2.9939415] final\n",
      "[0.   1.24] ytest[i]\n",
      "[0.        3.0386426] final\n",
      "[0.    0.971] ytest[i]\n",
      "[0.        2.0772552] final\n",
      "[0.    0.966] ytest[i]\n",
      "[0.        2.0842965] final\n",
      "[0.    1.181] ytest[i]\n",
      "[0.        1.9364352] final\n",
      "[0.    1.355] ytest[i]\n",
      "[0.       1.931717] final\n",
      "[0.   1.15] ytest[i]\n",
      "[0.      1.89839] final\n",
      "[0. 8.] ytest[i]\n",
      "[0.       5.928163] final\n",
      "[0. 8.] ytest[i]\n",
      "[0.       5.928163] final\n",
      "[0. 8.] ytest[i]\n",
      "[0.       5.928163] final\n",
      "[0. 8.] ytest[i]\n",
      "[0.       5.928163] final\n",
      "[0. 8.] ytest[i]\n",
      "[0.       5.928163] final\n",
      "[0. 8.] ytest[i]\n",
      "[0.       5.928163] final\n",
      "[0.   1.12] ytest[i]\n",
      "[0.       0.898523] final\n",
      "[0.    1.006] ytest[i]\n",
      "[0.       2.339199] final\n",
      "[0.    1.311] ytest[i]\n",
      "[0.        2.4599593] final\n",
      "[0.    1.009] ytest[i]\n",
      "[0.        2.3520532] final\n",
      "[0.    1.142] ytest[i]\n",
      "[0.        2.3511386] final\n",
      "[0.    1.334] ytest[i]\n",
      "[0.        1.9316831] final\n",
      "[0.    1.187] ytest[i]\n",
      "[0.        1.8365564] final\n",
      "[0.    1.125] ytest[i]\n",
      "[0.      3.01979] final\n",
      "[0.     1.1829] ytest[i]\n",
      "[0.        2.8616242] final\n",
      "[0.     1.0435] ytest[i]\n",
      "[0.        2.2131197] final\n",
      "[0.    1.433] ytest[i]\n",
      "[0.       2.012831] final\n",
      "[0.    1.292] ytest[i]\n",
      "[0.        2.6168594] final\n",
      "[0.    1.187] ytest[i]\n",
      "[0.        1.8365564] final\n",
      "[0. 8.] ytest[i]\n",
      "[0.      3.01979] final\n",
      "[0.         3.17820033] ytest[i]\n",
      "[0.        1.9834284] final\n",
      "[0.    7.999] ytest[i]\n",
      "[0.        2.8616242] final\n",
      "[0.    2.435] ytest[i]\n",
      "[0.        2.2131197] final\n",
      "[0.    1.433] ytest[i]\n",
      "[0.       2.012831] final\n",
      "[0. 8.] ytest[i]\n",
      "[0.        2.6168594] final\n",
      "[ 0.    -1.906] ytest[i]\n",
      "[0.        1.9292579] final\n",
      "[ 0.    -1.906] ytest[i]\n",
      "[0.        1.9292579] final\n",
      "[0.    1.143] ytest[i]\n",
      "[0.        2.6178796] final\n",
      "[0.    1.412] ytest[i]\n",
      "[0.        2.4983761] final\n",
      "[0.    1.126] ytest[i]\n",
      "[0.        2.9855428] final\n",
      "[0.    1.417] ytest[i]\n",
      "[0.        2.6200492] final\n",
      "[0.    1.279] ytest[i]\n",
      "[0.        1.9320276] final\n",
      "[0.    1.202] ytest[i]\n",
      "[0.        1.9131228] final\n",
      "[0.    1.189] ytest[i]\n",
      "[0.        2.0804763] final\n",
      "[0.    1.317] ytest[i]\n",
      "[0.        2.1163728] final\n",
      "[ 0.    -1.906] ytest[i]\n",
      "[0.       0.992338] final\n",
      "[0.   1.02] ytest[i]\n",
      "[0.        1.1345428] final\n",
      "[0.    1.079] ytest[i]\n",
      "[0.        2.3543189] final\n",
      "[0.    1.082] ytest[i]\n",
      "[0.        2.5081098] final\n",
      "[0.    1.355] ytest[i]\n",
      "[0.       1.931717] final\n",
      "[0.   7.24] ytest[i]\n",
      "[0.      1.89839] final\n",
      "[0.    1.006] ytest[i]\n",
      "[0.        2.5040781] final\n",
      "[0.    0.982] ytest[i]\n",
      "[0.        2.6639376] final\n",
      "[0.    1.115] ytest[i]\n",
      "[0.        1.9078714] final\n",
      "[0.    1.415] ytest[i]\n",
      "[0.       2.518459] final\n",
      "[0.    1.453] ytest[i]\n",
      "[0.        2.6199615] final\n",
      "[0.    1.123] ytest[i]\n",
      "[0.        1.9043589] final\n",
      "[0.    1.037] ytest[i]\n",
      "[0.        1.5788118] final\n",
      "[0.    1.143] ytest[i]\n",
      "[0.        1.6853267] final\n",
      "[0.    1.045] ytest[i]\n",
      "[0.        2.0165932] final\n",
      "[0.    1.314] ytest[i]\n",
      "[0.        2.3442698] final\n",
      "[0.   1.15] ytest[i]\n",
      "[0.        1.6681265] final\n",
      "[0.   1.32] ytest[i]\n",
      "[0.        1.8262408] final\n",
      "[ 0.    -1.906] ytest[i]\n",
      "[0.        1.9834284] final\n",
      "[ 0.    -1.906] ytest[i]\n",
      "[0.        1.9834284] final\n",
      "[ 0.    -1.906] ytest[i]\n",
      "[0.        1.9834284] final\n",
      "[ 0.    -1.906] ytest[i]\n",
      "[0.        1.9834284] final\n",
      "[ 0.    -1.906] ytest[i]\n",
      "[0.        1.9834284] final\n",
      "[ 0.    -1.906] ytest[i]\n",
      "[0.        1.9834284] final\n",
      "[0.    1.072] ytest[i]\n",
      "[0.        1.6231556] final\n",
      "[0.    1.356] ytest[i]\n",
      "[0.        2.1065123] final\n",
      "[0.    1.189] ytest[i]\n",
      "[0.       2.037654] final\n",
      "[0.    1.199] ytest[i]\n",
      "[0.        1.7540945] final\n",
      "[0.    1.345] ytest[i]\n",
      "[0.        1.9246781] final\n",
      "[0.    1.072] ytest[i]\n",
      "[0.        2.2939842] final\n",
      "[0.  1.2] ytest[i]\n",
      "[0.       1.494048] final\n",
      "[0.    1.194] ytest[i]\n",
      "[0.       1.531153] final\n",
      "[0.    1.166] ytest[i]\n",
      "[0.        3.2392282] final\n",
      "[0.   7.28] ytest[i]\n",
      "[0.        2.4876137] final\n",
      "[0.   1.24] ytest[i]\n",
      "[0.        1.9646473] final\n",
      "[0.    1.002] ytest[i]\n",
      "[0.        2.6145346] final\n",
      "[0.    1.441] ytest[i]\n",
      "[0.       2.496419] final\n",
      "[0.    7.583] ytest[i]\n",
      "[0.        3.3401675] final\n",
      "[0.    0.955] ytest[i]\n",
      "[0.        1.4092813] final\n",
      "[0.    0.962] ytest[i]\n",
      "[0.        1.6401265] final\n",
      "[0.    7.969] ytest[i]\n",
      "[0.       5.569941] final\n",
      "[0.    7.976] ytest[i]\n",
      "[0.        3.5304735] final\n",
      "[0.   1.26] ytest[i]\n",
      "[0.        1.9685537] final\n",
      "[0.   1.13] ytest[i]\n",
      "[0.        3.0934677] final\n",
      "[0.    1.269] ytest[i]\n",
      "[0.        2.2702448] final\n",
      "[0.    1.123] ytest[i]\n",
      "[0.        2.6041193] final\n",
      "[0.    1.415] ytest[i]\n",
      "[0.       2.626695] final\n",
      "[0.    1.418] ytest[i]\n",
      "[0.        2.4821231] final\n",
      "[ 0.    -1.906] ytest[i]\n",
      "[0.        0.6881946] final\n",
      "[0.    1.026] ytest[i]\n",
      "[0.        0.7693909] final\n",
      "[ 0.    -1.906] ytest[i]\n",
      "[0.        1.9292579] final\n",
      "[ 0.    -1.906] ytest[i]\n",
      "[0.        1.9292579] final\n",
      "[0.    4.654] ytest[i]\n",
      "[0.       4.179577] final\n",
      "[0.    7.999] ytest[i]\n",
      "[0.       4.903207] final\n",
      "[0.    4.461] ytest[i]\n",
      "[0.       3.533871] final\n",
      "[0.    4.528] ytest[i]\n",
      "[0.        3.6534197] final\n",
      "[0.    7.955] ytest[i]\n",
      "[0.        4.1803894] final\n",
      "[0.    7.973] ytest[i]\n",
      "[0.        4.5583005] final\n",
      "[0.    4.533] ytest[i]\n",
      "[0.        3.5899901] final\n",
      "[0.    4.517] ytest[i]\n",
      "[0.        3.9071138] final\n",
      "4.579 3.1918097\n",
      "0.41625700153556255 stabilization time\n"
     ]
    }
   ],
   "source": [
    "Final = []\n",
    "for i in range(len(y_train_c)):\n",
    "  \n",
    "    print(y_train_c[i],\"ytest[i]\")\n",
    "#     print(X_train_c[i])\n",
    "    \n",
    "    X_c = (scaler_rob_x.transform(X_train_c[i].reshape(1, -1)))\n",
    "\n",
    "#     print(X_c)\n",
    "    I = factor_fit.transform(X_c[:,0:10000])\n",
    "    I = np.concatenate((I,X_c[:,10000:10002]),axis=1)\n",
    "#   print(I.shape,\"I shape\")\n",
    "\n",
    "    pred_c = model1.predict(I)\n",
    "#     print(pred_c,\"pred_c.shape\")\n",
    "  \n",
    " \n",
    "\n",
    "  \n",
    "    final = scaler_rob_y.inverse_transform(pred_c.reshape(1, -1))\n",
    "#     print(final,\"final\")                               \n",
    "    final[0][0]= np.abs(np.round(final[0][0]))\n",
    "    #     print(final[0],\"final\")\n",
    "    k=[]\n",
    "    k.append(final[0][0])\n",
    "    k.append(final[0][1])\n",
    "    Final.append(k)\n",
    "\n",
    "\n",
    "                                          \n",
    "    print(final[0],\"final\")\n",
    "\n",
    "    h = abs(final[0]-y_train_c[i])\n",
    "Final_np = np.asarray(Final, dtype=np.float32)    \n",
    "# print(Final)\n",
    "print(y_train_c[100,1], Final_np[100,1])\n",
    "r2_time = r2_score(y_train_c[:,1], Final_np[:,1]) \n",
    "print(r2_time,\"stabilization time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "mc1vcYm9k37j",
    "outputId": "7e978f24-b2ff-416d-98b6-d6f3120736d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-0.20955849, -0.02966004, -0.06975824, -0.34044018,  0.40840343,\n",
      "         0.45637697,  0.08439308,  0.04427025,  0.05986654,  0.05042548,\n",
      "        -0.01051738,  0.5808257 , -0.04833255, -0.1133244 ,  0.09665569,\n",
      "        -0.21972431,  0.14838968, -0.09666391,  0.15851472,  0.6243187 ,\n",
      "         0.19580579,  0.10410159, -0.12963115, -0.02007479, -0.02929221,\n",
      "        -0.03490636,  0.15399024, -0.04794594,  0.30970612, -0.25512654],\n",
      "       [-0.2692955 ,  0.11101212,  0.41239008, -0.22651969, -0.11869007,\n",
      "        -0.26197487, -0.45282212,  0.2882518 ,  0.69426423,  0.6580187 ,\n",
      "        -0.23986813, -0.10433193, -0.07800017,  0.40982825, -0.0133964 ,\n",
      "         0.40459913,  0.81252456,  0.46724272, -0.4345396 , -0.11254603,\n",
      "         0.00721032, -0.06135016, -0.293448  ,  0.42018336, -0.24144791,\n",
      "         0.38162234,  0.45105076, -0.06017541, -0.17206928, -0.10095539],\n",
      "       [ 0.06935041,  0.19266202,  0.22879039,  0.12276103,  0.22223496,\n",
      "        -0.01010104, -0.20634282,  0.31755918,  0.06457499, -0.12532756,\n",
      "        -0.48384196,  0.26721132,  0.1941238 , -0.39132494,  0.21459657,\n",
      "         0.15302333,  0.20355621,  0.0299382 ,  0.14190817,  0.17828228,\n",
      "        -0.41135854, -0.01030684,  0.0212538 ,  0.4097437 ,  0.22760798,\n",
      "         0.17752707,  0.07901642,  0.2252975 ,  0.40837628,  0.68580097],\n",
      "       [-0.39383933, -0.13833319, -0.01261484,  0.34563074, -0.01447209,\n",
      "        -0.47077057,  0.43562204, -0.05917425, -0.00297554,  0.32919484,\n",
      "         0.30804753, -0.23898473,  0.00950595, -0.3473324 ,  0.23778494,\n",
      "         0.24268666, -0.25153822,  0.5831654 , -0.5418209 , -0.07573769,\n",
      "        -0.25827292, -0.30525148,  0.02502103,  0.1220995 ,  0.6552415 ,\n",
      "         0.02457703,  0.0479733 , -0.16227366,  0.04407619,  0.37821826],\n",
      "       [-0.1276707 ,  0.0119107 ,  0.15897918, -0.40848276, -0.06928039,\n",
      "         0.344176  , -0.43969953, -0.3670755 , -0.3126821 , -0.25973383,\n",
      "         0.02555434, -0.14415449,  0.33371156,  0.20282516,  0.3873246 ,\n",
      "        -0.1847561 , -0.30122584, -0.19746272,  0.13131589,  0.03955678,\n",
      "         0.17279597,  0.17425515,  0.3498885 ,  0.35259315, -0.08983305,\n",
      "        -0.6218774 ,  0.34313953, -0.06054851, -0.06703403,  0.22456138],\n",
      "       [-0.24709855,  0.22390293,  0.03032375, -0.55331916,  0.381478  ,\n",
      "         0.47066507,  0.26181322,  0.25355926,  0.0687631 , -0.40872675,\n",
      "        -0.42740276, -0.1503691 , -0.21663311,  0.07448681,  0.21847828,\n",
      "        -0.11913515, -0.34977722,  0.25501114,  0.03334626,  0.14271483,\n",
      "        -0.162057  ,  0.34825882,  0.06818794,  0.2530282 , -0.46729794,\n",
      "        -0.2879672 , -0.22225574,  0.07583486,  0.11682244,  0.32696992],\n",
      "       [-0.16118556,  0.3661837 , -0.50084704, -0.14907193,  0.25273448,\n",
      "        -0.16061884,  0.19605131,  0.13051197,  0.1334159 , -0.1853419 ,\n",
      "         0.06925961, -0.22162338,  0.29704347,  0.17310396,  0.12473069,\n",
      "        -0.25895023, -0.22078371, -0.44233426,  0.30350134,  0.06724489,\n",
      "         0.2914562 , -0.06681705,  0.04682426,  0.16142152, -0.3727444 ,\n",
      "         0.33236593,  0.5412369 , -0.30648172, -0.14767559, -0.32138687],\n",
      "       [-0.2806511 , -0.3898463 ,  0.08325934, -0.26531544,  0.13596867,\n",
      "         0.0876102 , -0.70613694,  0.43067616,  0.16365053,  0.1420945 ,\n",
      "        -0.06879557,  0.13010329, -0.35796466, -0.29820666, -0.10585025,\n",
      "         0.37564868,  0.17891543, -0.26054907,  0.38355225, -0.01599678,\n",
      "         0.05110464,  0.19445756,  0.34511232, -0.10672504, -0.02948527,\n",
      "        -0.16098286, -0.3298189 , -0.37103662,  0.052465  , -0.13497433],\n",
      "       [-0.11646651, -0.33610252, -0.27129495,  0.3335243 ,  0.09881666,\n",
      "        -0.24299923,  0.02801656, -0.14571863,  0.18598974,  0.08436794,\n",
      "         0.06952532, -0.32181606,  0.17798819,  0.0123282 , -0.34073037,\n",
      "        -0.49853793,  0.19425711,  0.16946127,  0.12140413,  0.34477192,\n",
      "        -0.35676977, -0.23753615,  0.16115373,  0.09856067,  0.22919998,\n",
      "        -0.39628246,  0.19158562,  0.17280973,  0.27753478,  0.12391881],\n",
      "       [ 0.20611288,  0.10750338, -0.29905275, -0.1000968 ,  0.48768663,\n",
      "         0.430129  , -0.33258837, -0.18002583, -0.14924511, -0.31453857,\n",
      "        -0.4121945 ,  0.46511862, -0.23536992,  0.3546094 , -0.08495636,\n",
      "        -0.04123687,  0.0513082 ,  0.27349433,  0.40541232,  0.23984739,\n",
      "         0.34232205, -0.06571517, -0.15420069,  0.30705673,  0.19194056,\n",
      "         0.16083543,  0.22411631, -0.05326078,  0.63737607,  0.28736037],\n",
      "       [-0.24952394,  0.09515994, -0.18932012,  0.00744358,  0.20933162,\n",
      "        -0.35368392,  0.06623802,  0.42972583,  0.3159168 ,  0.00931338,\n",
      "        -0.05916566,  0.02386501, -0.13963476,  0.5644105 , -0.49805948,\n",
      "        -0.3753315 , -0.06829406,  0.48121512, -0.06550268, -0.09006829,\n",
      "         0.54564553, -0.16426867,  0.00981045,  0.6024809 ,  0.1372826 ,\n",
      "         0.318572  ,  0.6565934 , -0.05510089, -0.06550772,  0.38965523],\n",
      "       [-0.2863968 ,  0.20143215, -0.03018151,  0.25571162,  0.1409002 ,\n",
      "        -0.00369998,  0.07615761, -0.06958259,  0.3435146 ,  0.11772843,\n",
      "         0.05902846, -0.04190429,  0.09179879, -0.40360832,  0.19238003,\n",
      "         0.03841868, -0.20871235, -0.20203929,  0.3799885 ,  0.11709695,\n",
      "        -0.2929023 , -0.32543328,  0.44165817,  0.1362273 , -0.33112842,\n",
      "        -0.06983399, -0.5864401 ,  0.18636419, -0.07087538, -0.48449698],\n",
      "       [-0.00121069, -0.4616152 , -0.00089694, -0.22846726, -0.2763752 ,\n",
      "        -0.33531502,  0.11088337,  0.64796257,  0.19146901, -0.1421265 ,\n",
      "        -0.6421164 ,  0.3672984 , -0.05980392, -0.16656098, -0.26040956,\n",
      "        -0.38872224, -0.18483287,  0.74775034,  0.43908504, -0.3285507 ,\n",
      "         0.18994685,  0.24035466,  0.03388277, -0.01272003,  0.12198836,\n",
      "        -0.07804342, -0.47834545,  0.11832128, -0.06141535,  0.2795252 ],\n",
      "       [ 0.47599396,  0.48554468,  0.20349158, -0.21281128, -0.24470364,\n",
      "        -0.06434289,  0.09897637, -0.11206733,  0.03850086,  0.05407755,\n",
      "         0.33809692, -0.26949322, -0.3385224 ,  0.19214195, -0.27747682,\n",
      "         0.122325  ,  0.21806313,  0.00878374,  0.29274085,  0.02480074,\n",
      "         0.23304068, -0.12267081,  0.4087033 , -0.2003351 ,  0.30301097,\n",
      "        -0.33214778, -0.504566  , -0.7742723 , -0.31160298, -0.14141361],\n",
      "       [-0.4759481 ,  0.12999888, -0.31386104,  0.05553366, -0.3527665 ,\n",
      "        -0.03969431,  0.19114761,  0.29498067,  0.45021778,  0.46894434,\n",
      "        -0.46660772,  0.04432239, -0.01720004, -0.45669866, -0.05886248,\n",
      "         0.36621225,  0.05070715, -0.47276214,  0.02078471, -0.6044042 ,\n",
      "        -0.01606443,  0.01870706,  0.5308826 , -0.0708923 , -0.1212313 ,\n",
      "         0.1290597 , -0.13921772, -0.02735277,  0.11309119,  0.17619643],\n",
      "       [ 0.5301451 ,  0.4912703 ,  0.5131964 , -0.15810655,  0.19908641,\n",
      "         0.31261075, -0.04130198,  0.0051302 ,  0.01849243,  0.27959698,\n",
      "         0.6660219 , -0.19008592, -0.33064455,  0.27917883,  0.0259387 ,\n",
      "         0.44648153, -0.20958585,  0.26417223,  0.27078453, -0.29974508,\n",
      "         0.18944609, -0.17250961,  0.08981726, -0.10913121,  0.5508025 ,\n",
      "         0.23118262,  0.07364039, -0.1132293 , -0.04008906,  0.13805239],\n",
      "       [-0.6643846 , -0.23252518,  0.00311887, -0.10984798, -0.15786792,\n",
      "        -0.06382223,  0.09315167,  0.08238348,  0.2625753 , -0.08402357,\n",
      "         0.12809078, -0.0565674 , -0.06227369,  0.3718325 ,  0.3202302 ,\n",
      "         0.19274966, -0.65956634,  0.24709697,  0.38612393,  0.32182145,\n",
      "        -0.25225565, -0.24540806,  0.12970199, -0.0841685 , -0.01993249,\n",
      "        -0.54327875, -0.27907938, -0.19337219, -0.08523237,  0.08634692],\n",
      "       [-0.33760583,  0.05554096, -0.03126807, -0.23780063,  0.527885  ,\n",
      "         0.09503336, -0.12802282,  0.11845202,  0.06956027,  0.54372007,\n",
      "         0.17896624,  0.09652596, -0.665793  , -0.41901496,  0.0753486 ,\n",
      "        -0.12778533, -0.16235848, -0.04121208, -0.47485226,  0.24267533,\n",
      "         0.20959641,  0.06652298,  0.10562566, -0.1227679 , -0.10256507,\n",
      "         0.05568441, -0.25697413,  0.14987223, -0.12354377, -0.35385755],\n",
      "       [-0.04252739,  0.1537779 , -0.67797565, -0.09420327, -0.0727165 ,\n",
      "        -0.06470886,  0.32356215,  0.11250363,  0.09826633, -0.00541785,\n",
      "         0.11943774,  0.02025421,  0.03742326,  0.22146732,  0.55276036,\n",
      "         0.22731443, -0.3661291 ,  0.21300755, -0.0359478 , -0.19503684,\n",
      "        -0.16469222, -0.05367049, -0.21839018, -0.14908463, -0.16440484,\n",
      "        -0.10628442,  0.43183276,  0.24273051,  0.08675397,  0.8308548 ],\n",
      "       [-0.04608797,  0.14952502, -0.30819932, -0.38934842, -0.05653849,\n",
      "         0.3067325 ,  0.35539377,  0.49495083,  0.46016854,  0.01853028,\n",
      "         0.00107027, -0.35476574,  0.2752318 ,  0.25165612,  0.39809704,\n",
      "        -0.0524884 , -0.04268807, -0.33583087, -0.33160946,  0.16347295,\n",
      "         0.0583525 , -0.0674897 ,  0.03579535, -0.0913494 , -0.10223268,\n",
      "        -0.00484926,  0.2308173 , -0.02758732, -0.10357568, -0.26300412],\n",
      "       [ 0.4644601 ,  0.06945229, -0.14536804,  0.38097212,  0.2976622 ,\n",
      "        -0.18359828,  0.25362602,  0.03424013,  0.5887642 , -0.27306262,\n",
      "        -0.18465763, -0.13555725, -0.01326906, -0.4940835 ,  0.05414316,\n",
      "         0.22194077,  0.30721253, -0.19038716,  0.338185  , -0.07677069,\n",
      "        -0.24856097, -0.29735953, -0.2708035 ,  0.02989533,  0.46542883,\n",
      "         0.18502456, -0.0124811 , -0.09204964,  0.14856002, -0.21255699],\n",
      "       [ 0.37078702, -0.25924572,  0.6165107 , -0.33847708, -0.31862333,\n",
      "         0.1505715 ,  0.02242199, -0.12820895, -0.35900095,  0.23105145,\n",
      "        -0.04794998, -0.05615981, -0.49579605, -0.24206261, -0.4559225 ,\n",
      "         0.0850527 ,  0.50480145,  0.14052658, -0.32191485, -0.70955455,\n",
      "         0.14522238,  0.45157227,  0.3816322 ,  0.31249216,  0.4756661 ,\n",
      "         0.29219604, -0.10100514, -0.16961198, -0.0787226 ,  0.18754657],\n",
      "       [ 0.61849374,  0.4387492 ,  0.30457166,  0.04395619,  0.06077307,\n",
      "         0.43717304,  0.13690613, -0.4844827 ,  0.22724596, -0.2305921 ,\n",
      "         0.23251319, -0.09789479, -0.33720368,  0.29445583, -0.08562927,\n",
      "        -0.49430898,  0.22721028, -0.3223794 ,  0.0536832 ,  0.12321921,\n",
      "        -0.20352873,  0.35905266, -0.6240969 ,  0.39120424, -0.15462555,\n",
      "        -0.34290466, -0.06094559, -0.16857038,  0.05833126,  0.5735446 ],\n",
      "       [ 0.04452085,  0.18832321, -0.47836614, -0.37811744, -0.24349457,\n",
      "         0.30277905,  0.15885451,  0.12551814, -0.07535368,  0.10937895,\n",
      "         0.18637739,  0.02703759,  0.04177833,  0.0122852 , -0.14480595,\n",
      "        -0.17055956, -0.20155312, -0.00295933, -0.2715022 ,  0.2615133 ,\n",
      "         0.07254849,  0.53852737, -0.0994013 , -0.05414369, -0.17219482,\n",
      "        -0.13712527,  0.03189334,  0.1767474 , -0.05395218, -0.06510402],\n",
      "       [ 0.06330553, -0.02112824, -0.45363697, -0.0966645 ,  0.09315324,\n",
      "        -0.09679334, -0.0743563 , -0.08502545, -0.3338613 ,  0.0776254 ,\n",
      "        -0.56176084, -0.14751709,  0.6067875 ,  0.2577383 ,  0.30632493,\n",
      "         0.13729805,  0.124175  ,  0.24603504, -0.03868427, -0.37904605,\n",
      "        -0.11808325, -0.4467211 ,  0.00392217, -0.1768751 ,  0.2049263 ,\n",
      "         0.23661532,  0.08726558, -0.22526477, -0.12347345, -0.03464192],\n",
      "       [ 0.09986578,  0.2708639 ,  0.0961237 , -0.00363368, -0.23218106,\n",
      "         0.3895363 ,  0.02539434,  0.08990414,  0.15275185, -0.23808768,\n",
      "        -0.15074603,  0.2311842 , -0.09926993,  0.18753542, -0.524007  ,\n",
      "         0.16059768, -0.25494257,  0.05561017,  0.03556512, -0.17718026,\n",
      "         0.17489575, -0.15417185, -0.1254586 ,  0.35143444, -0.00450941,\n",
      "         0.284716  ,  0.29871392,  0.20085517, -0.38957044,  0.03012739],\n",
      "       [-0.34623668, -0.05044958, -0.01646839, -0.0262689 ,  0.70460117,\n",
      "         0.10166454,  0.06958742,  0.00265031,  0.31853712,  0.2326871 ,\n",
      "        -0.3196077 ,  0.31949943, -0.40626267,  0.19877641, -0.2994942 ,\n",
      "         0.30502713, -0.10536864,  0.4532632 , -0.19480088, -0.39562148,\n",
      "         0.18096474,  0.01078624,  0.44916695,  0.2856372 ,  0.34140554,\n",
      "        -0.1383291 , -0.45383033,  0.5601804 , -0.04297568,  0.09535702],\n",
      "       [ 0.19513267,  0.24268737, -0.06779083,  0.02313789, -0.5065451 ,\n",
      "         0.47348538, -0.18299419,  0.07506059, -0.22848438, -0.0936247 ,\n",
      "        -0.67660666, -0.03929476,  0.06169136,  0.48648778, -0.11111895,\n",
      "        -0.14637825, -0.10005277, -0.17838581, -0.2579579 ,  0.3025965 ,\n",
      "        -0.07807501,  0.37409657,  0.52293503,  0.06529969,  0.13334522,\n",
      "        -0.02261982, -0.47931296,  0.26902723, -0.02605858, -0.24801369],\n",
      "       [-0.22483553,  0.10586698,  0.1648472 ,  0.20272748,  0.21191332,\n",
      "         0.16540939, -0.01688542,  0.04319255,  0.08124685,  0.18148524,\n",
      "        -0.01293027, -0.30056122,  0.10660127, -0.0693519 , -0.12244725,\n",
      "         0.1390818 ,  0.3671496 ,  0.3494492 , -0.01755228,  0.540875  ,\n",
      "        -0.49654692,  0.1611277 ,  0.2668748 , -0.27096257,  0.5193279 ,\n",
      "         0.06795   , -0.38294214, -0.11141986, -0.11857112,  0.00853488],\n",
      "       [ 0.16059153, -0.24106272,  0.05084928, -0.13046157, -0.0870785 ,\n",
      "        -0.7419288 , -0.04535564,  0.02173073,  0.31754282, -0.15967306,\n",
      "        -0.05719262, -0.4421991 , -0.0414018 , -0.01985752,  0.16991882,\n",
      "        -0.3332531 ,  0.09619538, -0.07721171, -0.1468351 ,  0.22727369,\n",
      "         0.38529184, -0.2947606 ,  0.52611434,  0.0603995 ,  0.07858447,\n",
      "         0.188308  ,  0.13099545, -0.32020006, -0.7097081 ,  0.1566544 ],\n",
      "       [-0.54774463, -0.19786145, -0.71630025, -0.03564304,  0.01117555,\n",
      "        -0.02562399, -0.30139685, -0.07531849, -0.30179912, -0.1050116 ,\n",
      "        -0.13774113, -0.50998884, -0.24814507, -0.01858563, -0.66454846,\n",
      "        -0.13104573, -0.00360927, -0.15238838,  0.03612585, -0.27484706,\n",
      "        -0.26205033, -0.6102766 , -0.24156675, -0.31146044,  0.24332343,\n",
      "        -0.36505815, -0.11730906, -0.46453446, -0.34081236, -0.2588051 ],\n",
      "       [ 0.15252085, -0.07580534, -0.18830402,  0.63833857, -0.3335595 ,\n",
      "        -0.18535   , -0.29002592, -0.11242807,  0.12093062, -0.18443751,\n",
      "        -0.17951496, -0.2798375 , -0.29118487, -0.24473257,  0.04026961,\n",
      "        -0.35731003, -0.49512056,  0.31537622,  0.20249173, -0.53810936,\n",
      "         0.51581454, -0.41067192, -0.01089555,  0.11162984,  0.04822358,\n",
      "        -0.38966614, -0.39775223, -0.19383745, -0.56439906, -0.12152512]],\n",
      "      dtype=float32), array([-0.126234  , -0.26645237, -0.35568807,  0.07432128, -0.1637672 ,\n",
      "       -0.11805742, -0.41649678, -0.15273574, -0.29804334, -0.04541289,\n",
      "       -0.09884824, -0.26284426, -0.37218276,  0.08527667, -0.21235389,\n",
      "       -0.10696194, -0.15845726, -0.06990503,  0.1350544 , -0.22179152,\n",
      "       -0.01117049, -0.24633117, -0.2227745 , -0.1028543 , -0.12225228,\n",
      "       -0.17757519, -0.39111692, -0.32602975, -0.30394602, -0.11852332],\n",
      "      dtype=float32), array([0.76845247, 0.8360234 , 1.0979509 , 0.7262804 , 1.1568241 ,\n",
      "       0.85792196, 1.0315868 , 1.0898442 , 1.1229699 , 0.82824737,\n",
      "       1.000952  , 1.0228924 , 1.0597022 , 1.002054  , 1.2646846 ,\n",
      "       0.9067023 , 1.0085939 , 1.0567465 , 1.1419541 , 0.9828782 ,\n",
      "       0.93596566, 1.1982393 , 0.93564665, 0.9146319 , 0.97131133,\n",
      "       1.305002  , 0.9679413 , 1.0879371 , 1.0510296 , 0.9601821 ],\n",
      "      dtype=float32), array([ 0.36906868, -0.21593149,  0.19519652, -0.19895403, -0.00260184,\n",
      "        0.06369093,  0.11481052,  0.12074113, -0.02171295,  0.12485135,\n",
      "        0.05599748, -0.04775565, -0.00510044,  0.0992054 ,  0.04378902,\n",
      "        0.1766424 ,  0.24103841, -0.00960865,  0.03441446,  0.03281139,\n",
      "        0.13272382,  0.05908442,  0.05400208,  0.058919  ,  0.21707393,\n",
      "        0.11916468,  0.19761908,  0.05611481,  0.08851326,  0.25264326],\n",
      "      dtype=float32), array([0.34576452, 0.3128141 , 0.18714365, 0.62626916, 0.40260294,\n",
      "       0.5182278 , 0.17931919, 0.40362343, 0.31248823, 0.43027428,\n",
      "       0.56614274, 0.1745757 , 0.18652262, 0.62028056, 0.17335576,\n",
      "       0.38584885, 0.4091734 , 0.5600387 , 0.6485302 , 0.29615647,\n",
      "       0.43970954, 0.12245744, 0.36566862, 0.33297133, 0.60108906,\n",
      "       0.20611976, 0.4063055 , 0.09543604, 0.19477022, 0.48390108],\n",
      "      dtype=float32), array([0.97767323, 0.48804083, 0.5842244 , 0.68347317, 0.90569156,\n",
      "       0.86508214, 0.33344698, 0.6348183 , 0.9992423 , 0.56507427,\n",
      "       1.0542693 , 0.38233253, 0.32734266, 1.1707509 , 0.4257901 ,\n",
      "       0.85008574, 1.0149027 , 0.9605698 , 1.5170001 , 0.8419115 ,\n",
      "       0.7850802 , 0.33267906, 1.1861739 , 0.5672488 , 1.4616604 ,\n",
      "       0.21280384, 0.80474657, 0.22980665, 0.24893653, 0.8858249 ],\n",
      "      dtype=float32), array([[-0.03258606,  0.28085098,  0.00561377,  0.32929286, -0.01913232,\n",
      "        -0.20861588, -0.00721434,  0.32127017,  0.3999605 ,  0.26637563,\n",
      "         0.5110476 ,  0.1628347 ],\n",
      "       [-0.15362187,  0.01229012,  0.30720907, -0.28581125, -0.5060563 ,\n",
      "        -0.42016318,  0.15447377,  0.18993926,  0.2784799 , -0.31151038,\n",
      "         0.08725428, -0.22954218],\n",
      "       [ 0.00730101, -0.18648733,  0.03213631,  0.5165989 ,  0.3907069 ,\n",
      "        -0.15884481,  0.12816015,  0.1679063 ,  0.4653744 , -0.42679802,\n",
      "         0.13315527,  0.15031314],\n",
      "       [ 0.01053791, -0.01465292,  0.1516083 , -0.01093592,  0.042936  ,\n",
      "         0.3450678 , -0.2096869 , -0.20844106, -0.32281765, -0.18129277,\n",
      "         0.39494938, -0.21918721],\n",
      "       [-0.21455593,  0.30002052,  0.18616681, -0.53123295, -0.25084695,\n",
      "        -0.2830366 , -0.49354342,  0.35151017, -0.05317397,  0.34249923,\n",
      "         0.0435237 ,  0.06352821],\n",
      "       [ 0.45497203, -0.03752761,  0.1223544 , -0.02344144, -0.01179202,\n",
      "        -0.7713727 , -0.13848282,  0.49943462, -0.0140204 ,  0.61345434,\n",
      "        -0.49523175, -0.12584952],\n",
      "       [-0.7845586 , -0.0019853 , -0.2642798 ,  0.20080905,  0.03807447,\n",
      "         0.31915438,  0.24390881, -0.22069563,  0.12902105, -0.05271415,\n",
      "         0.36501226, -0.22909819],\n",
      "       [-0.01784102, -0.4437131 ,  0.02602245, -0.16875671,  0.00925651,\n",
      "         0.06720562, -0.29339886,  0.32116687,  0.3620459 , -0.2737878 ,\n",
      "         0.13332161, -0.17322905],\n",
      "       [-0.6539699 , -0.41683367,  0.3727475 , -0.4312471 ,  0.17042454,\n",
      "         0.06200669, -0.06484123, -0.06910148, -0.03129187, -0.08810201,\n",
      "         0.19917716, -0.11842911],\n",
      "       [-0.6272126 , -0.2791467 , -0.12448667,  0.28760713,  0.5271247 ,\n",
      "        -0.0127969 ,  0.35869285, -0.20878282,  0.1234858 ,  0.2582859 ,\n",
      "         0.00158639, -0.14798532],\n",
      "       [-0.85482025, -0.15235351, -0.14750437, -0.11546491, -0.05607639,\n",
      "         0.07687066,  0.0861503 , -0.1216369 , -0.12988882,  0.14692886,\n",
      "        -0.04433966,  0.14585033],\n",
      "       [-0.02847336,  0.08272702, -0.46387625,  0.01626873, -0.11612162,\n",
      "        -0.79237485, -0.2696776 ,  0.11035449, -0.183643  ,  0.3694786 ,\n",
      "         0.40602076,  0.7604707 ],\n",
      "       [ 0.14109379,  0.10137663, -0.33965915, -0.22603953,  0.15726641,\n",
      "        -0.18340354, -0.6357621 ,  0.35887685, -0.24027376, -0.5456824 ,\n",
      "        -0.20274244,  0.3704257 ],\n",
      "       [ 0.11521843,  0.27670097, -0.13193877, -0.43729156,  0.03793776,\n",
      "         0.27233872, -0.23420997, -0.33550876,  0.18411359,  0.14968503,\n",
      "         0.19917987, -0.5085183 ],\n",
      "       [-0.07277311,  0.3233652 ,  0.19814408, -0.8404923 , -0.42620382,\n",
      "        -0.15951549, -0.38806373,  0.26416624, -0.20358106,  0.6229661 ,\n",
      "        -0.20043299,  0.09809045],\n",
      "       [-0.19132349, -0.22155464,  0.4554902 ,  0.01000561,  0.5828372 ,\n",
      "         0.19991127,  0.23277357,  0.16841432,  0.08850803,  0.26136327,\n",
      "         0.16221587,  0.01769356],\n",
      "       [ 0.09790462,  0.1955339 ,  0.17433515,  0.4968631 ,  0.62673795,\n",
      "        -0.3818039 ,  0.11260021,  0.10815216,  0.3411178 ,  0.22086461,\n",
      "         0.1247377 , -0.44373843],\n",
      "       [-0.10227094, -0.29354468, -0.03670917,  0.20808047,  0.00381574,\n",
      "        -0.2487275 , -0.2760885 , -0.793657  ,  0.2395813 , -0.07085424,\n",
      "         0.09483254, -0.0999402 ],\n",
      "       [ 0.20488541, -0.13909921, -0.2225195 , -0.18903045, -0.74011415,\n",
      "         0.28232884, -0.547629  ,  0.14061706,  0.11351312,  0.22594377,\n",
      "        -0.01283063, -0.05817299],\n",
      "       [ 0.02473716,  0.35976523, -0.26506665, -0.22733125, -0.23358752,\n",
      "        -0.5477228 , -0.67352265,  0.05028914, -0.29864898, -0.10578251,\n",
      "        -0.04404687, -0.06094046],\n",
      "       [-0.01768609, -0.05426473, -0.233828  , -0.17248051, -0.02821572,\n",
      "         0.17048724,  0.11574351,  0.61167854,  0.02902727,  0.282006  ,\n",
      "        -0.6275683 ,  0.08079434],\n",
      "       [ 0.10132359,  0.48875183, -0.4258755 , -0.11467478,  0.044213  ,\n",
      "        -0.6587294 , -0.07386205,  0.49751404, -0.4672105 ,  0.32657233,\n",
      "        -0.3364417 ,  0.5692196 ],\n",
      "       [-0.11895005,  0.73497814, -0.49012783, -0.07214539, -0.26119933,\n",
      "         0.18545505,  0.14453685,  0.5295351 , -0.12684327, -0.06544324,\n",
      "        -0.42209738,  0.11449715],\n",
      "       [-0.24022302,  0.27846077,  0.03098705, -0.0565056 ,  0.23572586,\n",
      "        -0.04207194, -0.17231292, -0.0083496 ,  0.49133417,  0.06189747,\n",
      "        -0.00124273, -0.2606647 ],\n",
      "       [ 0.2310661 ,  0.28184766,  0.17840444,  0.30055547,  0.4826882 ,\n",
      "        -0.08618683, -0.09990993, -0.32791296,  0.17047924, -0.5390904 ,\n",
      "         0.23771453, -0.05200287],\n",
      "       [-0.2782682 ,  0.03526596,  0.39503708,  0.26385194,  0.4008992 ,\n",
      "        -0.19061379, -0.28843918, -0.07361483,  0.20789148,  0.1992775 ,\n",
      "         0.45864323, -0.61202526],\n",
      "       [-0.5471864 , -0.18881878,  0.49231142, -0.25047746,  0.01516169,\n",
      "         0.07882283,  0.02025664, -0.15503938, -0.07400472, -0.03662653,\n",
      "         0.48446792, -0.17803684],\n",
      "       [ 0.10316122,  0.4869858 , -0.13380316, -0.25785094, -0.01299458,\n",
      "        -0.43207726, -0.45353025,  0.1797491 , -0.27934536,  0.3382006 ,\n",
      "        -0.4461323 ,  0.6371971 ],\n",
      "       [ 0.13487668,  0.5986043 , -0.2736305 , -0.13948922, -0.13581665,\n",
      "        -0.7272888 , -0.5399997 ,  0.11223882,  0.07843401, -0.02823923,\n",
      "        -0.56048435,  0.17218551],\n",
      "       [-0.07204479, -0.22511975,  0.01751843,  0.27946857,  0.04852932,\n",
      "         0.23769675,  0.04945593, -0.29146272,  0.43019095,  0.25126016,\n",
      "        -0.04597761, -0.2864947 ]], dtype=float32), array([0.195338  , 0.31617132, 0.18629628, 0.46939224, 0.9494381 ,\n",
      "       0.5262495 , 0.19998172, 0.4336927 , 0.6420053 , 0.0126676 ,\n",
      "       0.2235857 , 0.38251406], dtype=float32), array([0.9812756 , 0.58533335, 0.6168176 , 1.1998729 , 1.2153583 ,\n",
      "       0.6142878 , 1.0827665 , 0.8050273 , 1.2967354 , 0.604483  ,\n",
      "       0.85336703, 0.96161526], dtype=float32), array([ 0.28833753,  0.17477332, -0.243107  ,  0.17688999,  0.25245953,\n",
      "        0.21211675, -0.71966445, -0.5662372 , -0.89224637, -0.06042729,\n",
      "        0.21540909,  0.474208  ], dtype=float32), array([1.0046133, 1.1122428, 0.9386332, 1.569825 , 2.0321903, 1.3266041,\n",
      "       1.1341358, 1.3650748, 1.542722 , 1.0450572, 1.1477526, 1.0622528],\n",
      "      dtype=float32), array([1.7742816, 3.175268 , 2.1601827, 3.4300208, 6.2465873, 2.3965547,\n",
      "       2.2231147, 4.119572 , 3.4202547, 2.5406291, 2.4831307, 3.0928338],\n",
      "      dtype=float32), array([[ 1.3729535e-01, -7.8596339e-02, -1.4079043e-01,  8.5034245e-01,\n",
      "        -6.4227146e-01,  1.5163841e-02,  1.3728160e-01,  7.5042051e-01,\n",
      "         4.9326334e-02],\n",
      "       [ 1.6210134e-01,  5.0439459e-01, -6.1104113e-01, -6.3303761e-02,\n",
      "        -2.1713762e-01, -3.0481851e-02,  3.9920032e-02,  1.9390050e-01,\n",
      "        -1.5177236e-01],\n",
      "       [-2.8149173e-01, -1.5309732e-01,  1.5318278e-02, -3.3319300e-01,\n",
      "         2.3908940e-01,  3.5594535e-01, -9.3632601e-02, -5.2125925e-01,\n",
      "         9.1872355e-03],\n",
      "       [ 3.5406446e-01, -2.9235736e-01,  7.7120519e-01,  3.5521814e-01,\n",
      "        -1.6716744e-01,  2.8728448e-02, -3.9967665e-01,  6.0370505e-01,\n",
      "        -6.1692935e-01],\n",
      "       [-5.4007208e-01,  1.0991326e-01,  4.3651989e-01,  4.4177997e-01,\n",
      "         4.4567838e-02,  1.2619233e-01, -4.4424948e-01,  3.4028730e-01,\n",
      "        -4.5685461e-01],\n",
      "       [-2.2700541e-02, -3.4967923e-01, -1.5163103e-01,  3.1187510e-01,\n",
      "         1.5252532e-01,  1.2557068e-01,  2.5361750e-01, -1.3044113e-01,\n",
      "        -9.1180421e-02],\n",
      "       [-1.1233735e+00,  2.2730578e-01,  1.2213353e-01, -1.6037337e-01,\n",
      "        -4.9792716e-01, -9.4042009e-01,  2.5529948e-01, -2.7658895e-01,\n",
      "        -2.4825870e-01],\n",
      "       [ 2.0725361e-01, -5.4538554e-01, -1.9082868e-01, -6.4747399e-01,\n",
      "        -8.0447614e-01,  3.5594624e-01, -2.6639307e-01, -1.0331280e-01,\n",
      "         1.6431263e-01],\n",
      "       [ 2.8869775e-01, -1.3843877e+00,  2.7739730e-01, -1.5466979e-01,\n",
      "        -2.0247158e-01, -6.7504787e-01,  9.2570432e-02, -2.0735261e-01,\n",
      "        -1.5399030e-01],\n",
      "       [ 8.6389214e-02,  2.6638311e-01,  5.3445166e-01, -1.3071096e-01,\n",
      "        -3.8478413e-01, -7.9482502e-01, -3.2755390e-01,  2.7031624e-01,\n",
      "         2.1620636e-01],\n",
      "       [-1.1852266e-01, -2.1240567e-01, -1.6134182e-01,  5.4340041e-01,\n",
      "         2.6920110e-01,  3.7025240e-01, -8.2888198e-01,  3.7251619e-01,\n",
      "         4.5973618e-02],\n",
      "       [-1.3150686e-01,  6.8632385e-04,  7.2744668e-01,  2.6338652e-01,\n",
      "        -2.0519489e-01,  2.9007071e-01,  5.5753821e-01,  4.2430744e-01,\n",
      "        -5.4152038e-02]], dtype=float32), array([0.8001782 , 0.7538548 , 0.30348238, 0.3792754 , 0.62821656,\n",
      "       0.6186717 , 0.36347246, 0.4487624 , 0.09097968], dtype=float32), array([0.49719816, 0.5020211 , 0.3684998 , 0.42894885, 0.5994805 ,\n",
      "       0.31531918, 0.5434905 , 0.14237292, 0.4636596 ], dtype=float32), array([ 0.18885428,  0.1870048 ,  0.05971126, -0.23557386, -0.11399223,\n",
      "        0.17703666,  0.17959619,  0.27399194,  0.20111081], dtype=float32), array([1.4413788 , 2.2797651 , 0.82020897, 1.8611948 , 1.4903008 ,\n",
      "       2.01652   , 0.83583516, 1.7435476 , 0.6361471 ], dtype=float32), array([1.7893904 , 3.347895  , 1.4693925 , 1.7341018 , 1.5425489 ,\n",
      "       1.9686337 , 1.0690502 , 1.679569  , 0.71742076], dtype=float32), array([[ 5.2339892e-09,  5.5053372e-02],\n",
      "       [-2.3101929e-08,  8.9889921e-02],\n",
      "       [ 1.5890279e-08, -2.5961494e-02],\n",
      "       [-1.8772441e-08, -4.9093902e-02],\n",
      "       [ 9.4168570e-08, -8.8132061e-02],\n",
      "       [-8.0372491e-09,  5.9580576e-02],\n",
      "       [-7.6276692e-09,  9.4323747e-02],\n",
      "       [ 3.3715045e-07,  2.1009947e-01],\n",
      "       [ 1.4428825e-07,  8.1621878e-02]], dtype=float32), array([-4.8240931e-08,  3.6055323e-01], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.backend import manual_variable_initialization \n",
    "manual_variable_initialization(True)\n",
    "model.save (\"./app/MODEL/my_model_OFF.h5\")\n",
    "model1.save (\"./app/MODEL/my_model_1_OFF.h5\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(model.get_weights())\n",
    "\n",
    "print (model1.get_weights())\n",
    "model1.save_weights(\"on_1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jBGZMwMHlLXw"
   },
   "outputs": [],
   "source": [
    "# from keras.models import load_model\n",
    "# new_model = load_model('my_model_ON.h5')\n",
    "# new_model_1 = load_model('my_model_1_ON.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uqP6qSVglPrH"
   },
   "outputs": [],
   "source": [
    "# pred = new_model_1.predict((X_new1))\n",
    "# print(pred.shape)\n",
    "\n",
    "# mse = (mean_squared_error(Y_rob_train,pred))\n",
    "\n",
    "# print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MPxe7WHNlSVb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g05oiTETLRCg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "perpec_ON.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

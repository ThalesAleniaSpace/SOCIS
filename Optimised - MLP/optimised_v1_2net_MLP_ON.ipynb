{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "on_type_2_ica_factor_row_2values+_conti_1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJWhKDiQUjP5",
        "colab_type": "code",
        "outputId": "bbf07891-0e27-471d-cd11-8ff853cbc075",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Run this cell to mount your Google Drive.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSB2ZlQ9HUJj",
        "colab_type": "text"
      },
      "source": [
        "Importing all the Requirements \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7fSctGklB-F",
        "colab_type": "code",
        "outputId": "f5704f5c-d9e2-45b0-fc31-3cf4540a01d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import preprocessing \n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, BatchNormalization\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.feature_selection import VarianceThreshold"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrhS4b2JlKv6",
        "colab_type": "code",
        "outputId": "61b79b37-2994-40fb-9d51-5ddeb9db3d96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        }
      },
      "source": [
        "data_p = pd.read_csv(\"drive/My Drive/INTERN/notebooks/SOCIS/sprint2/points.csv\",dtype=object,error_bad_lines=False) \n",
        "data_p.head()\n",
        "data_p[\"id\"] = data_p[\"id\"].map(str) +\"_\"+ data_p[\"dir\"]\n",
        "data_p.head()\n",
        "# data_p.dtypes"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>s.no</th>\n",
              "      <th>id</th>\n",
              "      <th>dir</th>\n",
              "      <th>path</th>\n",
              "      <th>date</th>\n",
              "      <th>x1</th>\n",
              "      <th>y1</th>\n",
              "      <th>x2</th>\n",
              "      <th>y2</th>\n",
              "      <th>x3</th>\n",
              "      <th>y3</th>\n",
              "      <th>x4</th>\n",
              "      <th>y4</th>\n",
              "      <th>x5</th>\n",
              "      <th>y5</th>\n",
              "      <th>x6</th>\n",
              "      <th>y6</th>\n",
              "      <th>x7</th>\n",
              "      <th>y7</th>\n",
              "      <th>x8</th>\n",
              "      <th>y8</th>\n",
              "      <th>x9</th>\n",
              "      <th>y9</th>\n",
              "      <th>x10</th>\n",
              "      <th>y10</th>\n",
              "      <th>x11</th>\n",
              "      <th>y11</th>\n",
              "      <th>x12</th>\n",
              "      <th>y12</th>\n",
              "      <th>x13</th>\n",
              "      <th>y13</th>\n",
              "      <th>x14</th>\n",
              "      <th>y14</th>\n",
              "      <th>x15</th>\n",
              "      <th>y15</th>\n",
              "      <th>x16</th>\n",
              "      <th>y16</th>\n",
              "      <th>x17</th>\n",
              "      <th>y17</th>\n",
              "      <th>x18</th>\n",
              "      <th>...</th>\n",
              "      <th>x9981</th>\n",
              "      <th>y9981</th>\n",
              "      <th>x9982</th>\n",
              "      <th>y9982</th>\n",
              "      <th>x9983</th>\n",
              "      <th>y9983</th>\n",
              "      <th>x9984</th>\n",
              "      <th>y9984</th>\n",
              "      <th>x9985</th>\n",
              "      <th>y9985</th>\n",
              "      <th>x9986</th>\n",
              "      <th>y9986</th>\n",
              "      <th>x9987</th>\n",
              "      <th>y9987</th>\n",
              "      <th>x9988</th>\n",
              "      <th>y9988</th>\n",
              "      <th>x9989</th>\n",
              "      <th>y9989</th>\n",
              "      <th>x9990</th>\n",
              "      <th>y9990</th>\n",
              "      <th>x9991</th>\n",
              "      <th>y9991</th>\n",
              "      <th>x9992</th>\n",
              "      <th>y9992</th>\n",
              "      <th>x9993</th>\n",
              "      <th>y9993</th>\n",
              "      <th>x9994</th>\n",
              "      <th>y9994</th>\n",
              "      <th>x9995</th>\n",
              "      <th>y9995</th>\n",
              "      <th>x9996</th>\n",
              "      <th>y9996</th>\n",
              "      <th>x9997</th>\n",
              "      <th>y9997</th>\n",
              "      <th>x9998</th>\n",
              "      <th>y9998</th>\n",
              "      <th>x9999</th>\n",
              "      <th>y9999</th>\n",
              "      <th>x10000</th>\n",
              "      <th>y10000</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>ON_1_20181031_173504_104</td>\n",
              "      <td>104</td>\n",
              "      <td>C:\\Hilink\\BB4A\\RESULT\\BBM2\\BBM2\\NOMINAL\\MANUAL...</td>\n",
              "      <td>31/10/2018</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.2</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>OFF_4_20181031_173921_104</td>\n",
              "      <td>104</td>\n",
              "      <td>C:\\Hilink\\BB4A\\RESULT\\BBM2\\BBM2\\NOMINAL\\MANUAL...</td>\n",
              "      <td>31/10/2018</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.2</td>\n",
              "      <td>...</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0.03</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0.03</td>\n",
              "      <td>25.4</td>\n",
              "      <td>0.03</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0.03</td>\n",
              "      <td>25.2</td>\n",
              "      <td>0.03</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0.03</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0.03</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0.03</td>\n",
              "      <td>25.2</td>\n",
              "      <td>0.03</td>\n",
              "      <td>25.2</td>\n",
              "      <td>0.03</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0.03</td>\n",
              "      <td>25.2</td>\n",
              "      <td>0.03</td>\n",
              "      <td>25.2</td>\n",
              "      <td>0.03</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0.03</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0.03</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0.03</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0.03</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0.03</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0.03</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>OFF_2_20181031_173628_104</td>\n",
              "      <td>104</td>\n",
              "      <td>C:\\Hilink\\BB4A\\RESULT\\BBM2\\BBM2\\NOMINAL\\MANUAL...</td>\n",
              "      <td>31/10/2018</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.2</td>\n",
              "      <td>...</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0.03</td>\n",
              "      <td>25.2</td>\n",
              "      <td>0.03</td>\n",
              "      <td>25.2</td>\n",
              "      <td>0.02</td>\n",
              "      <td>25.2</td>\n",
              "      <td>0.03</td>\n",
              "      <td>25.4</td>\n",
              "      <td>0.03</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0.03</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0.03</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0.03</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0.03</td>\n",
              "      <td>25.2</td>\n",
              "      <td>0.03</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0.03</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0.03</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0.03</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0.03</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0.03</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0.03</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0.03</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0.02</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0.02</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>ON_3_20181031_173800_104</td>\n",
              "      <td>104</td>\n",
              "      <td>C:\\Hilink\\BB4A\\RESULT\\BBM2\\BBM2\\NOMINAL\\MANUAL...</td>\n",
              "      <td>31/10/2018</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.2</td>\n",
              "      <td>...</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>OFF_4_20181102_085018_103</td>\n",
              "      <td>103</td>\n",
              "      <td>C:\\Hilink\\BB4A\\RESULT\\BBM2\\BBM2\\NOMINAL\\MANUAL...</td>\n",
              "      <td>02/11/2018</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.2</td>\n",
              "      <td>...</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0.05</td>\n",
              "      <td>25.2</td>\n",
              "      <td>0.06</td>\n",
              "      <td>25.2</td>\n",
              "      <td>0.05</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0.06</td>\n",
              "      <td>25.2</td>\n",
              "      <td>0.06</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0.05</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0.06</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0.06</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0.06</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0.06</td>\n",
              "      <td>25.2</td>\n",
              "      <td>0.06</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0.06</td>\n",
              "      <td>24.8</td>\n",
              "      <td>0.06</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0.06</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0.06</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0.05</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0.06</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0.05</td>\n",
              "      <td>25.2</td>\n",
              "      <td>0.05</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0.05</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 20005 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "  s.no                         id  dir  ... y9999 x10000 y10000\n",
              "0    1   ON_1_20181031_173504_104  104  ...  0.14    0.2   0.14\n",
              "1    2  OFF_4_20181031_173921_104  104  ...  0.03   25.0   0.03\n",
              "2    3  OFF_2_20181031_173628_104  104  ...  0.02   25.0   0.03\n",
              "3    4   ON_3_20181031_173800_104  104  ...  0.14    0.2   0.14\n",
              "4    5  OFF_4_20181102_085018_103  103  ...  0.05   25.0   0.05\n",
              "\n",
              "[5 rows x 20005 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tiHdWmrVlUfZ",
        "colab_type": "code",
        "outputId": "2f5f8fd3-6bd5-4608-d6d9-0a4df2bbc801",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        }
      },
      "source": [
        "\n",
        "data_v = pd.read_csv(\"drive/My Drive/INTERN/notebooks/SOCIS/sprint2/values.csv\",dtype=object,error_bad_lines=False )\n",
        "le = preprocessing.LabelEncoder()\n",
        "\n",
        "data_v['power_state_spec'] = le.fit_transform(data_v['power_state_spec'].astype('str'))\n",
        "\n",
        "data_v['power_state_value'] = le.fit_transform(data_v['power_state_value'].astype('str'))\n",
        "data_v[\"id\"] = data_v[\"id\"].map(str) +\"_\"+data_v[\"dir\"]\n",
        "data_v.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>s.no</th>\n",
              "      <th>id</th>\n",
              "      <th>dir</th>\n",
              "      <th>_file_</th>\n",
              "      <th>power_state_value</th>\n",
              "      <th>current_rise/fall_time_value (mS)</th>\n",
              "      <th>current_stabilised_value (mA)</th>\n",
              "      <th>current_max/min_value (mA)</th>\n",
              "      <th>power_state_spec</th>\n",
              "      <th>current_rise/fall_time_spec (mS)</th>\n",
              "      <th>current_stabilised_spec (mA)</th>\n",
              "      <th>current_max/min_spec (mA)</th>\n",
              "      <th>power_state_N/NC</th>\n",
              "      <th>current_rise/fall_time_C/NC</th>\n",
              "      <th>current_stabilised_C/NC</th>\n",
              "      <th>current_max/min_C/NC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>ON_1_20181031_173504_104</td>\n",
              "      <td>104</td>\n",
              "      <td>HEGSE_72.HTM</td>\n",
              "      <td>1</td>\n",
              "      <td>89.990000000000</td>\n",
              "      <td>150.000000000000</td>\n",
              "      <td>405.992200000000</td>\n",
              "      <td>1</td>\n",
              "      <td>60</td>\n",
              "      <td>510.204</td>\n",
              "      <td>800</td>\n",
              "      <td>C</td>\n",
              "      <td>NC</td>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>OFF_2_20181031_173628_104</td>\n",
              "      <td>104</td>\n",
              "      <td>HEGSE_72.HTM</td>\n",
              "      <td>0</td>\n",
              "      <td>7.992000000000</td>\n",
              "      <td>30.000000000000</td>\n",
              "      <td>-56.000000000000</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>510.204</td>\n",
              "      <td>-100</td>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>ON_3_20181031_173800_104</td>\n",
              "      <td>104</td>\n",
              "      <td>HEGSE_72.HTM</td>\n",
              "      <td>1</td>\n",
              "      <td>89.950000000000</td>\n",
              "      <td>140.000000000000</td>\n",
              "      <td>405.992200000000</td>\n",
              "      <td>1</td>\n",
              "      <td>60</td>\n",
              "      <td>495.049</td>\n",
              "      <td>800</td>\n",
              "      <td>C</td>\n",
              "      <td>NC</td>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>OFF_4_20181031_173921_104</td>\n",
              "      <td>104</td>\n",
              "      <td>HEGSE_72.HTM</td>\n",
              "      <td>0</td>\n",
              "      <td>7.997000000000</td>\n",
              "      <td>30.000000000000</td>\n",
              "      <td>-58.000000000000</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>495.049</td>\n",
              "      <td>-100</td>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>ON_1_20181102_084600_103</td>\n",
              "      <td>103</td>\n",
              "      <td>HEGSE_72.HTM</td>\n",
              "      <td>1</td>\n",
              "      <td>56.650000000000</td>\n",
              "      <td>169.800000000000</td>\n",
              "      <td>405.992200000000</td>\n",
              "      <td>1</td>\n",
              "      <td>60</td>\n",
              "      <td>510.204</td>\n",
              "      <td>800</td>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  s.no                         id  ... current_stabilised_C/NC current_max/min_C/NC\n",
              "0    1   ON_1_20181031_173504_104  ...                       C                    C\n",
              "1    2  OFF_2_20181031_173628_104  ...                       C                    C\n",
              "2    3   ON_3_20181031_173800_104  ...                       C                    C\n",
              "3    4  OFF_4_20181031_173921_104  ...                       C                    C\n",
              "4    5   ON_1_20181102_084600_103  ...                       C                    C\n",
              "\n",
              "[5 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0D5hVOHFlj1E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "arr_v = data_v.to_numpy()\n",
        "arr_p = data_p.to_numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCNx0zUhll26",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "arr_v = arr_v[0:]\n",
        "# print(arr_v)\n",
        "arr_p = arr_p[0:]\n",
        "# print(arr_p)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aA8nouS6Htic",
        "colab_type": "text"
      },
      "source": [
        "Selecting the ON data set\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpc-5eQBlolc",
        "colab_type": "code",
        "outputId": "42c7f11d-23f0-4ee3-d9c2-14cd12f8f01c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "ON_list =[]\n",
        "OFF_list = []\n",
        "for i in range(len(arr_p)):\n",
        "    s = arr_p[i][1]\n",
        "    s = str(s)\n",
        "    \n",
        "#     print(type(st))\n",
        "    if s.find(\"N\") == -1:\n",
        "        OFF_list.append(arr_p[i])\n",
        "    \n",
        "    else:\n",
        "        ON_list.append(arr_p[i])\n",
        "# calculating for ON\n",
        "print(len(ON_list),\"ON\")\n",
        "print(len(OFF_list),\"OFF\")\n",
        "arr_on_p = np.array(ON_list)\n",
        "# print(arr_on_p)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "426 ON\n",
            "398 OFF\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umYNgb3Clq23",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "arr_on_p = np.delete(arr_on_p, 3,  axis=1)\n",
        "arr_on_p_n = arr_on_p[:, 1::2]\n",
        "arr_on_p_f = np.delete(arr_on_p_n, 1,  axis=1)\n",
        "# print(len(arr_on_p_f))\n",
        "# print(len(arr_on_p_f[0]))\n",
        "# print(arr_on_p_f[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDNn39eKlt3G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# arr_on_p_f[:,1:]= arr_on_p_f[:,1:].astype('float64')\n",
        "# print((arr_on_p_f[413]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93df0DeklwFG",
        "colab_type": "code",
        "outputId": "f79079f4-537f-4783-f20d-636514a84000",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        }
      },
      "source": [
        "data = arr_on_p_f\n",
        "\n",
        "df=pd.DataFrame(data=data[0:,0:],index=[i for i in range(data.shape[0])],\n",
        "                columns=['y'+str(i) for i in range(data.shape[1])])\n",
        "df.head()\n",
        "# df.dtypes\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y0</th>\n",
              "      <th>y1</th>\n",
              "      <th>y2</th>\n",
              "      <th>y3</th>\n",
              "      <th>y4</th>\n",
              "      <th>y5</th>\n",
              "      <th>y6</th>\n",
              "      <th>y7</th>\n",
              "      <th>y8</th>\n",
              "      <th>y9</th>\n",
              "      <th>y10</th>\n",
              "      <th>y11</th>\n",
              "      <th>y12</th>\n",
              "      <th>y13</th>\n",
              "      <th>y14</th>\n",
              "      <th>y15</th>\n",
              "      <th>y16</th>\n",
              "      <th>y17</th>\n",
              "      <th>y18</th>\n",
              "      <th>y19</th>\n",
              "      <th>y20</th>\n",
              "      <th>y21</th>\n",
              "      <th>y22</th>\n",
              "      <th>y23</th>\n",
              "      <th>y24</th>\n",
              "      <th>y25</th>\n",
              "      <th>y26</th>\n",
              "      <th>y27</th>\n",
              "      <th>y28</th>\n",
              "      <th>y29</th>\n",
              "      <th>y30</th>\n",
              "      <th>y31</th>\n",
              "      <th>y32</th>\n",
              "      <th>y33</th>\n",
              "      <th>y34</th>\n",
              "      <th>y35</th>\n",
              "      <th>y36</th>\n",
              "      <th>y37</th>\n",
              "      <th>y38</th>\n",
              "      <th>y39</th>\n",
              "      <th>...</th>\n",
              "      <th>y9961</th>\n",
              "      <th>y9962</th>\n",
              "      <th>y9963</th>\n",
              "      <th>y9964</th>\n",
              "      <th>y9965</th>\n",
              "      <th>y9966</th>\n",
              "      <th>y9967</th>\n",
              "      <th>y9968</th>\n",
              "      <th>y9969</th>\n",
              "      <th>y9970</th>\n",
              "      <th>y9971</th>\n",
              "      <th>y9972</th>\n",
              "      <th>y9973</th>\n",
              "      <th>y9974</th>\n",
              "      <th>y9975</th>\n",
              "      <th>y9976</th>\n",
              "      <th>y9977</th>\n",
              "      <th>y9978</th>\n",
              "      <th>y9979</th>\n",
              "      <th>y9980</th>\n",
              "      <th>y9981</th>\n",
              "      <th>y9982</th>\n",
              "      <th>y9983</th>\n",
              "      <th>y9984</th>\n",
              "      <th>y9985</th>\n",
              "      <th>y9986</th>\n",
              "      <th>y9987</th>\n",
              "      <th>y9988</th>\n",
              "      <th>y9989</th>\n",
              "      <th>y9990</th>\n",
              "      <th>y9991</th>\n",
              "      <th>y9992</th>\n",
              "      <th>y9993</th>\n",
              "      <th>y9994</th>\n",
              "      <th>y9995</th>\n",
              "      <th>y9996</th>\n",
              "      <th>y9997</th>\n",
              "      <th>y9998</th>\n",
              "      <th>y9999</th>\n",
              "      <th>y10000</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ON_1_20181031_173504_104</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>...</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ON_3_20181031_173800_104</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>...</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ON_3_20181102_084856_103</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.05</td>\n",
              "      <td>...</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ON_1_20181102_084600_103</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>...</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ON_1_20181102_085847_102</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>...</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 10001 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                         y0    y1    y2    y3  ... y9997 y9998 y9999 y10000\n",
              "0  ON_1_20181031_173504_104  0.03  0.03  0.03  ...  0.14  0.14  0.14   0.14\n",
              "1  ON_3_20181031_173800_104  0.03  0.02  0.04  ...  0.14  0.14  0.14   0.14\n",
              "2  ON_3_20181102_084856_103  0.06  0.06  0.06  ...  0.17  0.17  0.17   0.17\n",
              "3  ON_1_20181102_084600_103  0.05  0.06  0.06  ...  0.17  0.17  0.16   0.17\n",
              "4  ON_1_20181102_085847_102  0.06  0.06  0.06  ...  0.17  0.17  0.17   0.17\n",
              "\n",
              "[5 rows x 10001 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slrYEJ4ulx-q",
        "colab_type": "code",
        "outputId": "d44c087d-8871-4e8b-ba85-714c1e9c401a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "print(df.shape)\n",
        "# for j in range(10000):\n",
        "#   var = \"y\"+str(j+1)\n",
        "#   df[var].fillna(df[var].mean(), inplace=True)\n",
        "df_no_miss = df.dropna()\n",
        "print(df_no_miss.shape)\n",
        "print(df.shape)\n",
        "df_no_miss.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(426, 10001)\n",
            "(423, 10001)\n",
            "(426, 10001)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y0</th>\n",
              "      <th>y1</th>\n",
              "      <th>y2</th>\n",
              "      <th>y3</th>\n",
              "      <th>y4</th>\n",
              "      <th>y5</th>\n",
              "      <th>y6</th>\n",
              "      <th>y7</th>\n",
              "      <th>y8</th>\n",
              "      <th>y9</th>\n",
              "      <th>y10</th>\n",
              "      <th>y11</th>\n",
              "      <th>y12</th>\n",
              "      <th>y13</th>\n",
              "      <th>y14</th>\n",
              "      <th>y15</th>\n",
              "      <th>y16</th>\n",
              "      <th>y17</th>\n",
              "      <th>y18</th>\n",
              "      <th>y19</th>\n",
              "      <th>y20</th>\n",
              "      <th>y21</th>\n",
              "      <th>y22</th>\n",
              "      <th>y23</th>\n",
              "      <th>y24</th>\n",
              "      <th>y25</th>\n",
              "      <th>y26</th>\n",
              "      <th>y27</th>\n",
              "      <th>y28</th>\n",
              "      <th>y29</th>\n",
              "      <th>y30</th>\n",
              "      <th>y31</th>\n",
              "      <th>y32</th>\n",
              "      <th>y33</th>\n",
              "      <th>y34</th>\n",
              "      <th>y35</th>\n",
              "      <th>y36</th>\n",
              "      <th>y37</th>\n",
              "      <th>y38</th>\n",
              "      <th>y39</th>\n",
              "      <th>...</th>\n",
              "      <th>y9961</th>\n",
              "      <th>y9962</th>\n",
              "      <th>y9963</th>\n",
              "      <th>y9964</th>\n",
              "      <th>y9965</th>\n",
              "      <th>y9966</th>\n",
              "      <th>y9967</th>\n",
              "      <th>y9968</th>\n",
              "      <th>y9969</th>\n",
              "      <th>y9970</th>\n",
              "      <th>y9971</th>\n",
              "      <th>y9972</th>\n",
              "      <th>y9973</th>\n",
              "      <th>y9974</th>\n",
              "      <th>y9975</th>\n",
              "      <th>y9976</th>\n",
              "      <th>y9977</th>\n",
              "      <th>y9978</th>\n",
              "      <th>y9979</th>\n",
              "      <th>y9980</th>\n",
              "      <th>y9981</th>\n",
              "      <th>y9982</th>\n",
              "      <th>y9983</th>\n",
              "      <th>y9984</th>\n",
              "      <th>y9985</th>\n",
              "      <th>y9986</th>\n",
              "      <th>y9987</th>\n",
              "      <th>y9988</th>\n",
              "      <th>y9989</th>\n",
              "      <th>y9990</th>\n",
              "      <th>y9991</th>\n",
              "      <th>y9992</th>\n",
              "      <th>y9993</th>\n",
              "      <th>y9994</th>\n",
              "      <th>y9995</th>\n",
              "      <th>y9996</th>\n",
              "      <th>y9997</th>\n",
              "      <th>y9998</th>\n",
              "      <th>y9999</th>\n",
              "      <th>y10000</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ON_1_20181031_173504_104</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>...</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ON_3_20181031_173800_104</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>...</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ON_3_20181102_084856_103</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.05</td>\n",
              "      <td>...</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ON_1_20181102_084600_103</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>...</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ON_1_20181102_085847_102</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>...</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 10001 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                         y0    y1    y2    y3  ... y9997 y9998 y9999 y10000\n",
              "0  ON_1_20181031_173504_104  0.03  0.03  0.03  ...  0.14  0.14  0.14   0.14\n",
              "1  ON_3_20181031_173800_104  0.03  0.02  0.04  ...  0.14  0.14  0.14   0.14\n",
              "2  ON_3_20181102_084856_103  0.06  0.06  0.06  ...  0.17  0.17  0.17   0.17\n",
              "3  ON_1_20181102_084600_103  0.05  0.06  0.06  ...  0.17  0.17  0.16   0.17\n",
              "4  ON_1_20181102_085847_102  0.06  0.06  0.06  ...  0.17  0.17  0.17   0.17\n",
              "\n",
              "[5 rows x 10001 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9INWdr53l17r",
        "colab_type": "code",
        "outputId": "b9ef09fe-c43e-4a07-bb77-d597321e1615",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "arr_p_no = df_no_miss.to_numpy()\n",
        "print(len(arr_p_no))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "423\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cA29_yRkl4jN",
        "colab_type": "code",
        "outputId": "84f9c093-27e1-4875-950d-44b40c5a2e1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        }
      },
      "source": [
        "df1= df_no_miss.rename(index=str, columns={\"y0\": \"id\"})\n",
        "df1.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>y1</th>\n",
              "      <th>y2</th>\n",
              "      <th>y3</th>\n",
              "      <th>y4</th>\n",
              "      <th>y5</th>\n",
              "      <th>y6</th>\n",
              "      <th>y7</th>\n",
              "      <th>y8</th>\n",
              "      <th>y9</th>\n",
              "      <th>y10</th>\n",
              "      <th>y11</th>\n",
              "      <th>y12</th>\n",
              "      <th>y13</th>\n",
              "      <th>y14</th>\n",
              "      <th>y15</th>\n",
              "      <th>y16</th>\n",
              "      <th>y17</th>\n",
              "      <th>y18</th>\n",
              "      <th>y19</th>\n",
              "      <th>y20</th>\n",
              "      <th>y21</th>\n",
              "      <th>y22</th>\n",
              "      <th>y23</th>\n",
              "      <th>y24</th>\n",
              "      <th>y25</th>\n",
              "      <th>y26</th>\n",
              "      <th>y27</th>\n",
              "      <th>y28</th>\n",
              "      <th>y29</th>\n",
              "      <th>y30</th>\n",
              "      <th>y31</th>\n",
              "      <th>y32</th>\n",
              "      <th>y33</th>\n",
              "      <th>y34</th>\n",
              "      <th>y35</th>\n",
              "      <th>y36</th>\n",
              "      <th>y37</th>\n",
              "      <th>y38</th>\n",
              "      <th>y39</th>\n",
              "      <th>...</th>\n",
              "      <th>y9961</th>\n",
              "      <th>y9962</th>\n",
              "      <th>y9963</th>\n",
              "      <th>y9964</th>\n",
              "      <th>y9965</th>\n",
              "      <th>y9966</th>\n",
              "      <th>y9967</th>\n",
              "      <th>y9968</th>\n",
              "      <th>y9969</th>\n",
              "      <th>y9970</th>\n",
              "      <th>y9971</th>\n",
              "      <th>y9972</th>\n",
              "      <th>y9973</th>\n",
              "      <th>y9974</th>\n",
              "      <th>y9975</th>\n",
              "      <th>y9976</th>\n",
              "      <th>y9977</th>\n",
              "      <th>y9978</th>\n",
              "      <th>y9979</th>\n",
              "      <th>y9980</th>\n",
              "      <th>y9981</th>\n",
              "      <th>y9982</th>\n",
              "      <th>y9983</th>\n",
              "      <th>y9984</th>\n",
              "      <th>y9985</th>\n",
              "      <th>y9986</th>\n",
              "      <th>y9987</th>\n",
              "      <th>y9988</th>\n",
              "      <th>y9989</th>\n",
              "      <th>y9990</th>\n",
              "      <th>y9991</th>\n",
              "      <th>y9992</th>\n",
              "      <th>y9993</th>\n",
              "      <th>y9994</th>\n",
              "      <th>y9995</th>\n",
              "      <th>y9996</th>\n",
              "      <th>y9997</th>\n",
              "      <th>y9998</th>\n",
              "      <th>y9999</th>\n",
              "      <th>y10000</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ON_1_20181031_173504_104</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>...</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ON_3_20181031_173800_104</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>...</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ON_3_20181102_084856_103</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.05</td>\n",
              "      <td>...</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ON_1_20181102_084600_103</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>...</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ON_1_20181102_085847_102</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>...</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 10001 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                         id    y1    y2    y3  ... y9997 y9998 y9999 y10000\n",
              "0  ON_1_20181031_173504_104  0.03  0.03  0.03  ...  0.14  0.14  0.14   0.14\n",
              "1  ON_3_20181031_173800_104  0.03  0.02  0.04  ...  0.14  0.14  0.14   0.14\n",
              "2  ON_3_20181102_084856_103  0.06  0.06  0.06  ...  0.17  0.17  0.17   0.17\n",
              "3  ON_1_20181102_084600_103  0.05  0.06  0.06  ...  0.17  0.17  0.16   0.17\n",
              "4  ON_1_20181102_085847_102  0.06  0.06  0.06  ...  0.17  0.17  0.17   0.17\n",
              "\n",
              "[5 rows x 10001 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "potGQ4Anl6xp",
        "colab_type": "code",
        "outputId": "8077c39d-d90c-4919-b0b4-96595dfd346e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(df1.shape)\n",
        "df2 = data_v\n",
        "# print(df2.shape)\n",
        "combine = (pd.merge(df1, df2, how='left', on='id'))\n",
        "# print(df1.unique)\n",
        "print(combine.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(423, 10001)\n",
            "(423, 10016)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jjetg1TIl9pM",
        "colab_type": "code",
        "outputId": "71e0e4f6-8e14-4343-ac35-a14fa523891a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "combine.head()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>y1</th>\n",
              "      <th>y2</th>\n",
              "      <th>y3</th>\n",
              "      <th>y4</th>\n",
              "      <th>y5</th>\n",
              "      <th>y6</th>\n",
              "      <th>y7</th>\n",
              "      <th>y8</th>\n",
              "      <th>y9</th>\n",
              "      <th>y10</th>\n",
              "      <th>y11</th>\n",
              "      <th>y12</th>\n",
              "      <th>y13</th>\n",
              "      <th>y14</th>\n",
              "      <th>y15</th>\n",
              "      <th>y16</th>\n",
              "      <th>y17</th>\n",
              "      <th>y18</th>\n",
              "      <th>y19</th>\n",
              "      <th>y20</th>\n",
              "      <th>y21</th>\n",
              "      <th>y22</th>\n",
              "      <th>y23</th>\n",
              "      <th>y24</th>\n",
              "      <th>y25</th>\n",
              "      <th>y26</th>\n",
              "      <th>y27</th>\n",
              "      <th>y28</th>\n",
              "      <th>y29</th>\n",
              "      <th>y30</th>\n",
              "      <th>y31</th>\n",
              "      <th>y32</th>\n",
              "      <th>y33</th>\n",
              "      <th>y34</th>\n",
              "      <th>y35</th>\n",
              "      <th>y36</th>\n",
              "      <th>y37</th>\n",
              "      <th>y38</th>\n",
              "      <th>y39</th>\n",
              "      <th>...</th>\n",
              "      <th>y9976</th>\n",
              "      <th>y9977</th>\n",
              "      <th>y9978</th>\n",
              "      <th>y9979</th>\n",
              "      <th>y9980</th>\n",
              "      <th>y9981</th>\n",
              "      <th>y9982</th>\n",
              "      <th>y9983</th>\n",
              "      <th>y9984</th>\n",
              "      <th>y9985</th>\n",
              "      <th>y9986</th>\n",
              "      <th>y9987</th>\n",
              "      <th>y9988</th>\n",
              "      <th>y9989</th>\n",
              "      <th>y9990</th>\n",
              "      <th>y9991</th>\n",
              "      <th>y9992</th>\n",
              "      <th>y9993</th>\n",
              "      <th>y9994</th>\n",
              "      <th>y9995</th>\n",
              "      <th>y9996</th>\n",
              "      <th>y9997</th>\n",
              "      <th>y9998</th>\n",
              "      <th>y9999</th>\n",
              "      <th>y10000</th>\n",
              "      <th>s.no</th>\n",
              "      <th>dir</th>\n",
              "      <th>_file_</th>\n",
              "      <th>power_state_value</th>\n",
              "      <th>current_rise/fall_time_value (mS)</th>\n",
              "      <th>current_stabilised_value (mA)</th>\n",
              "      <th>current_max/min_value (mA)</th>\n",
              "      <th>power_state_spec</th>\n",
              "      <th>current_rise/fall_time_spec (mS)</th>\n",
              "      <th>current_stabilised_spec (mA)</th>\n",
              "      <th>current_max/min_spec (mA)</th>\n",
              "      <th>power_state_N/NC</th>\n",
              "      <th>current_rise/fall_time_C/NC</th>\n",
              "      <th>current_stabilised_C/NC</th>\n",
              "      <th>current_max/min_C/NC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ON_1_20181031_173504_104</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>...</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>1</td>\n",
              "      <td>104</td>\n",
              "      <td>HEGSE_72.HTM</td>\n",
              "      <td>1.0</td>\n",
              "      <td>89.990000000000</td>\n",
              "      <td>150.000000000000</td>\n",
              "      <td>405.992200000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>60</td>\n",
              "      <td>510.204</td>\n",
              "      <td>800</td>\n",
              "      <td>C</td>\n",
              "      <td>NC</td>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ON_3_20181031_173800_104</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>...</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>3</td>\n",
              "      <td>104</td>\n",
              "      <td>HEGSE_72.HTM</td>\n",
              "      <td>1.0</td>\n",
              "      <td>89.950000000000</td>\n",
              "      <td>140.000000000000</td>\n",
              "      <td>405.992200000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>60</td>\n",
              "      <td>495.049</td>\n",
              "      <td>800</td>\n",
              "      <td>C</td>\n",
              "      <td>NC</td>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ON_3_20181102_084856_103</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.05</td>\n",
              "      <td>...</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>7</td>\n",
              "      <td>103</td>\n",
              "      <td>HEGSE_72.HTM</td>\n",
              "      <td>1.0</td>\n",
              "      <td>36.970000000000</td>\n",
              "      <td>166.300000000000</td>\n",
              "      <td>405.992200000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>60</td>\n",
              "      <td>495.049</td>\n",
              "      <td>800</td>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ON_1_20181102_084600_103</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>...</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>5</td>\n",
              "      <td>103</td>\n",
              "      <td>HEGSE_72.HTM</td>\n",
              "      <td>1.0</td>\n",
              "      <td>56.650000000000</td>\n",
              "      <td>169.800000000000</td>\n",
              "      <td>405.992200000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>60</td>\n",
              "      <td>510.204</td>\n",
              "      <td>800</td>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ON_1_20181102_085847_102</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>...</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>9</td>\n",
              "      <td>102</td>\n",
              "      <td>HEGSE_72.HTM</td>\n",
              "      <td>1.0</td>\n",
              "      <td>37.040000000000</td>\n",
              "      <td>170.000000000000</td>\n",
              "      <td>401.312500000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>60</td>\n",
              "      <td>510.204</td>\n",
              "      <td>800</td>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 10016 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                         id    y1  ... current_stabilised_C/NC current_max/min_C/NC\n",
              "0  ON_1_20181031_173504_104  0.03  ...                       C                    C\n",
              "1  ON_3_20181031_173800_104  0.03  ...                       C                    C\n",
              "2  ON_3_20181102_084856_103  0.06  ...                       C                    C\n",
              "3  ON_1_20181102_084600_103  0.05  ...                       C                    C\n",
              "4  ON_1_20181102_085847_102  0.06  ...                       C                    C\n",
              "\n",
              "[5 rows x 10016 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdcHiYxSl_6m",
        "colab_type": "code",
        "outputId": "9381ddea-ddba-416d-b269-b8470ccac242",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "combine.iloc[:,0:10010].head()\n",
        "k = combine.drop(['s.no','dir','_file_'], axis = 1) \n",
        "\n",
        "k.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>y1</th>\n",
              "      <th>y2</th>\n",
              "      <th>y3</th>\n",
              "      <th>y4</th>\n",
              "      <th>y5</th>\n",
              "      <th>y6</th>\n",
              "      <th>y7</th>\n",
              "      <th>y8</th>\n",
              "      <th>y9</th>\n",
              "      <th>y10</th>\n",
              "      <th>y11</th>\n",
              "      <th>y12</th>\n",
              "      <th>y13</th>\n",
              "      <th>y14</th>\n",
              "      <th>y15</th>\n",
              "      <th>y16</th>\n",
              "      <th>y17</th>\n",
              "      <th>y18</th>\n",
              "      <th>y19</th>\n",
              "      <th>y20</th>\n",
              "      <th>y21</th>\n",
              "      <th>y22</th>\n",
              "      <th>y23</th>\n",
              "      <th>y24</th>\n",
              "      <th>y25</th>\n",
              "      <th>y26</th>\n",
              "      <th>y27</th>\n",
              "      <th>y28</th>\n",
              "      <th>y29</th>\n",
              "      <th>y30</th>\n",
              "      <th>y31</th>\n",
              "      <th>y32</th>\n",
              "      <th>y33</th>\n",
              "      <th>y34</th>\n",
              "      <th>y35</th>\n",
              "      <th>y36</th>\n",
              "      <th>y37</th>\n",
              "      <th>y38</th>\n",
              "      <th>y39</th>\n",
              "      <th>...</th>\n",
              "      <th>y9973</th>\n",
              "      <th>y9974</th>\n",
              "      <th>y9975</th>\n",
              "      <th>y9976</th>\n",
              "      <th>y9977</th>\n",
              "      <th>y9978</th>\n",
              "      <th>y9979</th>\n",
              "      <th>y9980</th>\n",
              "      <th>y9981</th>\n",
              "      <th>y9982</th>\n",
              "      <th>y9983</th>\n",
              "      <th>y9984</th>\n",
              "      <th>y9985</th>\n",
              "      <th>y9986</th>\n",
              "      <th>y9987</th>\n",
              "      <th>y9988</th>\n",
              "      <th>y9989</th>\n",
              "      <th>y9990</th>\n",
              "      <th>y9991</th>\n",
              "      <th>y9992</th>\n",
              "      <th>y9993</th>\n",
              "      <th>y9994</th>\n",
              "      <th>y9995</th>\n",
              "      <th>y9996</th>\n",
              "      <th>y9997</th>\n",
              "      <th>y9998</th>\n",
              "      <th>y9999</th>\n",
              "      <th>y10000</th>\n",
              "      <th>power_state_value</th>\n",
              "      <th>current_rise/fall_time_value (mS)</th>\n",
              "      <th>current_stabilised_value (mA)</th>\n",
              "      <th>current_max/min_value (mA)</th>\n",
              "      <th>power_state_spec</th>\n",
              "      <th>current_rise/fall_time_spec (mS)</th>\n",
              "      <th>current_stabilised_spec (mA)</th>\n",
              "      <th>current_max/min_spec (mA)</th>\n",
              "      <th>power_state_N/NC</th>\n",
              "      <th>current_rise/fall_time_C/NC</th>\n",
              "      <th>current_stabilised_C/NC</th>\n",
              "      <th>current_max/min_C/NC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ON_1_20181031_173504_104</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>...</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>1.0</td>\n",
              "      <td>89.990000000000</td>\n",
              "      <td>150.000000000000</td>\n",
              "      <td>405.992200000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>60</td>\n",
              "      <td>510.204</td>\n",
              "      <td>800</td>\n",
              "      <td>C</td>\n",
              "      <td>NC</td>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ON_3_20181031_173800_104</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>...</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>1.0</td>\n",
              "      <td>89.950000000000</td>\n",
              "      <td>140.000000000000</td>\n",
              "      <td>405.992200000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>60</td>\n",
              "      <td>495.049</td>\n",
              "      <td>800</td>\n",
              "      <td>C</td>\n",
              "      <td>NC</td>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ON_3_20181102_084856_103</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.05</td>\n",
              "      <td>...</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>1.0</td>\n",
              "      <td>36.970000000000</td>\n",
              "      <td>166.300000000000</td>\n",
              "      <td>405.992200000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>60</td>\n",
              "      <td>495.049</td>\n",
              "      <td>800</td>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ON_1_20181102_084600_103</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>...</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>1.0</td>\n",
              "      <td>56.650000000000</td>\n",
              "      <td>169.800000000000</td>\n",
              "      <td>405.992200000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>60</td>\n",
              "      <td>510.204</td>\n",
              "      <td>800</td>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ON_1_20181102_085847_102</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>...</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>1.0</td>\n",
              "      <td>37.040000000000</td>\n",
              "      <td>170.000000000000</td>\n",
              "      <td>401.312500000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>60</td>\n",
              "      <td>510.204</td>\n",
              "      <td>800</td>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 10013 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                         id    y1  ... current_stabilised_C/NC current_max/min_C/NC\n",
              "0  ON_1_20181031_173504_104  0.03  ...                       C                    C\n",
              "1  ON_3_20181031_173800_104  0.03  ...                       C                    C\n",
              "2  ON_3_20181102_084856_103  0.06  ...                       C                    C\n",
              "3  ON_1_20181102_084600_103  0.05  ...                       C                    C\n",
              "4  ON_1_20181102_085847_102  0.06  ...                       C                    C\n",
              "\n",
              "[5 rows x 10013 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01BZcRcNmCVI",
        "colab_type": "code",
        "outputId": "5f1395b9-a3e5-4b6b-d4e9-9c450cf41805",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "input_1 = k.iloc[:,0:10009]\n",
        "# filling the missing values\n",
        "\n",
        "# print(input_1.iloc[:,10008])\n",
        "miss = input_1.iloc[:,1:]\n",
        "miss.head()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y1</th>\n",
              "      <th>y2</th>\n",
              "      <th>y3</th>\n",
              "      <th>y4</th>\n",
              "      <th>y5</th>\n",
              "      <th>y6</th>\n",
              "      <th>y7</th>\n",
              "      <th>y8</th>\n",
              "      <th>y9</th>\n",
              "      <th>y10</th>\n",
              "      <th>y11</th>\n",
              "      <th>y12</th>\n",
              "      <th>y13</th>\n",
              "      <th>y14</th>\n",
              "      <th>y15</th>\n",
              "      <th>y16</th>\n",
              "      <th>y17</th>\n",
              "      <th>y18</th>\n",
              "      <th>y19</th>\n",
              "      <th>y20</th>\n",
              "      <th>y21</th>\n",
              "      <th>y22</th>\n",
              "      <th>y23</th>\n",
              "      <th>y24</th>\n",
              "      <th>y25</th>\n",
              "      <th>y26</th>\n",
              "      <th>y27</th>\n",
              "      <th>y28</th>\n",
              "      <th>y29</th>\n",
              "      <th>y30</th>\n",
              "      <th>y31</th>\n",
              "      <th>y32</th>\n",
              "      <th>y33</th>\n",
              "      <th>y34</th>\n",
              "      <th>y35</th>\n",
              "      <th>y36</th>\n",
              "      <th>y37</th>\n",
              "      <th>y38</th>\n",
              "      <th>y39</th>\n",
              "      <th>y40</th>\n",
              "      <th>...</th>\n",
              "      <th>y9969</th>\n",
              "      <th>y9970</th>\n",
              "      <th>y9971</th>\n",
              "      <th>y9972</th>\n",
              "      <th>y9973</th>\n",
              "      <th>y9974</th>\n",
              "      <th>y9975</th>\n",
              "      <th>y9976</th>\n",
              "      <th>y9977</th>\n",
              "      <th>y9978</th>\n",
              "      <th>y9979</th>\n",
              "      <th>y9980</th>\n",
              "      <th>y9981</th>\n",
              "      <th>y9982</th>\n",
              "      <th>y9983</th>\n",
              "      <th>y9984</th>\n",
              "      <th>y9985</th>\n",
              "      <th>y9986</th>\n",
              "      <th>y9987</th>\n",
              "      <th>y9988</th>\n",
              "      <th>y9989</th>\n",
              "      <th>y9990</th>\n",
              "      <th>y9991</th>\n",
              "      <th>y9992</th>\n",
              "      <th>y9993</th>\n",
              "      <th>y9994</th>\n",
              "      <th>y9995</th>\n",
              "      <th>y9996</th>\n",
              "      <th>y9997</th>\n",
              "      <th>y9998</th>\n",
              "      <th>y9999</th>\n",
              "      <th>y10000</th>\n",
              "      <th>power_state_value</th>\n",
              "      <th>current_rise/fall_time_value (mS)</th>\n",
              "      <th>current_stabilised_value (mA)</th>\n",
              "      <th>current_max/min_value (mA)</th>\n",
              "      <th>power_state_spec</th>\n",
              "      <th>current_rise/fall_time_spec (mS)</th>\n",
              "      <th>current_stabilised_spec (mA)</th>\n",
              "      <th>current_max/min_spec (mA)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>...</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>1.0</td>\n",
              "      <td>89.990000000000</td>\n",
              "      <td>150.000000000000</td>\n",
              "      <td>405.992200000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>60</td>\n",
              "      <td>510.204</td>\n",
              "      <td>800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.03</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>...</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>1.0</td>\n",
              "      <td>89.950000000000</td>\n",
              "      <td>140.000000000000</td>\n",
              "      <td>405.992200000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>60</td>\n",
              "      <td>495.049</td>\n",
              "      <td>800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>...</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>1.0</td>\n",
              "      <td>36.970000000000</td>\n",
              "      <td>166.300000000000</td>\n",
              "      <td>405.992200000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>60</td>\n",
              "      <td>495.049</td>\n",
              "      <td>800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>...</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>1.0</td>\n",
              "      <td>56.650000000000</td>\n",
              "      <td>169.800000000000</td>\n",
              "      <td>405.992200000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>60</td>\n",
              "      <td>510.204</td>\n",
              "      <td>800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>...</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>1.0</td>\n",
              "      <td>37.040000000000</td>\n",
              "      <td>170.000000000000</td>\n",
              "      <td>401.312500000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>60</td>\n",
              "      <td>510.204</td>\n",
              "      <td>800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 10008 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     y1    y2  ... current_stabilised_spec (mA) current_max/min_spec (mA)\n",
              "0  0.03  0.03  ...                      510.204                       800\n",
              "1  0.03  0.02  ...                      495.049                       800\n",
              "2  0.06  0.06  ...                      495.049                       800\n",
              "3  0.05  0.06  ...                      510.204                       800\n",
              "4  0.06  0.06  ...                      510.204                       800\n",
              "\n",
              "[5 rows x 10008 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHLKkyZVIB3b",
        "colab_type": "text"
      },
      "source": [
        "Filling the missing values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crlfNqSdmEx6",
        "colab_type": "code",
        "outputId": "3925973f-9576-490a-a73b-b2902fcced9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "input_1 = k.iloc[:,0:10009]\n",
        "# filling the missing values\n",
        "\n",
        "miss = input_1.iloc[:,1:]\n",
        "miss.head()\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "for column in (miss.iloc[:,10000:]):\n",
        "  su = 0\n",
        "  div = 0\n",
        "  for r in range(miss.shape[0]):\n",
        "    if (pd.isna(miss[column][r]))== False:\n",
        "      su = float(miss[column][r])+su\n",
        "\n",
        "      div = div+1\n",
        "\n",
        "  fin = float(su/div)\n",
        "\n",
        "  miss[column].fillna(float(fin),inplace=True)\n",
        "#########converting ever\n",
        "# thing into float\n",
        "miss =miss.astype('float64')\n",
        "# print(miss.dtypes)\n",
        "miss.head()\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y1</th>\n",
              "      <th>y2</th>\n",
              "      <th>y3</th>\n",
              "      <th>y4</th>\n",
              "      <th>y5</th>\n",
              "      <th>y6</th>\n",
              "      <th>y7</th>\n",
              "      <th>y8</th>\n",
              "      <th>y9</th>\n",
              "      <th>y10</th>\n",
              "      <th>y11</th>\n",
              "      <th>y12</th>\n",
              "      <th>y13</th>\n",
              "      <th>y14</th>\n",
              "      <th>y15</th>\n",
              "      <th>y16</th>\n",
              "      <th>y17</th>\n",
              "      <th>y18</th>\n",
              "      <th>y19</th>\n",
              "      <th>y20</th>\n",
              "      <th>y21</th>\n",
              "      <th>y22</th>\n",
              "      <th>y23</th>\n",
              "      <th>y24</th>\n",
              "      <th>y25</th>\n",
              "      <th>y26</th>\n",
              "      <th>y27</th>\n",
              "      <th>y28</th>\n",
              "      <th>y29</th>\n",
              "      <th>y30</th>\n",
              "      <th>y31</th>\n",
              "      <th>y32</th>\n",
              "      <th>y33</th>\n",
              "      <th>y34</th>\n",
              "      <th>y35</th>\n",
              "      <th>y36</th>\n",
              "      <th>y37</th>\n",
              "      <th>y38</th>\n",
              "      <th>y39</th>\n",
              "      <th>y40</th>\n",
              "      <th>...</th>\n",
              "      <th>y9969</th>\n",
              "      <th>y9970</th>\n",
              "      <th>y9971</th>\n",
              "      <th>y9972</th>\n",
              "      <th>y9973</th>\n",
              "      <th>y9974</th>\n",
              "      <th>y9975</th>\n",
              "      <th>y9976</th>\n",
              "      <th>y9977</th>\n",
              "      <th>y9978</th>\n",
              "      <th>y9979</th>\n",
              "      <th>y9980</th>\n",
              "      <th>y9981</th>\n",
              "      <th>y9982</th>\n",
              "      <th>y9983</th>\n",
              "      <th>y9984</th>\n",
              "      <th>y9985</th>\n",
              "      <th>y9986</th>\n",
              "      <th>y9987</th>\n",
              "      <th>y9988</th>\n",
              "      <th>y9989</th>\n",
              "      <th>y9990</th>\n",
              "      <th>y9991</th>\n",
              "      <th>y9992</th>\n",
              "      <th>y9993</th>\n",
              "      <th>y9994</th>\n",
              "      <th>y9995</th>\n",
              "      <th>y9996</th>\n",
              "      <th>y9997</th>\n",
              "      <th>y9998</th>\n",
              "      <th>y9999</th>\n",
              "      <th>y10000</th>\n",
              "      <th>power_state_value</th>\n",
              "      <th>current_rise/fall_time_value (mS)</th>\n",
              "      <th>current_stabilised_value (mA)</th>\n",
              "      <th>current_max/min_value (mA)</th>\n",
              "      <th>power_state_spec</th>\n",
              "      <th>current_rise/fall_time_spec (mS)</th>\n",
              "      <th>current_stabilised_spec (mA)</th>\n",
              "      <th>current_max/min_spec (mA)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>...</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>1.0</td>\n",
              "      <td>89.99</td>\n",
              "      <td>150.0</td>\n",
              "      <td>405.9922</td>\n",
              "      <td>1.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>510.204</td>\n",
              "      <td>800.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.03</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>...</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>1.0</td>\n",
              "      <td>89.95</td>\n",
              "      <td>140.0</td>\n",
              "      <td>405.9922</td>\n",
              "      <td>1.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>495.049</td>\n",
              "      <td>800.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>...</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>1.0</td>\n",
              "      <td>36.97</td>\n",
              "      <td>166.3</td>\n",
              "      <td>405.9922</td>\n",
              "      <td>1.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>495.049</td>\n",
              "      <td>800.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>...</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.17</td>\n",
              "      <td>1.0</td>\n",
              "      <td>56.65</td>\n",
              "      <td>169.8</td>\n",
              "      <td>405.9922</td>\n",
              "      <td>1.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>510.204</td>\n",
              "      <td>800.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>...</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.17</td>\n",
              "      <td>1.0</td>\n",
              "      <td>37.04</td>\n",
              "      <td>170.0</td>\n",
              "      <td>401.3125</td>\n",
              "      <td>1.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>510.204</td>\n",
              "      <td>800.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 10008 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     y1    y2  ...  current_stabilised_spec (mA)  current_max/min_spec (mA)\n",
              "0  0.03  0.03  ...                       510.204                      800.0\n",
              "1  0.03  0.02  ...                       495.049                      800.0\n",
              "2  0.06  0.06  ...                       495.049                      800.0\n",
              "3  0.05  0.06  ...                       510.204                      800.0\n",
              "4  0.06  0.06  ...                       510.204                      800.0\n",
              "\n",
              "[5 rows x 10008 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yIBUXiPILnl",
        "colab_type": "text"
      },
      "source": [
        "Initialsing various scaling functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtZv2K45mJ1y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble.forest import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn.preprocessing import QuantileTransformer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.preprocessing import robust_scale\n",
        "\n",
        "scaler_min_x = MinMaxScaler()\n",
        "scaler_min_y = MinMaxScaler()\n",
        "\n",
        "scaler_norm_x = Normalizer()\n",
        "scaler_norm_y = Normalizer()\n",
        "\n",
        "scaler_stan_x = StandardScaler()\n",
        "scaler_stan_y = StandardScaler()\n",
        "\n",
        "scalar_qt_x =QuantileTransformer(output_distribution='uniform')\n",
        "scalar_qt_y =QuantileTransformer(output_distribution='uniform')\n",
        "       "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jv72miytmPZ0",
        "colab_type": "code",
        "outputId": "1cf3dcda-8d9c-4647-e880-2ed5e3bf66e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        }
      },
      "source": [
        "rand_na = miss\n",
        "# print(miss.shape)\n",
        "input_1_arr = rand_na.to_numpy()\n",
        "input_1_arr[:,:]= input_1_arr[:,:].astype('float64')\n",
        "\n",
        "X = input_1_arr[:,0:10000]\n",
        "Y = input_1_arr[:,10002:10004]\n",
        "# print(X.shape)\n",
        "# print(Y.shape)\n",
        "# print(Y)\n",
        "y=np.reshape(Y, (-1,1))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.20)\n",
        "\n",
        "# ######minmax\n",
        "scaler_min_x = MinMaxScaler().fit(X_train)\n",
        "scaler_min_y = MinMaxScaler().fit(y_train)\n",
        "\n",
        "X_minmax_train = scaler_min_x.transform(X_train)\n",
        "Y_minmax_train = scaler_min_y.transform(y_train)\n",
        "\n",
        "\n",
        "# print(X)\n",
        "# print(Y)\n",
        "#####standard\n",
        "\n",
        "scaler_stan_x = StandardScaler().fit(X_train)\n",
        "scaler_stan_y = StandardScaler().fit(y_train)\n",
        "\n",
        "\n",
        "X_stan_train = scaler_stan_x.transform(X_train)\n",
        "Y_stan_train = scaler_stan_y.transform(y_train)\n",
        "\n",
        "#######normlised\n",
        "scaler_norm_x = Normalizer().fit(X_train)\n",
        "scaler_norm_y = Normalizer().fit(y_train)\n",
        "\n",
        "\n",
        "X_norm_train = scaler_norm_x.transform(X_train)\n",
        "Y_norm_train = scaler_norm_y.transform(y_train)\n",
        "\n",
        "\n",
        "# ################qt\n",
        "\n",
        "scaler_qt_x =  QuantileTransformer(output_distribution='normal').fit(X_train)\n",
        "scaler_qt_y =  QuantileTransformer(output_distribution='normal').fit(y_train)\n",
        "\n",
        "\n",
        "X_qt_train = scaler_qt_x.transform(X_train)\n",
        "Y_qt_train = scaler_qt_y.transform(y_train)\n",
        "\n",
        "\n",
        "##robust\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "X_train_t = X_train.transpose()\n",
        "y_train_t = y_train.transpose()\n",
        "print(X_train.shape,\"after\")\n",
        "print(y_train.shape,\"after\")\n",
        "scaler_rob_x = RobustScaler().fit(X_train_t)\n",
        "scaler_rob_y = RobustScaler().fit(y_train_t)\n",
        "\n",
        "\n",
        "X_rob_train = scaler_rob_x.transform(X_train_t)\n",
        "Y_rob_train = scaler_rob_y.transform(y_train_t)\n",
        "\n",
        "X_rob_train = X_rob_train.transpose()\n",
        "Y_rob_train = Y_rob_train.transpose()\n",
        "\n",
        "print(X_rob_train.shape)\n",
        "print(Y_rob_train.shape)\n",
        "# print(Y_rob_train)\n",
        "\n",
        "##robustscale\n",
        "# print(X_train.shape)\n",
        "# scaler_robsc_x= robust_scale(X_train, axis=1, with_centering=True, with_scaling=True, quantile_range=(25.0, 75.0), copy=True)\n",
        "# scaler_robsc_y= robust_scale(y_train, axis=1, with_centering=True, with_scaling=True, quantile_range=(25.0, 75.0), copy=True)\n",
        "\n",
        "\n",
        "\n",
        "# X_robsc_train = scaler_robsc_x\n",
        "# Y_robsc_train = scaler_robsc_y\n",
        "# print(X_robsc_train.shape)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:2239: UserWarning: n_quantiles (1000) is greater than the total number of samples (338). n_quantiles is set to n_samples.\n",
            "  % (self.n_quantiles, n_samples))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:2239: UserWarning: n_quantiles (1000) is greater than the total number of samples (338). n_quantiles is set to n_samples.\n",
            "  % (self.n_quantiles, n_samples))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(338, 10000)\n",
            "(338, 2)\n",
            "(338, 10000) after\n",
            "(338, 2) after\n",
            "(338, 10000)\n",
            "(338, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvn_nCixmTJh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from sklearn.decomposition import PCA\n",
        "# # # pca - keep 90% of variance\n",
        "\n",
        "\n",
        "# # print(X_norm)\n",
        "\n",
        "# # print(Y_norm)\n",
        "# pca = PCA(n_components = 30)\n",
        "# pca_fit =  pca.fit(X_rob_train)\n",
        "# X_new = pca_fit.transform(X_rob_train)\n",
        "# print(X_new.shape)\n",
        "# # principal_df = pd.DataFrame(data = principal_components)\n",
        "# # print(principal_df.head())\n",
        "\n",
        "# var_exp = pca.explained_variance_ratio_\n",
        "# print(var_exp.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ratY7rORQSZz",
        "colab_type": "code",
        "outputId": "bd75b8b6-4045-4223-c632-cfb87814851d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "from sklearn.decomposition import FactorAnalysis\n",
        "\n",
        "transformer = FactorAnalysis(n_components=30, random_state=0)\n",
        "factor_fit = transformer.fit(X_rob_train)\n",
        "X_new = factor_fit.transform(X_rob_train)\n",
        "X_new.shape"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(338, 30)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RQkbJaPTvx6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from sklearn.decomposition import FastICA\n",
        "\n",
        "# transformer = FastICA(n_components=30, random_state=0)\n",
        "# ica_fit = transformer.fit(X_stan_train)\n",
        "# X_new = ica_fit.transform(X_stan_train)\n",
        "# X_new.shape\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_YOzbiHN-Wb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# from sklearn.manifold import Isomap\n",
        "\n",
        "# transformer = Isomap(n_components=50)\n",
        "\n",
        "# iso_fit = transformer.fit(X_stan_train)\n",
        "# X_new = iso_fit.transform(X_stan_train)\n",
        "# X_new.shape\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWyDS-XIIVM-",
        "colab_type": "text"
      },
      "source": [
        "Initialising the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyO17geKmdUf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "def baseline_model_30(optimizer='adam'):\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "    model.add(Dense(28, activation='relu', \n",
        "                    kernel_initializer = 'he_normal', \n",
        "                    input_shape=(30,)))\n",
        "    model.add(BatchNormalization())\n",
        "#     model.add(Dropout(0.5))\n",
        "#     model.add(Dense(30, activation='relu',\n",
        "#                     kernel_initializer = 'he_normal'))\n",
        "#       model.add(BatchNormalization())\n",
        "#     model.add(Dropout(0.5))\n",
        "    model.add(Dense(12, activation='relu',\n",
        "                    kernel_initializer = 'he_normal'))\n",
        "    model.add(BatchNormalization())\n",
        "#     model.add(Dropout(0.5))\n",
        "#     model.add(Dense(9, activation='relu',\n",
        "#                     kernel_initializer = 'he_normal'))\n",
        "#     model.add(BatchNormalization())\n",
        "#     model.add(Dropout(0.5))\n",
        "    model.add(Dense(2, activation='linear', \n",
        "                    kernel_initializer='he_normal'))\n",
        "    model.compile(loss = 'mse', optimizer=optimizer, metrics=['mae'])\n",
        "#     model.summary()\n",
        "    return model\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fi8vQVPMyVwL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def train_data_nn(X_train, y_train):\n",
        "    \n",
        "    np.random.seed(42)\n",
        "    # create model\n",
        "    estimator = KerasRegressor(build_fn=baseline_model_30, epochs=200, batch_size=5, verbose=0)\n",
        "    kfold = KFold(n_splits=5, random_state=None )\n",
        "    results = cross_val_score(estimator, X_train, y_train, cv=kfold)  \n",
        "    print(\"Standardized: %.2f (%.2f) MSE\" % (results.mean(), results.std()))\n",
        "    return estimator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcNOQJBemhDG",
        "colab_type": "code",
        "outputId": "976ad029-008b-45f8-bb64-abff36a27bff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = baseline_model_30()\n",
        "\n",
        "estimator = train_data_nn(X_new, Y_rob_train)\n",
        "\n",
        "print(X_new.shape)\n",
        "print(y_train.shape)\n",
        "history = estimator.fit(X_new,  Y_rob_train, epochs=200, batch_size=5,  verbose=1, validation_split=0.0)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0715 13:38:56.941497 140423277315968 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0715 13:38:56.966790 140423277315968 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0715 13:38:56.972054 140423277315968 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n",
            "W0715 13:38:57.064817 140423277315968 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0715 13:38:57.201936 140423277315968 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0715 13:38:57.997306 140423277315968 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Standardized: -0.12 (0.09) MSE\n",
            "(338, 30)\n",
            "(338, 2)\n",
            "Epoch 1/200\n",
            "338/338 [==============================] - 1s 3ms/step - loss: 2.1137 - mean_absolute_error: 1.1371\n",
            "Epoch 2/200\n",
            "338/338 [==============================] - 0s 365us/step - loss: 1.2400 - mean_absolute_error: 0.8840\n",
            "Epoch 3/200\n",
            "338/338 [==============================] - 0s 380us/step - loss: 0.8474 - mean_absolute_error: 0.7273\n",
            "Epoch 4/200\n",
            "338/338 [==============================] - 0s 366us/step - loss: 0.6064 - mean_absolute_error: 0.6137\n",
            "Epoch 5/200\n",
            "338/338 [==============================] - 0s 391us/step - loss: 0.4505 - mean_absolute_error: 0.5162\n",
            "Epoch 6/200\n",
            "338/338 [==============================] - 0s 386us/step - loss: 0.3254 - mean_absolute_error: 0.4354\n",
            "Epoch 7/200\n",
            "338/338 [==============================] - 0s 387us/step - loss: 0.2917 - mean_absolute_error: 0.3985\n",
            "Epoch 8/200\n",
            "338/338 [==============================] - 0s 372us/step - loss: 0.2822 - mean_absolute_error: 0.3919\n",
            "Epoch 9/200\n",
            "338/338 [==============================] - 0s 370us/step - loss: 0.2392 - mean_absolute_error: 0.3427\n",
            "Epoch 10/200\n",
            "338/338 [==============================] - 0s 434us/step - loss: 0.2116 - mean_absolute_error: 0.3282\n",
            "Epoch 11/200\n",
            "338/338 [==============================] - 0s 379us/step - loss: 0.2053 - mean_absolute_error: 0.3174\n",
            "Epoch 12/200\n",
            "338/338 [==============================] - 0s 385us/step - loss: 0.1956 - mean_absolute_error: 0.2951\n",
            "Epoch 13/200\n",
            "338/338 [==============================] - 0s 375us/step - loss: 0.1750 - mean_absolute_error: 0.2848\n",
            "Epoch 14/200\n",
            "338/338 [==============================] - 0s 374us/step - loss: 0.1724 - mean_absolute_error: 0.2645\n",
            "Epoch 15/200\n",
            "338/338 [==============================] - 0s 384us/step - loss: 0.1627 - mean_absolute_error: 0.2656\n",
            "Epoch 16/200\n",
            "338/338 [==============================] - 0s 377us/step - loss: 0.1473 - mean_absolute_error: 0.2481\n",
            "Epoch 17/200\n",
            "338/338 [==============================] - 0s 371us/step - loss: 0.1504 - mean_absolute_error: 0.2503\n",
            "Epoch 18/200\n",
            "338/338 [==============================] - 0s 393us/step - loss: 0.1390 - mean_absolute_error: 0.2291\n",
            "Epoch 19/200\n",
            "338/338 [==============================] - 0s 372us/step - loss: 0.1445 - mean_absolute_error: 0.2366\n",
            "Epoch 20/200\n",
            "338/338 [==============================] - 0s 370us/step - loss: 0.1273 - mean_absolute_error: 0.2154\n",
            "Epoch 21/200\n",
            "338/338 [==============================] - 0s 394us/step - loss: 0.1291 - mean_absolute_error: 0.2125\n",
            "Epoch 22/200\n",
            "338/338 [==============================] - 0s 372us/step - loss: 0.1332 - mean_absolute_error: 0.2195\n",
            "Epoch 23/200\n",
            "338/338 [==============================] - 0s 365us/step - loss: 0.1256 - mean_absolute_error: 0.2077\n",
            "Epoch 24/200\n",
            "338/338 [==============================] - 0s 399us/step - loss: 0.1243 - mean_absolute_error: 0.2039\n",
            "Epoch 25/200\n",
            "338/338 [==============================] - 0s 371us/step - loss: 0.1194 - mean_absolute_error: 0.1959\n",
            "Epoch 26/200\n",
            "338/338 [==============================] - 0s 376us/step - loss: 0.1233 - mean_absolute_error: 0.1951\n",
            "Epoch 27/200\n",
            "338/338 [==============================] - 0s 378us/step - loss: 0.1122 - mean_absolute_error: 0.1890\n",
            "Epoch 28/200\n",
            "338/338 [==============================] - 0s 375us/step - loss: 0.1121 - mean_absolute_error: 0.1924\n",
            "Epoch 29/200\n",
            "338/338 [==============================] - 0s 374us/step - loss: 0.1078 - mean_absolute_error: 0.1781\n",
            "Epoch 30/200\n",
            "338/338 [==============================] - 0s 396us/step - loss: 0.1132 - mean_absolute_error: 0.1820\n",
            "Epoch 31/200\n",
            "338/338 [==============================] - 0s 370us/step - loss: 0.1152 - mean_absolute_error: 0.1873\n",
            "Epoch 32/200\n",
            "338/338 [==============================] - 0s 373us/step - loss: 0.1089 - mean_absolute_error: 0.1779\n",
            "Epoch 33/200\n",
            "338/338 [==============================] - 0s 372us/step - loss: 0.1054 - mean_absolute_error: 0.1697\n",
            "Epoch 34/200\n",
            "338/338 [==============================] - 0s 378us/step - loss: 0.1090 - mean_absolute_error: 0.1734\n",
            "Epoch 35/200\n",
            "338/338 [==============================] - 0s 367us/step - loss: 0.1080 - mean_absolute_error: 0.1703\n",
            "Epoch 36/200\n",
            "338/338 [==============================] - 0s 383us/step - loss: 0.1025 - mean_absolute_error: 0.1672\n",
            "Epoch 37/200\n",
            "338/338 [==============================] - 0s 378us/step - loss: 0.1077 - mean_absolute_error: 0.1628\n",
            "Epoch 38/200\n",
            "338/338 [==============================] - 0s 368us/step - loss: 0.1072 - mean_absolute_error: 0.1641\n",
            "Epoch 39/200\n",
            "338/338 [==============================] - 0s 370us/step - loss: 0.1035 - mean_absolute_error: 0.1622\n",
            "Epoch 40/200\n",
            "338/338 [==============================] - 0s 392us/step - loss: 0.0980 - mean_absolute_error: 0.1581\n",
            "Epoch 41/200\n",
            "338/338 [==============================] - 0s 397us/step - loss: 0.1101 - mean_absolute_error: 0.1673\n",
            "Epoch 42/200\n",
            "338/338 [==============================] - 0s 370us/step - loss: 0.1039 - mean_absolute_error: 0.1586\n",
            "Epoch 43/200\n",
            "338/338 [==============================] - 0s 390us/step - loss: 0.1026 - mean_absolute_error: 0.1606\n",
            "Epoch 44/200\n",
            "338/338 [==============================] - 0s 373us/step - loss: 0.0983 - mean_absolute_error: 0.1500\n",
            "Epoch 45/200\n",
            "338/338 [==============================] - 0s 374us/step - loss: 0.1007 - mean_absolute_error: 0.1487\n",
            "Epoch 46/200\n",
            "338/338 [==============================] - 0s 376us/step - loss: 0.0997 - mean_absolute_error: 0.1492\n",
            "Epoch 47/200\n",
            "338/338 [==============================] - 0s 390us/step - loss: 0.1031 - mean_absolute_error: 0.1484\n",
            "Epoch 48/200\n",
            "338/338 [==============================] - 0s 374us/step - loss: 0.1003 - mean_absolute_error: 0.1545\n",
            "Epoch 49/200\n",
            "338/338 [==============================] - 0s 371us/step - loss: 0.1039 - mean_absolute_error: 0.1545\n",
            "Epoch 50/200\n",
            "338/338 [==============================] - 0s 389us/step - loss: 0.0973 - mean_absolute_error: 0.1473\n",
            "Epoch 51/200\n",
            "338/338 [==============================] - 0s 376us/step - loss: 0.1020 - mean_absolute_error: 0.1483\n",
            "Epoch 52/200\n",
            "338/338 [==============================] - 0s 368us/step - loss: 0.0995 - mean_absolute_error: 0.1491\n",
            "Epoch 53/200\n",
            "338/338 [==============================] - 0s 387us/step - loss: 0.0937 - mean_absolute_error: 0.1463\n",
            "Epoch 54/200\n",
            "338/338 [==============================] - 0s 371us/step - loss: 0.0962 - mean_absolute_error: 0.1422\n",
            "Epoch 55/200\n",
            "338/338 [==============================] - 0s 372us/step - loss: 0.1017 - mean_absolute_error: 0.1505\n",
            "Epoch 56/200\n",
            "338/338 [==============================] - 0s 379us/step - loss: 0.0984 - mean_absolute_error: 0.1401\n",
            "Epoch 57/200\n",
            "338/338 [==============================] - 0s 380us/step - loss: 0.0965 - mean_absolute_error: 0.1384\n",
            "Epoch 58/200\n",
            "338/338 [==============================] - 0s 367us/step - loss: 0.0942 - mean_absolute_error: 0.1460\n",
            "Epoch 59/200\n",
            "338/338 [==============================] - 0s 384us/step - loss: 0.0986 - mean_absolute_error: 0.1396\n",
            "Epoch 60/200\n",
            "338/338 [==============================] - 0s 391us/step - loss: 0.0964 - mean_absolute_error: 0.1421\n",
            "Epoch 61/200\n",
            "338/338 [==============================] - 0s 370us/step - loss: 0.0919 - mean_absolute_error: 0.1370\n",
            "Epoch 62/200\n",
            "338/338 [==============================] - 0s 377us/step - loss: 0.0969 - mean_absolute_error: 0.1396\n",
            "Epoch 63/200\n",
            "338/338 [==============================] - 0s 382us/step - loss: 0.0957 - mean_absolute_error: 0.1330\n",
            "Epoch 64/200\n",
            "338/338 [==============================] - 0s 374us/step - loss: 0.0956 - mean_absolute_error: 0.1408\n",
            "Epoch 65/200\n",
            "338/338 [==============================] - 0s 373us/step - loss: 0.0906 - mean_absolute_error: 0.1416\n",
            "Epoch 66/200\n",
            "338/338 [==============================] - 0s 384us/step - loss: 0.0948 - mean_absolute_error: 0.1381\n",
            "Epoch 67/200\n",
            "338/338 [==============================] - 0s 382us/step - loss: 0.0895 - mean_absolute_error: 0.1372\n",
            "Epoch 68/200\n",
            "338/338 [==============================] - 0s 372us/step - loss: 0.0949 - mean_absolute_error: 0.1399\n",
            "Epoch 69/200\n",
            "338/338 [==============================] - 0s 406us/step - loss: 0.0958 - mean_absolute_error: 0.1368\n",
            "Epoch 70/200\n",
            "338/338 [==============================] - 0s 366us/step - loss: 0.0958 - mean_absolute_error: 0.1364\n",
            "Epoch 71/200\n",
            "338/338 [==============================] - 0s 372us/step - loss: 0.0944 - mean_absolute_error: 0.1402\n",
            "Epoch 72/200\n",
            "338/338 [==============================] - 0s 391us/step - loss: 0.0909 - mean_absolute_error: 0.1369\n",
            "Epoch 73/200\n",
            "338/338 [==============================] - 0s 376us/step - loss: 0.1008 - mean_absolute_error: 0.1427\n",
            "Epoch 74/200\n",
            "338/338 [==============================] - 0s 368us/step - loss: 0.0872 - mean_absolute_error: 0.1316\n",
            "Epoch 75/200\n",
            "338/338 [==============================] - 0s 380us/step - loss: 0.0944 - mean_absolute_error: 0.1386\n",
            "Epoch 76/200\n",
            "338/338 [==============================] - 0s 382us/step - loss: 0.0975 - mean_absolute_error: 0.1359\n",
            "Epoch 77/200\n",
            "338/338 [==============================] - 0s 373us/step - loss: 0.0932 - mean_absolute_error: 0.1381\n",
            "Epoch 78/200\n",
            "338/338 [==============================] - 0s 378us/step - loss: 0.0905 - mean_absolute_error: 0.1305\n",
            "Epoch 79/200\n",
            "338/338 [==============================] - 0s 384us/step - loss: 0.0963 - mean_absolute_error: 0.1355\n",
            "Epoch 80/200\n",
            "338/338 [==============================] - 0s 371us/step - loss: 0.0902 - mean_absolute_error: 0.1335\n",
            "Epoch 81/200\n",
            "338/338 [==============================] - 0s 377us/step - loss: 0.0878 - mean_absolute_error: 0.1343\n",
            "Epoch 82/200\n",
            "338/338 [==============================] - 0s 397us/step - loss: 0.0929 - mean_absolute_error: 0.1389\n",
            "Epoch 83/200\n",
            "338/338 [==============================] - 0s 369us/step - loss: 0.0911 - mean_absolute_error: 0.1322\n",
            "Epoch 84/200\n",
            "338/338 [==============================] - 0s 370us/step - loss: 0.0895 - mean_absolute_error: 0.1334\n",
            "Epoch 85/200\n",
            "338/338 [==============================] - 0s 394us/step - loss: 0.0930 - mean_absolute_error: 0.1395\n",
            "Epoch 86/200\n",
            "338/338 [==============================] - 0s 371us/step - loss: 0.0914 - mean_absolute_error: 0.1360\n",
            "Epoch 87/200\n",
            "338/338 [==============================] - 0s 373us/step - loss: 0.0948 - mean_absolute_error: 0.1393\n",
            "Epoch 88/200\n",
            "338/338 [==============================] - 0s 389us/step - loss: 0.0926 - mean_absolute_error: 0.1405\n",
            "Epoch 89/200\n",
            "338/338 [==============================] - 0s 374us/step - loss: 0.0922 - mean_absolute_error: 0.1357\n",
            "Epoch 90/200\n",
            "338/338 [==============================] - 0s 423us/step - loss: 0.0907 - mean_absolute_error: 0.1381\n",
            "Epoch 91/200\n",
            "338/338 [==============================] - 0s 374us/step - loss: 0.0953 - mean_absolute_error: 0.1380\n",
            "Epoch 92/200\n",
            "338/338 [==============================] - 0s 389us/step - loss: 0.0907 - mean_absolute_error: 0.1338\n",
            "Epoch 93/200\n",
            "338/338 [==============================] - 0s 374us/step - loss: 0.0945 - mean_absolute_error: 0.1365\n",
            "Epoch 94/200\n",
            "338/338 [==============================] - 0s 372us/step - loss: 0.0902 - mean_absolute_error: 0.1310\n",
            "Epoch 95/200\n",
            "338/338 [==============================] - 0s 380us/step - loss: 0.0946 - mean_absolute_error: 0.1400\n",
            "Epoch 96/200\n",
            "338/338 [==============================] - 0s 370us/step - loss: 0.0897 - mean_absolute_error: 0.1388\n",
            "Epoch 97/200\n",
            "338/338 [==============================] - 0s 381us/step - loss: 0.0884 - mean_absolute_error: 0.1308\n",
            "Epoch 98/200\n",
            "338/338 [==============================] - 0s 383us/step - loss: 0.0910 - mean_absolute_error: 0.1326\n",
            "Epoch 99/200\n",
            "338/338 [==============================] - 0s 372us/step - loss: 0.0856 - mean_absolute_error: 0.1366\n",
            "Epoch 100/200\n",
            "338/338 [==============================] - 0s 373us/step - loss: 0.0872 - mean_absolute_error: 0.1368\n",
            "Epoch 101/200\n",
            "338/338 [==============================] - 0s 376us/step - loss: 0.0899 - mean_absolute_error: 0.1334\n",
            "Epoch 102/200\n",
            "338/338 [==============================] - 0s 377us/step - loss: 0.0828 - mean_absolute_error: 0.1295\n",
            "Epoch 103/200\n",
            "338/338 [==============================] - 0s 367us/step - loss: 0.0899 - mean_absolute_error: 0.1359\n",
            "Epoch 104/200\n",
            "338/338 [==============================] - 0s 379us/step - loss: 0.0842 - mean_absolute_error: 0.1377\n",
            "Epoch 105/200\n",
            "338/338 [==============================] - 0s 377us/step - loss: 0.0897 - mean_absolute_error: 0.1346\n",
            "Epoch 106/200\n",
            "338/338 [==============================] - 0s 375us/step - loss: 0.0911 - mean_absolute_error: 0.1374\n",
            "Epoch 107/200\n",
            "338/338 [==============================] - 0s 380us/step - loss: 0.0859 - mean_absolute_error: 0.1322\n",
            "Epoch 108/200\n",
            "338/338 [==============================] - 0s 366us/step - loss: 0.0869 - mean_absolute_error: 0.1317\n",
            "Epoch 109/200\n",
            "338/338 [==============================] - 0s 379us/step - loss: 0.0892 - mean_absolute_error: 0.1342\n",
            "Epoch 110/200\n",
            "338/338 [==============================] - 0s 367us/step - loss: 0.0829 - mean_absolute_error: 0.1327\n",
            "Epoch 111/200\n",
            "338/338 [==============================] - 0s 378us/step - loss: 0.0838 - mean_absolute_error: 0.1376\n",
            "Epoch 112/200\n",
            "338/338 [==============================] - 0s 380us/step - loss: 0.0889 - mean_absolute_error: 0.1380\n",
            "Epoch 113/200\n",
            "338/338 [==============================] - 0s 379us/step - loss: 0.0858 - mean_absolute_error: 0.1304\n",
            "Epoch 114/200\n",
            "338/338 [==============================] - 0s 398us/step - loss: 0.0858 - mean_absolute_error: 0.1313\n",
            "Epoch 115/200\n",
            "338/338 [==============================] - 0s 372us/step - loss: 0.0840 - mean_absolute_error: 0.1329\n",
            "Epoch 116/200\n",
            "338/338 [==============================] - 0s 373us/step - loss: 0.0860 - mean_absolute_error: 0.1346\n",
            "Epoch 117/200\n",
            "338/338 [==============================] - 0s 384us/step - loss: 0.0850 - mean_absolute_error: 0.1398\n",
            "Epoch 118/200\n",
            "338/338 [==============================] - 0s 369us/step - loss: 0.0906 - mean_absolute_error: 0.1437\n",
            "Epoch 119/200\n",
            "338/338 [==============================] - 0s 373us/step - loss: 0.0895 - mean_absolute_error: 0.1322\n",
            "Epoch 120/200\n",
            "338/338 [==============================] - 0s 374us/step - loss: 0.0884 - mean_absolute_error: 0.1426\n",
            "Epoch 121/200\n",
            "338/338 [==============================] - 0s 398us/step - loss: 0.0863 - mean_absolute_error: 0.1411\n",
            "Epoch 122/200\n",
            "338/338 [==============================] - 0s 373us/step - loss: 0.0870 - mean_absolute_error: 0.1289\n",
            "Epoch 123/200\n",
            "338/338 [==============================] - 0s 371us/step - loss: 0.0866 - mean_absolute_error: 0.1385\n",
            "Epoch 124/200\n",
            "338/338 [==============================] - 0s 390us/step - loss: 0.0862 - mean_absolute_error: 0.1333\n",
            "Epoch 125/200\n",
            "338/338 [==============================] - 0s 373us/step - loss: 0.0862 - mean_absolute_error: 0.1287\n",
            "Epoch 126/200\n",
            "338/338 [==============================] - 0s 372us/step - loss: 0.0824 - mean_absolute_error: 0.1326\n",
            "Epoch 127/200\n",
            "338/338 [==============================] - 0s 389us/step - loss: 0.0775 - mean_absolute_error: 0.1302\n",
            "Epoch 128/200\n",
            "338/338 [==============================] - 0s 370us/step - loss: 0.0796 - mean_absolute_error: 0.1354\n",
            "Epoch 129/200\n",
            "338/338 [==============================] - 0s 375us/step - loss: 0.0853 - mean_absolute_error: 0.1378\n",
            "Epoch 130/200\n",
            "338/338 [==============================] - 0s 393us/step - loss: 0.0886 - mean_absolute_error: 0.1392\n",
            "Epoch 131/200\n",
            "338/338 [==============================] - 0s 377us/step - loss: 0.0852 - mean_absolute_error: 0.1417\n",
            "Epoch 132/200\n",
            "338/338 [==============================] - 0s 369us/step - loss: 0.0872 - mean_absolute_error: 0.1409\n",
            "Epoch 133/200\n",
            "338/338 [==============================] - 0s 383us/step - loss: 0.0841 - mean_absolute_error: 0.1343\n",
            "Epoch 134/200\n",
            "338/338 [==============================] - 0s 367us/step - loss: 0.0839 - mean_absolute_error: 0.1377\n",
            "Epoch 135/200\n",
            "338/338 [==============================] - 0s 368us/step - loss: 0.0824 - mean_absolute_error: 0.1342\n",
            "Epoch 136/200\n",
            "338/338 [==============================] - 0s 378us/step - loss: 0.0864 - mean_absolute_error: 0.1390\n",
            "Epoch 137/200\n",
            "338/338 [==============================] - 0s 385us/step - loss: 0.0851 - mean_absolute_error: 0.1397\n",
            "Epoch 138/200\n",
            "338/338 [==============================] - 0s 368us/step - loss: 0.0821 - mean_absolute_error: 0.1373\n",
            "Epoch 139/200\n",
            "338/338 [==============================] - 0s 369us/step - loss: 0.0915 - mean_absolute_error: 0.1370\n",
            "Epoch 140/200\n",
            "338/338 [==============================] - 0s 385us/step - loss: 0.0800 - mean_absolute_error: 0.1330\n",
            "Epoch 141/200\n",
            "338/338 [==============================] - 0s 366us/step - loss: 0.0865 - mean_absolute_error: 0.1366\n",
            "Epoch 142/200\n",
            "338/338 [==============================] - 0s 364us/step - loss: 0.0853 - mean_absolute_error: 0.1310\n",
            "Epoch 143/200\n",
            "338/338 [==============================] - 0s 397us/step - loss: 0.0836 - mean_absolute_error: 0.1328\n",
            "Epoch 144/200\n",
            "338/338 [==============================] - 0s 389us/step - loss: 0.0861 - mean_absolute_error: 0.1340\n",
            "Epoch 145/200\n",
            "338/338 [==============================] - 0s 373us/step - loss: 0.0927 - mean_absolute_error: 0.1354\n",
            "Epoch 146/200\n",
            "338/338 [==============================] - 0s 375us/step - loss: 0.0881 - mean_absolute_error: 0.1317\n",
            "Epoch 147/200\n",
            "338/338 [==============================] - 0s 388us/step - loss: 0.0818 - mean_absolute_error: 0.1348\n",
            "Epoch 148/200\n",
            "338/338 [==============================] - 0s 374us/step - loss: 0.0827 - mean_absolute_error: 0.1284\n",
            "Epoch 149/200\n",
            "338/338 [==============================] - 0s 379us/step - loss: 0.0827 - mean_absolute_error: 0.1374\n",
            "Epoch 150/200\n",
            "338/338 [==============================] - 0s 371us/step - loss: 0.0794 - mean_absolute_error: 0.1298\n",
            "Epoch 151/200\n",
            "338/338 [==============================] - 0s 371us/step - loss: 0.0819 - mean_absolute_error: 0.1342\n",
            "Epoch 152/200\n",
            "338/338 [==============================] - 0s 394us/step - loss: 0.0807 - mean_absolute_error: 0.1309\n",
            "Epoch 153/200\n",
            "338/338 [==============================] - 0s 377us/step - loss: 0.0822 - mean_absolute_error: 0.1374\n",
            "Epoch 154/200\n",
            "338/338 [==============================] - 0s 375us/step - loss: 0.0814 - mean_absolute_error: 0.1328\n",
            "Epoch 155/200\n",
            "338/338 [==============================] - 0s 391us/step - loss: 0.0882 - mean_absolute_error: 0.1415\n",
            "Epoch 156/200\n",
            "338/338 [==============================] - 0s 370us/step - loss: 0.0855 - mean_absolute_error: 0.1385\n",
            "Epoch 157/200\n",
            "338/338 [==============================] - 0s 371us/step - loss: 0.0817 - mean_absolute_error: 0.1290\n",
            "Epoch 158/200\n",
            "338/338 [==============================] - 0s 385us/step - loss: 0.0859 - mean_absolute_error: 0.1370\n",
            "Epoch 159/200\n",
            "338/338 [==============================] - 0s 378us/step - loss: 0.0865 - mean_absolute_error: 0.1309\n",
            "Epoch 160/200\n",
            "338/338 [==============================] - 0s 376us/step - loss: 0.0806 - mean_absolute_error: 0.1387\n",
            "Epoch 161/200\n",
            "338/338 [==============================] - 0s 383us/step - loss: 0.0822 - mean_absolute_error: 0.1418\n",
            "Epoch 162/200\n",
            "338/338 [==============================] - 0s 373us/step - loss: 0.0823 - mean_absolute_error: 0.1401\n",
            "Epoch 163/200\n",
            "338/338 [==============================] - 0s 375us/step - loss: 0.0855 - mean_absolute_error: 0.1395\n",
            "Epoch 164/200\n",
            "338/338 [==============================] - 0s 403us/step - loss: 0.0850 - mean_absolute_error: 0.1364\n",
            "Epoch 165/200\n",
            "338/338 [==============================] - 0s 371us/step - loss: 0.0799 - mean_absolute_error: 0.1270\n",
            "Epoch 166/200\n",
            "338/338 [==============================] - 0s 372us/step - loss: 0.0786 - mean_absolute_error: 0.1363\n",
            "Epoch 167/200\n",
            "338/338 [==============================] - 0s 380us/step - loss: 0.0833 - mean_absolute_error: 0.1419\n",
            "Epoch 168/200\n",
            "338/338 [==============================] - 0s 380us/step - loss: 0.0861 - mean_absolute_error: 0.1379\n",
            "Epoch 169/200\n",
            "338/338 [==============================] - 0s 370us/step - loss: 0.0803 - mean_absolute_error: 0.1341\n",
            "Epoch 170/200\n",
            "338/338 [==============================] - 0s 397us/step - loss: 0.0792 - mean_absolute_error: 0.1341\n",
            "Epoch 171/200\n",
            "338/338 [==============================] - 0s 416us/step - loss: 0.0778 - mean_absolute_error: 0.1292\n",
            "Epoch 172/200\n",
            "338/338 [==============================] - 0s 379us/step - loss: 0.0800 - mean_absolute_error: 0.1324\n",
            "Epoch 173/200\n",
            "338/338 [==============================] - 0s 373us/step - loss: 0.0826 - mean_absolute_error: 0.1371\n",
            "Epoch 174/200\n",
            "338/338 [==============================] - 0s 376us/step - loss: 0.0830 - mean_absolute_error: 0.1424\n",
            "Epoch 175/200\n",
            "338/338 [==============================] - 0s 399us/step - loss: 0.0833 - mean_absolute_error: 0.1385\n",
            "Epoch 176/200\n",
            "338/338 [==============================] - 0s 373us/step - loss: 0.0819 - mean_absolute_error: 0.1319\n",
            "Epoch 177/200\n",
            "338/338 [==============================] - 0s 369us/step - loss: 0.0832 - mean_absolute_error: 0.1401\n",
            "Epoch 178/200\n",
            "338/338 [==============================] - 0s 383us/step - loss: 0.0828 - mean_absolute_error: 0.1335\n",
            "Epoch 179/200\n",
            "338/338 [==============================] - 0s 379us/step - loss: 0.0789 - mean_absolute_error: 0.1429\n",
            "Epoch 180/200\n",
            "338/338 [==============================] - 0s 373us/step - loss: 0.0836 - mean_absolute_error: 0.1378\n",
            "Epoch 181/200\n",
            "338/338 [==============================] - 0s 385us/step - loss: 0.0786 - mean_absolute_error: 0.1297\n",
            "Epoch 182/200\n",
            "338/338 [==============================] - 0s 380us/step - loss: 0.0833 - mean_absolute_error: 0.1422\n",
            "Epoch 183/200\n",
            "338/338 [==============================] - 0s 376us/step - loss: 0.0810 - mean_absolute_error: 0.1407\n",
            "Epoch 184/200\n",
            "338/338 [==============================] - 0s 371us/step - loss: 0.0804 - mean_absolute_error: 0.1365\n",
            "Epoch 185/200\n",
            "338/338 [==============================] - 0s 408us/step - loss: 0.0798 - mean_absolute_error: 0.1339\n",
            "Epoch 186/200\n",
            "338/338 [==============================] - 0s 373us/step - loss: 0.0844 - mean_absolute_error: 0.1357\n",
            "Epoch 187/200\n",
            "338/338 [==============================] - 0s 370us/step - loss: 0.0842 - mean_absolute_error: 0.1386\n",
            "Epoch 188/200\n",
            "338/338 [==============================] - 0s 389us/step - loss: 0.0839 - mean_absolute_error: 0.1338\n",
            "Epoch 189/200\n",
            "338/338 [==============================] - 0s 369us/step - loss: 0.0828 - mean_absolute_error: 0.1374\n",
            "Epoch 190/200\n",
            "338/338 [==============================] - 0s 374us/step - loss: 0.0811 - mean_absolute_error: 0.1357\n",
            "Epoch 191/200\n",
            "338/338 [==============================] - 0s 398us/step - loss: 0.0904 - mean_absolute_error: 0.1365\n",
            "Epoch 192/200\n",
            "338/338 [==============================] - 0s 376us/step - loss: 0.0832 - mean_absolute_error: 0.1388\n",
            "Epoch 193/200\n",
            "338/338 [==============================] - 0s 373us/step - loss: 0.0772 - mean_absolute_error: 0.1331\n",
            "Epoch 194/200\n",
            "338/338 [==============================] - 0s 387us/step - loss: 0.0783 - mean_absolute_error: 0.1367\n",
            "Epoch 195/200\n",
            "338/338 [==============================] - 0s 369us/step - loss: 0.0785 - mean_absolute_error: 0.1353\n",
            "Epoch 196/200\n",
            "338/338 [==============================] - 0s 371us/step - loss: 0.0802 - mean_absolute_error: 0.1343\n",
            "Epoch 197/200\n",
            "338/338 [==============================] - 0s 381us/step - loss: 0.0813 - mean_absolute_error: 0.1363\n",
            "Epoch 198/200\n",
            "338/338 [==============================] - 0s 373us/step - loss: 0.0765 - mean_absolute_error: 0.1396\n",
            "Epoch 199/200\n",
            "338/338 [==============================] - 0s 376us/step - loss: 0.0855 - mean_absolute_error: 0.1345\n",
            "Epoch 200/200\n",
            "338/338 [==============================] - 0s 384us/step - loss: 0.0772 - mean_absolute_error: 0.1297\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9d8_B0Z4zqYy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def visualize_learning_curve(history):\n",
        "#     # list all data in history\n",
        "#     print(history.history.keys())\n",
        "#     # summarize history for accuracy\n",
        "#     plt.plot(history.history['loss'])\n",
        "#     plt.plot(history.history['val_loss'])\n",
        "#     plt.title('model loss')\n",
        "#     plt.ylabel('loss')\n",
        "#     plt.xlabel('epoch')\n",
        "#     plt.legend(['train', 'validation'], loc='upper left')\n",
        "#     plt.show()\n",
        "#     # summarize history for loss\n",
        "#     plt.plot(history.history['mean_absolute_error'])\n",
        "#     plt.plot(history.history['val_mean_absolute_error'])\n",
        "#     plt.title('model mean_absolute_error')\n",
        "#     plt.ylabel('mean_absolute_error')\n",
        "#     plt.xlabel('epoch')\n",
        "#     plt.legend(['train', 'validation'], loc='upper left')\n",
        "#     plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kuqj8rvH0VMC",
        "colab_type": "code",
        "outputId": "01aebff7-bd2e-4419-b57f-a9e3ad874054",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "#row wise'\n",
        "\n",
        "print(X_test.shape)\n",
        "X_test_t = X_test.transpose()\n",
        "print(X_test_t.shape)\n",
        "scaler_rob_x = RobustScaler().fit(X_test_t)\n",
        "X_new_test_t = scaler_rob_x.transform(X_test_t)\n",
        "X_new_test = X_new_test_t.transpose()\n",
        "print(X_new_test.shape)\n",
        "\n",
        "y_test_t = y_test.transpose()\n",
        "scaler_rob_y = RobustScaler().fit(y_test_t)\n",
        "Y_new_test_t = scaler_rob_y.transform(y_test_t)\n",
        "Y_new_test = Y_new_test_t.transpose()\n",
        "\n",
        "X_new_test = factor_fit.transform(X_new_test)\n",
        "print(X_new_test.shape)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(85, 10000)\n",
            "(10000, 85)\n",
            "(85, 10000)\n",
            "(85, 30)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqFvR1Itm4rd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # print(X_test.shape)\n",
        "# # X_test_t = X_test.transpose()\n",
        "# # print(X_test_t.shape)\n",
        "# # scaler_rob_x = RobustScaler().fit(X_test)\n",
        "# X_new_test = scaler_stan_x.transform(X_test)\n",
        "# # X_new_test = X_new_test_t.transpose()\n",
        "# print(X_new_test.shape)\n",
        "\n",
        "# # y_test_t = y_test.transpose()\n",
        "# # scaler_rob_y = RobustScaler().fit(y_test_t)\n",
        "# Y_new_test = scaler_stan_y.transform(y_test)\n",
        "# # Y_new_test = Y_new_test_t.transpose()\n",
        "\n",
        "# X_new_test = pca_fit.transform(X_new_test)\n",
        "# print(X_new_test.shape)\n",
        "\n",
        "# results = model.evaluate(X_new_test, Y_new_test)\n",
        "# print('loss: ', results[0])\n",
        "# print('mse: ', results[1])\n",
        "\n",
        "# print('accuracy',results[2])\n",
        "\n",
        "# visualize_learning_curve(history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYQL8uR307Sa",
        "colab_type": "code",
        "outputId": "15d9e55f-4246-4b10-8bbf-59bb08078c40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
        "import math\n",
        "from sklearn.metrics import max_error\n",
        "\n",
        "pred = estimator.predict((X_new_test))\n",
        "print(pred.shape)\n",
        "\n",
        "mse = (mean_squared_error(Y_new_test,pred))\n",
        "\n",
        "print(mse)\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(85, 2)\n",
            "0.12621013009625598\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCd-rzIoIjET",
        "colab_type": "text"
      },
      "source": [
        "view test results\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFot1fw80rNZ",
        "colab_type": "code",
        "outputId": "2448d1fb-b8c1-4dc2-8af0-130c7ac25119",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "#row wise\n",
        "\n",
        "\n",
        "for i in range(len(y_test)):\n",
        "  \n",
        "#   print(y_test[i],\"ytest[i]\")\n",
        "  \n",
        "  \n",
        "#   print(X_test[i])\n",
        "  X_test_t= X_test[i].transpose()\n",
        "#   print(X_test_t.reshape(-1, 1).shape,\"X_test fitted \")\n",
        "#   print(X_test_t.shape)\n",
        "  scaler_rob_x = RobustScaler().fit((X_test_t.reshape(-1, 1)))\n",
        "#   print(X_test_t.reshape(-1, 1))                            \n",
        "  X = (scaler_rob_x.transform(X_test_t.reshape(-1, 1)))\n",
        "#   print(X.shape,\"X shape\")\n",
        "  I = factor_fit.transform(X.transpose())\n",
        "#   print(I.shape,\"I\")\n",
        "  pred = estimator.predict(I)\n",
        "#   print(pred.shape,\"pred.shape\")\n",
        "  \n",
        "  y_test_ti = y_test[i].transpose()\n",
        "#   print(y_test_ti.reshape(-1, 1).shape,\"ytest tranposed shape\")\n",
        "  scaler_rob_y = RobustScaler().fit(y_test_ti.reshape(-1, 1))\n",
        "  final_t = scaler_rob_y.inverse_transform(pred.reshape(-1, 1))\n",
        "                                          \n",
        "#   print(final_t.shape)\n",
        "  final = final_t.transpose()\n",
        "                                          \n",
        "#   print(final[0])\n",
        "\n",
        "  h = abs(final-y_test[i])\n",
        "#   print(h,\"h\")\n",
        "  o=np.divide(h,y_test[i])\n",
        "#   print(o*100,\"percentage\") \n"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:33: RuntimeWarning: divide by zero encountered in true_divide\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:33: RuntimeWarning: divide by zero encountered in true_divide\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:33: RuntimeWarning: divide by zero encountered in true_divide\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:33: RuntimeWarning: divide by zero encountered in true_divide\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCJMVBksukDB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "####creating new X,Y\n",
        "X1 = input_1_arr[:,0:10000]\n",
        "Y1 = input_1_arr[:,10000:10004]\n",
        "\n",
        "X=X1\n",
        "Y=Y1[:,2:4]\n",
        "# print(Y)\n",
        "Y_new = np.zeros((Y.shape[0],2))\n",
        "for i in range(len(Y)):\n",
        "  \n",
        "#   print(Y[i],\"y\")\n",
        "#   print(Y.shape)\n",
        "  \n",
        "  \n",
        "\n",
        "  X_t= X[i].transpose()\n",
        "#   print(X_test_t.reshape(-1, 1).shape,\"X_test fitted \")\n",
        "#   print(X_test_t.shape)\n",
        "  scaler_rob_x = RobustScaler().fit((X_t.reshape(-1, 1)))\n",
        "#   print(X_test_t.reshape(-1, 1))                            \n",
        "  Xi = (scaler_rob_x.transform(X_t.reshape(-1, 1)))\n",
        "#   print(X.shape,\"X shape\")\n",
        "  I = factor_fit.transform(Xi.transpose())\n",
        "#   print(I.shape,\"I\")\n",
        "  pred = estimator.predict(I)\n",
        "#   print(pred.shape,\"pred.shape\")\n",
        "  \n",
        "  Y_ti =Y[i].transpose()\n",
        "#   print(y_test_ti.reshape(-1, 1).shape,\"ytest tranposed shape\")\n",
        "  scaler_rob_y = RobustScaler().fit(Y_ti.reshape(-1, 1))\n",
        "  final_t = scaler_rob_y.inverse_transform(pred.reshape(-1, 1))\n",
        "                                          \n",
        "#   print(final_t.shape)\n",
        "  final = final_t.transpose()\n",
        "                                          \n",
        "#   print(final[0])\n",
        "\n",
        "  h = abs(final-Y[i])\n",
        "#   print(h,\"h\")\n",
        "  o=np.divide(h,Y[i])\n",
        "#   print(o*100,\"percentage\") \n",
        "  \n",
        "  Y_new[i]=final[0]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVL_dl5Pzj5R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X1 = X1\n",
        "Y1 = Y1\n",
        "# print(Y1)\n",
        "\n",
        "# print(Y)\n",
        "\n",
        "# print(Y_new[:,0])\n",
        "\n",
        "Y1[:,2]= Y_new[:,0]\n",
        "Y1[:,3]= Y_new[:,1]\n",
        "# print(Y1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "019ZECRx3jFP",
        "colab_type": "code",
        "outputId": "d4b8f61f-ce1b-439f-e10b-7ad18ce3e4dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X1_new = np.concatenate((X1,Y1[:,2:4]),axis=1)\n",
        "print(X1_new.shape)\n",
        "Y1_new = Y1[:,0:2]\n",
        "# print(Y1_new)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(423, 10002)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7X0ut1rT5DYE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train and test\n",
        "\n",
        "X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(X1_new, Y1_new, test_size=0.20)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgmKJr9R4y6I",
        "colab_type": "code",
        "outputId": "18032521-50ce-4f69-b1ee-6be2597e96a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "#standardise\n",
        "\n",
        "\n",
        "# ######minmax\n",
        "scaler_min_x = MinMaxScaler().fit(X_train_c)\n",
        "scaler_min_y = MinMaxScaler().fit(y_train_c)\n",
        "\n",
        "X_minmax_train = scaler_min_x.transform(X_train_c)\n",
        "Y_minmax_train = scaler_min_y.transform(y_train_c)\n",
        "\n",
        "\n",
        "# print(X)\n",
        "# print(Y)\n",
        "#####standard\n",
        "\n",
        "scaler_stan_x = StandardScaler().fit(X_train_c)\n",
        "scaler_stan_y = StandardScaler().fit(y_train_c)\n",
        "\n",
        "\n",
        "X_stan_train = scaler_stan_x.transform(X_train_c)\n",
        "Y_stan_train = scaler_stan_y.transform(y_train_c)\n",
        "\n",
        "#######normlised\n",
        "scaler_norm_x = Normalizer().fit(X_train_c)\n",
        "scaler_norm_y = Normalizer().fit(y_train_c)\n",
        "\n",
        "\n",
        "X_norm_train = scaler_norm_x.transform(X_train_c)\n",
        "Y_norm_train = scaler_norm_y.transform(y_train_c)\n",
        "\n",
        "\n",
        "# ################qt\n",
        "\n",
        "scaler_qt_x =  QuantileTransformer(output_distribution='normal').fit(X_train_c)\n",
        "scaler_qt_y =  QuantileTransformer(output_distribution='normal').fit(y_train_c)\n",
        "\n",
        "\n",
        "X_qt_train = scaler_qt_x.transform(X_train_c)\n",
        "Y_qt_train = scaler_qt_y.transform(y_train_c)\n",
        "\n",
        "\n",
        "##robust\n",
        "# print(X_train.shape)\n",
        "# print(y_train.shape)\n",
        "# X_train_t = X_train.transpose()\n",
        "# y_train_t = y_train.transpose()\n",
        "# print(X_train.shape,\"after\")\n",
        "# print(y_train.shape,\"after\")\n",
        "scaler_rob_x = RobustScaler().fit(X_train_c)\n",
        "scaler_rob_y = RobustScaler().fit(y_train_c)\n",
        "\n",
        "\n",
        "X_rob_train = scaler_rob_x.transform(X_train_c)\n",
        "Y_rob_train = scaler_rob_y.transform(y_train_c)\n",
        "\n",
        "# X_rob_train = X_rob_train.transpose()\n",
        "# Y_rob_train = Y_rob_train.transpose()\n",
        "\n",
        "# print(X_rob_train.shape)\n",
        "# print(Y_rob_train.shape)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:2239: UserWarning: n_quantiles (1000) is greater than the total number of samples (338). n_quantiles is set to n_samples.\n",
            "  % (self.n_quantiles, n_samples))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/data.py:2239: UserWarning: n_quantiles (1000) is greater than the total number of samples (338). n_quantiles is set to n_samples.\n",
            "  % (self.n_quantiles, n_samples))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpiuG3rL4ec8",
        "colab_type": "code",
        "outputId": "4e9d4724-5d1c-4cfb-ce92-4ccdeb54c1d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#apply PCA on X1_new\n",
        "transformer = FactorAnalysis(n_components=30, random_state=0)\n",
        "factor_fit = transformer.fit(X_rob_train[:,0:10000])\n",
        "X_new1 = factor_fit.transform(X_rob_train[:,0:10000])\n",
        "print(X_new1.shape)\n",
        "X_new1 = np.concatenate((X_new1,X_rob_train[:,10000:10002]),axis=1)\n",
        "print(X_new1.shape)\n",
        "# print((X_rob_train[:,0:10000].shape))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(338, 30)\n",
            "(338, 32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPzkUvPt6oUi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "def baseline_model_31(optimizer='adam'):\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "    model.add(Dense(28, activation='relu', \n",
        "                    kernel_initializer = 'he_normal', \n",
        "                    input_shape=(32,)))\n",
        "    model.add(BatchNormalization())\n",
        "#     model.add(Dropout(0.5))\n",
        "#     model.add(Dense(30, activation='relu',\n",
        "#                     kernel_initializer = 'he_normal'))\n",
        "#       model.add(BatchNormalization())\n",
        "#     model.add(Dropout(0.5))\n",
        "    model.add(Dense(12, activation='relu',\n",
        "                    kernel_initializer = 'he_normal'))\n",
        "    model.add(BatchNormalization())\n",
        "#     model.add(Dropout(0.5))\n",
        "    model.add(Dense(9, activation='relu',\n",
        "                    kernel_initializer = 'he_normal'))\n",
        "#     model.add(BatchNormalization())\n",
        "#     model.add(Dropout(0.5))\n",
        "    model.add(Dense(2, activation='linear', \n",
        "                    kernel_initializer='he_normal'))\n",
        "    model.compile(loss = 'mse', optimizer=optimizer, metrics=['mae'])\n",
        "#     model.summary()\n",
        "    return model\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9TAs18b6-e4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_data_nn_1(X_train, y_train):\n",
        "    \n",
        "    np.random.seed(42)\n",
        "    # create model\n",
        "    estimator = KerasRegressor(build_fn=baseline_model_31, epochs=200, batch_size=5, verbose=0)\n",
        "    kfold = KFold(n_splits=5, random_state=None )\n",
        "    results = cross_val_score(estimator, X_train, y_train, cv=kfold)  \n",
        "    print(\"Standardized: %.2f (%.2f) MSE\" % (results.mean(), results.std()))\n",
        "    return estimator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDiBevcz7HND",
        "colab_type": "code",
        "outputId": "bd4b0e51-7384-4b2b-d669-bdda1dac811a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model1 = baseline_model_31()\n",
        "\n",
        "estimator1 = train_data_nn_1(X_new1, Y_rob_train)\n",
        "\n",
        "# print(X_new.shape)\n",
        "# print(y_train.shape)\n",
        "history = estimator1.fit(X_new1,  Y_rob_train, epochs=300, batch_size=5,  verbose=1, validation_split=0.0)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Standardized: -3.09 (1.15) MSE\n",
            "Epoch 1/300\n",
            "338/338 [==============================] - 2s 6ms/step - loss: 5.8541 - mean_absolute_error: 1.6570\n",
            "Epoch 2/300\n",
            "338/338 [==============================] - 0s 428us/step - loss: 4.6348 - mean_absolute_error: 1.3620\n",
            "Epoch 3/300\n",
            "338/338 [==============================] - 0s 437us/step - loss: 4.0445 - mean_absolute_error: 1.2032\n",
            "Epoch 4/300\n",
            "338/338 [==============================] - 0s 434us/step - loss: 3.9467 - mean_absolute_error: 1.1255\n",
            "Epoch 5/300\n",
            "338/338 [==============================] - 0s 454us/step - loss: 3.7057 - mean_absolute_error: 1.0495\n",
            "Epoch 6/300\n",
            "338/338 [==============================] - 0s 457us/step - loss: 3.7767 - mean_absolute_error: 1.0577\n",
            "Epoch 7/300\n",
            "338/338 [==============================] - 0s 458us/step - loss: 3.6310 - mean_absolute_error: 1.0037\n",
            "Epoch 8/300\n",
            "338/338 [==============================] - 0s 439us/step - loss: 3.6720 - mean_absolute_error: 0.9883\n",
            "Epoch 9/300\n",
            "338/338 [==============================] - 0s 433us/step - loss: 3.5515 - mean_absolute_error: 0.9606\n",
            "Epoch 10/300\n",
            "338/338 [==============================] - 0s 452us/step - loss: 3.5955 - mean_absolute_error: 0.9304\n",
            "Epoch 11/300\n",
            "338/338 [==============================] - 0s 456us/step - loss: 3.4649 - mean_absolute_error: 0.9308\n",
            "Epoch 12/300\n",
            "338/338 [==============================] - 0s 433us/step - loss: 3.3304 - mean_absolute_error: 0.9079\n",
            "Epoch 13/300\n",
            "338/338 [==============================] - 0s 441us/step - loss: 3.1753 - mean_absolute_error: 0.8856\n",
            "Epoch 14/300\n",
            "338/338 [==============================] - 0s 458us/step - loss: 3.1590 - mean_absolute_error: 0.8592\n",
            "Epoch 15/300\n",
            "338/338 [==============================] - 0s 441us/step - loss: 3.0931 - mean_absolute_error: 0.8553\n",
            "Epoch 16/300\n",
            "338/338 [==============================] - 0s 452us/step - loss: 3.2115 - mean_absolute_error: 0.8669\n",
            "Epoch 17/300\n",
            "338/338 [==============================] - 0s 454us/step - loss: 3.0041 - mean_absolute_error: 0.8417\n",
            "Epoch 18/300\n",
            "338/338 [==============================] - 0s 452us/step - loss: 3.1956 - mean_absolute_error: 0.8376\n",
            "Epoch 19/300\n",
            "338/338 [==============================] - 0s 437us/step - loss: 2.8750 - mean_absolute_error: 0.8110\n",
            "Epoch 20/300\n",
            "338/338 [==============================] - 0s 455us/step - loss: 3.0255 - mean_absolute_error: 0.8570\n",
            "Epoch 21/300\n",
            "338/338 [==============================] - 0s 443us/step - loss: 2.9701 - mean_absolute_error: 0.8241\n",
            "Epoch 22/300\n",
            "338/338 [==============================] - 0s 444us/step - loss: 2.8129 - mean_absolute_error: 0.8034\n",
            "Epoch 23/300\n",
            "338/338 [==============================] - 0s 455us/step - loss: 2.9084 - mean_absolute_error: 0.8067\n",
            "Epoch 24/300\n",
            "338/338 [==============================] - 0s 433us/step - loss: 2.6556 - mean_absolute_error: 0.7828\n",
            "Epoch 25/300\n",
            "338/338 [==============================] - 0s 442us/step - loss: 2.7824 - mean_absolute_error: 0.7867\n",
            "Epoch 26/300\n",
            "338/338 [==============================] - 0s 442us/step - loss: 2.8288 - mean_absolute_error: 0.7999\n",
            "Epoch 27/300\n",
            "338/338 [==============================] - 0s 456us/step - loss: 2.7649 - mean_absolute_error: 0.7935\n",
            "Epoch 28/300\n",
            "338/338 [==============================] - 0s 456us/step - loss: 2.6554 - mean_absolute_error: 0.7759\n",
            "Epoch 29/300\n",
            "338/338 [==============================] - 0s 442us/step - loss: 2.8073 - mean_absolute_error: 0.7885\n",
            "Epoch 30/300\n",
            "338/338 [==============================] - 0s 454us/step - loss: 2.6866 - mean_absolute_error: 0.7671\n",
            "Epoch 31/300\n",
            "338/338 [==============================] - 0s 448us/step - loss: 2.6059 - mean_absolute_error: 0.7707\n",
            "Epoch 32/300\n",
            "338/338 [==============================] - 0s 461us/step - loss: 2.5924 - mean_absolute_error: 0.7545\n",
            "Epoch 33/300\n",
            "338/338 [==============================] - 0s 456us/step - loss: 2.6390 - mean_absolute_error: 0.7597\n",
            "Epoch 34/300\n",
            "338/338 [==============================] - 0s 447us/step - loss: 2.3468 - mean_absolute_error: 0.7293\n",
            "Epoch 35/300\n",
            "338/338 [==============================] - 0s 432us/step - loss: 2.3562 - mean_absolute_error: 0.7296\n",
            "Epoch 36/300\n",
            "338/338 [==============================] - 0s 456us/step - loss: 2.3499 - mean_absolute_error: 0.7251\n",
            "Epoch 37/300\n",
            "338/338 [==============================] - 0s 446us/step - loss: 2.5105 - mean_absolute_error: 0.7303\n",
            "Epoch 38/300\n",
            "338/338 [==============================] - 0s 441us/step - loss: 2.5327 - mean_absolute_error: 0.7448\n",
            "Epoch 39/300\n",
            "338/338 [==============================] - 0s 459us/step - loss: 2.5207 - mean_absolute_error: 0.7450\n",
            "Epoch 40/300\n",
            "338/338 [==============================] - 0s 442us/step - loss: 2.5346 - mean_absolute_error: 0.7174\n",
            "Epoch 41/300\n",
            "338/338 [==============================] - 0s 458us/step - loss: 2.3278 - mean_absolute_error: 0.7247\n",
            "Epoch 42/300\n",
            "338/338 [==============================] - 0s 473us/step - loss: 2.3370 - mean_absolute_error: 0.7158\n",
            "Epoch 43/300\n",
            "338/338 [==============================] - 0s 438us/step - loss: 2.3683 - mean_absolute_error: 0.6976\n",
            "Epoch 44/300\n",
            "338/338 [==============================] - 0s 420us/step - loss: 2.5524 - mean_absolute_error: 0.7407\n",
            "Epoch 45/300\n",
            "338/338 [==============================] - 0s 454us/step - loss: 2.3504 - mean_absolute_error: 0.7178\n",
            "Epoch 46/300\n",
            "338/338 [==============================] - 0s 439us/step - loss: 2.3921 - mean_absolute_error: 0.7008\n",
            "Epoch 47/300\n",
            "338/338 [==============================] - 0s 497us/step - loss: 2.4473 - mean_absolute_error: 0.6952\n",
            "Epoch 48/300\n",
            "338/338 [==============================] - 0s 434us/step - loss: 2.3042 - mean_absolute_error: 0.6849\n",
            "Epoch 49/300\n",
            "338/338 [==============================] - 0s 447us/step - loss: 2.1326 - mean_absolute_error: 0.6726\n",
            "Epoch 50/300\n",
            "338/338 [==============================] - 0s 449us/step - loss: 2.2589 - mean_absolute_error: 0.6741\n",
            "Epoch 51/300\n",
            "338/338 [==============================] - 0s 442us/step - loss: 2.4195 - mean_absolute_error: 0.6924\n",
            "Epoch 52/300\n",
            "338/338 [==============================] - 0s 474us/step - loss: 2.4067 - mean_absolute_error: 0.6876\n",
            "Epoch 53/300\n",
            "338/338 [==============================] - 0s 444us/step - loss: 2.2530 - mean_absolute_error: 0.6862\n",
            "Epoch 54/300\n",
            "338/338 [==============================] - 0s 445us/step - loss: 2.3477 - mean_absolute_error: 0.6687\n",
            "Epoch 55/300\n",
            "338/338 [==============================] - 0s 453us/step - loss: 2.3124 - mean_absolute_error: 0.6799\n",
            "Epoch 56/300\n",
            "338/338 [==============================] - 0s 450us/step - loss: 2.2631 - mean_absolute_error: 0.7090\n",
            "Epoch 57/300\n",
            "338/338 [==============================] - 0s 429us/step - loss: 2.0686 - mean_absolute_error: 0.6711\n",
            "Epoch 58/300\n",
            "338/338 [==============================] - 0s 460us/step - loss: 2.3441 - mean_absolute_error: 0.6913\n",
            "Epoch 59/300\n",
            "338/338 [==============================] - 0s 448us/step - loss: 2.2457 - mean_absolute_error: 0.7008\n",
            "Epoch 60/300\n",
            "338/338 [==============================] - 0s 434us/step - loss: 2.2650 - mean_absolute_error: 0.6772\n",
            "Epoch 61/300\n",
            "338/338 [==============================] - 0s 454us/step - loss: 2.1964 - mean_absolute_error: 0.6756\n",
            "Epoch 62/300\n",
            "338/338 [==============================] - 0s 458us/step - loss: 2.1055 - mean_absolute_error: 0.6561\n",
            "Epoch 63/300\n",
            "338/338 [==============================] - 0s 440us/step - loss: 2.3295 - mean_absolute_error: 0.6815\n",
            "Epoch 64/300\n",
            "338/338 [==============================] - 0s 448us/step - loss: 2.2123 - mean_absolute_error: 0.6563\n",
            "Epoch 65/300\n",
            "338/338 [==============================] - 0s 466us/step - loss: 1.9715 - mean_absolute_error: 0.6334\n",
            "Epoch 66/300\n",
            "338/338 [==============================] - 0s 439us/step - loss: 2.2716 - mean_absolute_error: 0.6728\n",
            "Epoch 67/300\n",
            "338/338 [==============================] - 0s 513us/step - loss: 2.3768 - mean_absolute_error: 0.6724\n",
            "Epoch 68/300\n",
            "338/338 [==============================] - 0s 505us/step - loss: 2.0148 - mean_absolute_error: 0.6186\n",
            "Epoch 69/300\n",
            "338/338 [==============================] - 0s 444us/step - loss: 2.2685 - mean_absolute_error: 0.6565\n",
            "Epoch 70/300\n",
            "338/338 [==============================] - 0s 446us/step - loss: 2.1150 - mean_absolute_error: 0.6359\n",
            "Epoch 71/300\n",
            "338/338 [==============================] - 0s 450us/step - loss: 1.9970 - mean_absolute_error: 0.6496\n",
            "Epoch 72/300\n",
            "338/338 [==============================] - 0s 447us/step - loss: 1.9709 - mean_absolute_error: 0.6294\n",
            "Epoch 73/300\n",
            "338/338 [==============================] - 0s 432us/step - loss: 2.1828 - mean_absolute_error: 0.6676\n",
            "Epoch 74/300\n",
            "338/338 [==============================] - 0s 455us/step - loss: 2.1261 - mean_absolute_error: 0.6409\n",
            "Epoch 75/300\n",
            "338/338 [==============================] - 0s 454us/step - loss: 2.1686 - mean_absolute_error: 0.6614\n",
            "Epoch 76/300\n",
            "338/338 [==============================] - 0s 430us/step - loss: 2.0543 - mean_absolute_error: 0.6243\n",
            "Epoch 77/300\n",
            "338/338 [==============================] - 0s 456us/step - loss: 2.0965 - mean_absolute_error: 0.6431\n",
            "Epoch 78/300\n",
            "338/338 [==============================] - 0s 457us/step - loss: 2.1162 - mean_absolute_error: 0.6491\n",
            "Epoch 79/300\n",
            "338/338 [==============================] - 0s 438us/step - loss: 2.0109 - mean_absolute_error: 0.6071\n",
            "Epoch 80/300\n",
            "338/338 [==============================] - 0s 450us/step - loss: 2.0694 - mean_absolute_error: 0.6316\n",
            "Epoch 81/300\n",
            "338/338 [==============================] - 0s 448us/step - loss: 2.3897 - mean_absolute_error: 0.6945\n",
            "Epoch 82/300\n",
            "338/338 [==============================] - 0s 462us/step - loss: 2.0766 - mean_absolute_error: 0.6334\n",
            "Epoch 83/300\n",
            "338/338 [==============================] - 0s 428us/step - loss: 2.4420 - mean_absolute_error: 0.6736\n",
            "Epoch 84/300\n",
            "338/338 [==============================] - 0s 440us/step - loss: 2.0828 - mean_absolute_error: 0.6268\n",
            "Epoch 85/300\n",
            "338/338 [==============================] - 0s 436us/step - loss: 2.0361 - mean_absolute_error: 0.6174\n",
            "Epoch 86/300\n",
            "338/338 [==============================] - 0s 433us/step - loss: 1.8810 - mean_absolute_error: 0.6179\n",
            "Epoch 87/300\n",
            "338/338 [==============================] - 0s 469us/step - loss: 1.9842 - mean_absolute_error: 0.6202\n",
            "Epoch 88/300\n",
            "338/338 [==============================] - 0s 434us/step - loss: 2.0586 - mean_absolute_error: 0.6311\n",
            "Epoch 89/300\n",
            "338/338 [==============================] - 0s 438us/step - loss: 1.9785 - mean_absolute_error: 0.6297\n",
            "Epoch 90/300\n",
            "338/338 [==============================] - 0s 439us/step - loss: 1.7599 - mean_absolute_error: 0.5957\n",
            "Epoch 91/300\n",
            "338/338 [==============================] - 0s 441us/step - loss: 1.9222 - mean_absolute_error: 0.6122\n",
            "Epoch 92/300\n",
            "338/338 [==============================] - 0s 447us/step - loss: 2.1059 - mean_absolute_error: 0.6541\n",
            "Epoch 93/300\n",
            "338/338 [==============================] - 0s 473us/step - loss: 2.3267 - mean_absolute_error: 0.6666\n",
            "Epoch 94/300\n",
            "338/338 [==============================] - 0s 441us/step - loss: 2.0921 - mean_absolute_error: 0.6272\n",
            "Epoch 95/300\n",
            "338/338 [==============================] - 0s 440us/step - loss: 2.2578 - mean_absolute_error: 0.6493\n",
            "Epoch 96/300\n",
            "338/338 [==============================] - 0s 453us/step - loss: 1.9880 - mean_absolute_error: 0.6239\n",
            "Epoch 97/300\n",
            "338/338 [==============================] - 0s 448us/step - loss: 1.9474 - mean_absolute_error: 0.6270\n",
            "Epoch 98/300\n",
            "338/338 [==============================] - 0s 465us/step - loss: 1.8376 - mean_absolute_error: 0.5937\n",
            "Epoch 99/300\n",
            "338/338 [==============================] - 0s 427us/step - loss: 2.0833 - mean_absolute_error: 0.6638\n",
            "Epoch 100/300\n",
            "338/338 [==============================] - 0s 449us/step - loss: 2.1998 - mean_absolute_error: 0.6739\n",
            "Epoch 101/300\n",
            "338/338 [==============================] - 0s 431us/step - loss: 1.9901 - mean_absolute_error: 0.6376\n",
            "Epoch 102/300\n",
            "338/338 [==============================] - 0s 430us/step - loss: 1.8440 - mean_absolute_error: 0.6096\n",
            "Epoch 103/300\n",
            "338/338 [==============================] - 0s 435us/step - loss: 1.8780 - mean_absolute_error: 0.6184\n",
            "Epoch 104/300\n",
            "338/338 [==============================] - 0s 447us/step - loss: 1.6843 - mean_absolute_error: 0.5943\n",
            "Epoch 105/300\n",
            "338/338 [==============================] - 0s 450us/step - loss: 2.0509 - mean_absolute_error: 0.6213\n",
            "Epoch 106/300\n",
            "338/338 [==============================] - 0s 437us/step - loss: 1.9278 - mean_absolute_error: 0.6302\n",
            "Epoch 107/300\n",
            "338/338 [==============================] - 0s 457us/step - loss: 1.7481 - mean_absolute_error: 0.6016\n",
            "Epoch 108/300\n",
            "338/338 [==============================] - 0s 450us/step - loss: 1.9204 - mean_absolute_error: 0.6239\n",
            "Epoch 109/300\n",
            "338/338 [==============================] - 0s 436us/step - loss: 2.0598 - mean_absolute_error: 0.6503\n",
            "Epoch 110/300\n",
            "338/338 [==============================] - 0s 463us/step - loss: 1.8868 - mean_absolute_error: 0.5914\n",
            "Epoch 111/300\n",
            "338/338 [==============================] - 0s 444us/step - loss: 1.9421 - mean_absolute_error: 0.6208\n",
            "Epoch 112/300\n",
            "338/338 [==============================] - 0s 424us/step - loss: 1.6224 - mean_absolute_error: 0.5702\n",
            "Epoch 113/300\n",
            "338/338 [==============================] - 0s 438us/step - loss: 1.9200 - mean_absolute_error: 0.6158\n",
            "Epoch 114/300\n",
            "338/338 [==============================] - 0s 463us/step - loss: 1.9565 - mean_absolute_error: 0.6114\n",
            "Epoch 115/300\n",
            "338/338 [==============================] - 0s 438us/step - loss: 1.7692 - mean_absolute_error: 0.5925\n",
            "Epoch 116/300\n",
            "338/338 [==============================] - 0s 441us/step - loss: 1.9884 - mean_absolute_error: 0.6167\n",
            "Epoch 117/300\n",
            "338/338 [==============================] - 0s 453us/step - loss: 1.7855 - mean_absolute_error: 0.5982\n",
            "Epoch 118/300\n",
            "338/338 [==============================] - 0s 449us/step - loss: 1.8005 - mean_absolute_error: 0.6005\n",
            "Epoch 119/300\n",
            "338/338 [==============================] - 0s 433us/step - loss: 2.2262 - mean_absolute_error: 0.6720\n",
            "Epoch 120/300\n",
            "338/338 [==============================] - 0s 448us/step - loss: 1.6402 - mean_absolute_error: 0.5998\n",
            "Epoch 121/300\n",
            "338/338 [==============================] - 0s 448us/step - loss: 2.0116 - mean_absolute_error: 0.6094\n",
            "Epoch 122/300\n",
            "338/338 [==============================] - 0s 434us/step - loss: 1.7347 - mean_absolute_error: 0.6040\n",
            "Epoch 123/300\n",
            "338/338 [==============================] - 0s 458us/step - loss: 1.6615 - mean_absolute_error: 0.5827\n",
            "Epoch 124/300\n",
            "338/338 [==============================] - 0s 450us/step - loss: 2.0094 - mean_absolute_error: 0.6277\n",
            "Epoch 125/300\n",
            "338/338 [==============================] - 0s 436us/step - loss: 1.8207 - mean_absolute_error: 0.5966\n",
            "Epoch 126/300\n",
            "338/338 [==============================] - 0s 439us/step - loss: 1.8223 - mean_absolute_error: 0.5972\n",
            "Epoch 127/300\n",
            "338/338 [==============================] - 0s 442us/step - loss: 1.7730 - mean_absolute_error: 0.5737\n",
            "Epoch 128/300\n",
            "338/338 [==============================] - 0s 453us/step - loss: 1.5733 - mean_absolute_error: 0.5619\n",
            "Epoch 129/300\n",
            "338/338 [==============================] - 0s 449us/step - loss: 1.7890 - mean_absolute_error: 0.6145\n",
            "Epoch 130/300\n",
            "338/338 [==============================] - 0s 448us/step - loss: 1.6702 - mean_absolute_error: 0.5671\n",
            "Epoch 131/300\n",
            "338/338 [==============================] - 0s 459us/step - loss: 2.1124 - mean_absolute_error: 0.6395\n",
            "Epoch 132/300\n",
            "338/338 [==============================] - 0s 434us/step - loss: 2.0012 - mean_absolute_error: 0.6119\n",
            "Epoch 133/300\n",
            "338/338 [==============================] - 0s 430us/step - loss: 1.7046 - mean_absolute_error: 0.5917\n",
            "Epoch 134/300\n",
            "338/338 [==============================] - 0s 444us/step - loss: 1.9523 - mean_absolute_error: 0.6071\n",
            "Epoch 135/300\n",
            "338/338 [==============================] - 0s 453us/step - loss: 1.8608 - mean_absolute_error: 0.5925\n",
            "Epoch 136/300\n",
            "338/338 [==============================] - 0s 490us/step - loss: 1.9184 - mean_absolute_error: 0.5865\n",
            "Epoch 137/300\n",
            "338/338 [==============================] - 0s 486us/step - loss: 1.6754 - mean_absolute_error: 0.5860\n",
            "Epoch 138/300\n",
            "338/338 [==============================] - 0s 430us/step - loss: 1.9458 - mean_absolute_error: 0.6078\n",
            "Epoch 139/300\n",
            "338/338 [==============================] - 0s 462us/step - loss: 1.8231 - mean_absolute_error: 0.5792\n",
            "Epoch 140/300\n",
            "338/338 [==============================] - 0s 446us/step - loss: 1.8392 - mean_absolute_error: 0.6072\n",
            "Epoch 141/300\n",
            "338/338 [==============================] - 0s 432us/step - loss: 1.4877 - mean_absolute_error: 0.5604\n",
            "Epoch 142/300\n",
            "338/338 [==============================] - 0s 438us/step - loss: 1.8345 - mean_absolute_error: 0.6324\n",
            "Epoch 143/300\n",
            "338/338 [==============================] - 0s 442us/step - loss: 1.5512 - mean_absolute_error: 0.5659\n",
            "Epoch 144/300\n",
            "338/338 [==============================] - 0s 464us/step - loss: 1.8516 - mean_absolute_error: 0.6098\n",
            "Epoch 145/300\n",
            "338/338 [==============================] - 0s 440us/step - loss: 1.5610 - mean_absolute_error: 0.5587\n",
            "Epoch 146/300\n",
            "338/338 [==============================] - 0s 446us/step - loss: 1.9425 - mean_absolute_error: 0.6318\n",
            "Epoch 147/300\n",
            "338/338 [==============================] - 0s 456us/step - loss: 1.6907 - mean_absolute_error: 0.5966\n",
            "Epoch 148/300\n",
            "338/338 [==============================] - 0s 438us/step - loss: 1.8315 - mean_absolute_error: 0.5996\n",
            "Epoch 149/300\n",
            "338/338 [==============================] - 0s 435us/step - loss: 1.7704 - mean_absolute_error: 0.5946\n",
            "Epoch 150/300\n",
            "338/338 [==============================] - 0s 452us/step - loss: 1.5740 - mean_absolute_error: 0.5758\n",
            "Epoch 151/300\n",
            "338/338 [==============================] - 0s 447us/step - loss: 1.6052 - mean_absolute_error: 0.5575\n",
            "Epoch 152/300\n",
            "338/338 [==============================] - 0s 438us/step - loss: 1.7479 - mean_absolute_error: 0.5917\n",
            "Epoch 153/300\n",
            "338/338 [==============================] - 0s 452us/step - loss: 1.6595 - mean_absolute_error: 0.5848\n",
            "Epoch 154/300\n",
            "338/338 [==============================] - 0s 434us/step - loss: 1.8521 - mean_absolute_error: 0.6093\n",
            "Epoch 155/300\n",
            "338/338 [==============================] - 0s 458us/step - loss: 1.6606 - mean_absolute_error: 0.5716\n",
            "Epoch 156/300\n",
            "338/338 [==============================] - 0s 451us/step - loss: 1.8799 - mean_absolute_error: 0.6104\n",
            "Epoch 157/300\n",
            "338/338 [==============================] - 0s 441us/step - loss: 1.7216 - mean_absolute_error: 0.5959\n",
            "Epoch 158/300\n",
            "338/338 [==============================] - 0s 436us/step - loss: 1.5644 - mean_absolute_error: 0.5597\n",
            "Epoch 159/300\n",
            "338/338 [==============================] - 0s 441us/step - loss: 1.6930 - mean_absolute_error: 0.5700\n",
            "Epoch 160/300\n",
            "338/338 [==============================] - 0s 442us/step - loss: 1.7763 - mean_absolute_error: 0.5672\n",
            "Epoch 161/300\n",
            "338/338 [==============================] - 0s 449us/step - loss: 1.8159 - mean_absolute_error: 0.5793\n",
            "Epoch 162/300\n",
            "338/338 [==============================] - 0s 457us/step - loss: 1.7129 - mean_absolute_error: 0.5966\n",
            "Epoch 163/300\n",
            "338/338 [==============================] - 0s 454us/step - loss: 1.6576 - mean_absolute_error: 0.5818\n",
            "Epoch 164/300\n",
            "338/338 [==============================] - 0s 470us/step - loss: 1.3647 - mean_absolute_error: 0.5051\n",
            "Epoch 165/300\n",
            "338/338 [==============================] - 0s 431us/step - loss: 1.4805 - mean_absolute_error: 0.5650\n",
            "Epoch 166/300\n",
            "338/338 [==============================] - 0s 448us/step - loss: 1.7119 - mean_absolute_error: 0.5573\n",
            "Epoch 167/300\n",
            "338/338 [==============================] - 0s 443us/step - loss: 1.6138 - mean_absolute_error: 0.5728\n",
            "Epoch 168/300\n",
            "338/338 [==============================] - 0s 443us/step - loss: 1.5843 - mean_absolute_error: 0.5631\n",
            "Epoch 169/300\n",
            "338/338 [==============================] - 0s 460us/step - loss: 1.3940 - mean_absolute_error: 0.5422\n",
            "Epoch 170/300\n",
            "338/338 [==============================] - 0s 457us/step - loss: 1.5833 - mean_absolute_error: 0.5562\n",
            "Epoch 171/300\n",
            "338/338 [==============================] - 0s 434us/step - loss: 1.4270 - mean_absolute_error: 0.5402\n",
            "Epoch 172/300\n",
            "338/338 [==============================] - 0s 456us/step - loss: 1.2150 - mean_absolute_error: 0.5081\n",
            "Epoch 173/300\n",
            "338/338 [==============================] - 0s 442us/step - loss: 1.6333 - mean_absolute_error: 0.5777\n",
            "Epoch 174/300\n",
            "338/338 [==============================] - 0s 449us/step - loss: 1.6192 - mean_absolute_error: 0.5701\n",
            "Epoch 175/300\n",
            "338/338 [==============================] - 0s 445us/step - loss: 1.5853 - mean_absolute_error: 0.5678\n",
            "Epoch 176/300\n",
            "338/338 [==============================] - 0s 442us/step - loss: 1.5995 - mean_absolute_error: 0.5840\n",
            "Epoch 177/300\n",
            "338/338 [==============================] - 0s 448us/step - loss: 2.1160 - mean_absolute_error: 0.6005\n",
            "Epoch 178/300\n",
            "338/338 [==============================] - 0s 442us/step - loss: 1.6238 - mean_absolute_error: 0.5461\n",
            "Epoch 179/300\n",
            "338/338 [==============================] - 0s 456us/step - loss: 1.4732 - mean_absolute_error: 0.5289\n",
            "Epoch 180/300\n",
            "338/338 [==============================] - 0s 447us/step - loss: 1.4519 - mean_absolute_error: 0.5393\n",
            "Epoch 181/300\n",
            "338/338 [==============================] - 0s 457us/step - loss: 1.7149 - mean_absolute_error: 0.6026\n",
            "Epoch 182/300\n",
            "338/338 [==============================] - 0s 440us/step - loss: 1.6712 - mean_absolute_error: 0.5681\n",
            "Epoch 183/300\n",
            "338/338 [==============================] - 0s 440us/step - loss: 1.7059 - mean_absolute_error: 0.5603\n",
            "Epoch 184/300\n",
            "338/338 [==============================] - 0s 470us/step - loss: 1.5985 - mean_absolute_error: 0.5410\n",
            "Epoch 185/300\n",
            "338/338 [==============================] - 0s 434us/step - loss: 1.4751 - mean_absolute_error: 0.5465\n",
            "Epoch 186/300\n",
            "338/338 [==============================] - 0s 459us/step - loss: 1.4330 - mean_absolute_error: 0.5390\n",
            "Epoch 187/300\n",
            "338/338 [==============================] - 0s 437us/step - loss: 1.5485 - mean_absolute_error: 0.5663\n",
            "Epoch 188/300\n",
            "338/338 [==============================] - 0s 448us/step - loss: 1.5888 - mean_absolute_error: 0.5655\n",
            "Epoch 189/300\n",
            "338/338 [==============================] - 0s 448us/step - loss: 1.6279 - mean_absolute_error: 0.5576\n",
            "Epoch 190/300\n",
            "338/338 [==============================] - 0s 445us/step - loss: 1.7222 - mean_absolute_error: 0.5742\n",
            "Epoch 191/300\n",
            "338/338 [==============================] - 0s 466us/step - loss: 1.6753 - mean_absolute_error: 0.5529\n",
            "Epoch 192/300\n",
            "338/338 [==============================] - 0s 437us/step - loss: 1.3654 - mean_absolute_error: 0.5174\n",
            "Epoch 193/300\n",
            "338/338 [==============================] - 0s 446us/step - loss: 1.4312 - mean_absolute_error: 0.5316\n",
            "Epoch 194/300\n",
            "338/338 [==============================] - 0s 452us/step - loss: 1.5139 - mean_absolute_error: 0.5502\n",
            "Epoch 195/300\n",
            "338/338 [==============================] - 0s 445us/step - loss: 1.6160 - mean_absolute_error: 0.5479\n",
            "Epoch 196/300\n",
            "338/338 [==============================] - 0s 447us/step - loss: 1.6222 - mean_absolute_error: 0.5708\n",
            "Epoch 197/300\n",
            "338/338 [==============================] - 0s 450us/step - loss: 1.2618 - mean_absolute_error: 0.5094\n",
            "Epoch 198/300\n",
            "338/338 [==============================] - 0s 443us/step - loss: 1.6757 - mean_absolute_error: 0.5839\n",
            "Epoch 199/300\n",
            "338/338 [==============================] - 0s 482us/step - loss: 1.7159 - mean_absolute_error: 0.5514\n",
            "Epoch 200/300\n",
            "338/338 [==============================] - 0s 425us/step - loss: 1.4597 - mean_absolute_error: 0.5419\n",
            "Epoch 201/300\n",
            "338/338 [==============================] - 0s 433us/step - loss: 1.4790 - mean_absolute_error: 0.5376\n",
            "Epoch 202/300\n",
            "338/338 [==============================] - 0s 441us/step - loss: 1.6200 - mean_absolute_error: 0.5784\n",
            "Epoch 203/300\n",
            "338/338 [==============================] - 0s 440us/step - loss: 1.6606 - mean_absolute_error: 0.5539\n",
            "Epoch 204/300\n",
            "338/338 [==============================] - 0s 444us/step - loss: 1.4537 - mean_absolute_error: 0.5560\n",
            "Epoch 205/300\n",
            "338/338 [==============================] - 0s 442us/step - loss: 1.4986 - mean_absolute_error: 0.5310\n",
            "Epoch 206/300\n",
            "338/338 [==============================] - 0s 466us/step - loss: 1.3251 - mean_absolute_error: 0.5189\n",
            "Epoch 207/300\n",
            "338/338 [==============================] - 0s 556us/step - loss: 1.5951 - mean_absolute_error: 0.5688\n",
            "Epoch 208/300\n",
            "338/338 [==============================] - 0s 430us/step - loss: 1.4159 - mean_absolute_error: 0.5423\n",
            "Epoch 209/300\n",
            "338/338 [==============================] - 0s 474us/step - loss: 1.5100 - mean_absolute_error: 0.5359\n",
            "Epoch 210/300\n",
            "338/338 [==============================] - 0s 438us/step - loss: 1.3507 - mean_absolute_error: 0.5243\n",
            "Epoch 211/300\n",
            "338/338 [==============================] - 0s 447us/step - loss: 1.3854 - mean_absolute_error: 0.5385\n",
            "Epoch 212/300\n",
            "338/338 [==============================] - 0s 461us/step - loss: 1.4093 - mean_absolute_error: 0.5324\n",
            "Epoch 213/300\n",
            "338/338 [==============================] - 0s 430us/step - loss: 1.5433 - mean_absolute_error: 0.5620\n",
            "Epoch 214/300\n",
            "338/338 [==============================] - 0s 472us/step - loss: 1.6190 - mean_absolute_error: 0.5673\n",
            "Epoch 215/300\n",
            "338/338 [==============================] - 0s 437us/step - loss: 1.4061 - mean_absolute_error: 0.5342\n",
            "Epoch 216/300\n",
            "338/338 [==============================] - 0s 434us/step - loss: 1.4975 - mean_absolute_error: 0.5323\n",
            "Epoch 217/300\n",
            "338/338 [==============================] - 0s 453us/step - loss: 1.2775 - mean_absolute_error: 0.4948\n",
            "Epoch 218/300\n",
            "338/338 [==============================] - 0s 449us/step - loss: 1.5202 - mean_absolute_error: 0.5194\n",
            "Epoch 219/300\n",
            "338/338 [==============================] - 0s 439us/step - loss: 1.2075 - mean_absolute_error: 0.5019\n",
            "Epoch 220/300\n",
            "338/338 [==============================] - 0s 460us/step - loss: 1.6116 - mean_absolute_error: 0.5618\n",
            "Epoch 221/300\n",
            "338/338 [==============================] - 0s 460us/step - loss: 1.3759 - mean_absolute_error: 0.5340\n",
            "Epoch 222/300\n",
            "338/338 [==============================] - 0s 452us/step - loss: 1.5217 - mean_absolute_error: 0.5478\n",
            "Epoch 223/300\n",
            "338/338 [==============================] - 0s 428us/step - loss: 1.4520 - mean_absolute_error: 0.5493\n",
            "Epoch 224/300\n",
            "338/338 [==============================] - 0s 440us/step - loss: 1.6710 - mean_absolute_error: 0.5736\n",
            "Epoch 225/300\n",
            "338/338 [==============================] - 0s 442us/step - loss: 1.3559 - mean_absolute_error: 0.5350\n",
            "Epoch 226/300\n",
            "338/338 [==============================] - 0s 448us/step - loss: 1.5833 - mean_absolute_error: 0.5396\n",
            "Epoch 227/300\n",
            "338/338 [==============================] - 0s 450us/step - loss: 1.5168 - mean_absolute_error: 0.5516\n",
            "Epoch 228/300\n",
            "338/338 [==============================] - 0s 454us/step - loss: 1.7430 - mean_absolute_error: 0.5690\n",
            "Epoch 229/300\n",
            "338/338 [==============================] - 0s 450us/step - loss: 1.5828 - mean_absolute_error: 0.5483\n",
            "Epoch 230/300\n",
            "338/338 [==============================] - 0s 438us/step - loss: 1.4467 - mean_absolute_error: 0.5341\n",
            "Epoch 231/300\n",
            "338/338 [==============================] - 0s 442us/step - loss: 1.8097 - mean_absolute_error: 0.5922\n",
            "Epoch 232/300\n",
            "338/338 [==============================] - 0s 444us/step - loss: 1.5050 - mean_absolute_error: 0.5294\n",
            "Epoch 233/300\n",
            "338/338 [==============================] - 0s 453us/step - loss: 1.5622 - mean_absolute_error: 0.5577\n",
            "Epoch 234/300\n",
            "338/338 [==============================] - 0s 453us/step - loss: 1.5311 - mean_absolute_error: 0.5444\n",
            "Epoch 235/300\n",
            "338/338 [==============================] - 0s 428us/step - loss: 1.4329 - mean_absolute_error: 0.5392\n",
            "Epoch 236/300\n",
            "338/338 [==============================] - 0s 455us/step - loss: 1.3550 - mean_absolute_error: 0.5269\n",
            "Epoch 237/300\n",
            "338/338 [==============================] - 0s 457us/step - loss: 1.7687 - mean_absolute_error: 0.5668\n",
            "Epoch 238/300\n",
            "338/338 [==============================] - 0s 437us/step - loss: 1.4418 - mean_absolute_error: 0.5349\n",
            "Epoch 239/300\n",
            "338/338 [==============================] - 0s 453us/step - loss: 1.3262 - mean_absolute_error: 0.5167\n",
            "Epoch 240/300\n",
            "338/338 [==============================] - 0s 447us/step - loss: 1.4113 - mean_absolute_error: 0.5285\n",
            "Epoch 241/300\n",
            "338/338 [==============================] - 0s 442us/step - loss: 1.5309 - mean_absolute_error: 0.5489\n",
            "Epoch 242/300\n",
            "338/338 [==============================] - 0s 450us/step - loss: 1.4223 - mean_absolute_error: 0.5415\n",
            "Epoch 243/300\n",
            "338/338 [==============================] - 0s 456us/step - loss: 1.4560 - mean_absolute_error: 0.5291\n",
            "Epoch 244/300\n",
            "338/338 [==============================] - 0s 439us/step - loss: 1.4444 - mean_absolute_error: 0.5439\n",
            "Epoch 245/300\n",
            "338/338 [==============================] - 0s 444us/step - loss: 1.5006 - mean_absolute_error: 0.5284\n",
            "Epoch 246/300\n",
            "338/338 [==============================] - 0s 456us/step - loss: 1.4452 - mean_absolute_error: 0.5276\n",
            "Epoch 247/300\n",
            "338/338 [==============================] - 0s 450us/step - loss: 1.3768 - mean_absolute_error: 0.5291\n",
            "Epoch 248/300\n",
            "338/338 [==============================] - 0s 443us/step - loss: 1.4996 - mean_absolute_error: 0.5465\n",
            "Epoch 249/300\n",
            "338/338 [==============================] - 0s 431us/step - loss: 1.6061 - mean_absolute_error: 0.5444\n",
            "Epoch 250/300\n",
            "338/338 [==============================] - 0s 486us/step - loss: 1.2634 - mean_absolute_error: 0.5105\n",
            "Epoch 251/300\n",
            "338/338 [==============================] - 0s 434us/step - loss: 1.3936 - mean_absolute_error: 0.5097\n",
            "Epoch 252/300\n",
            "338/338 [==============================] - 0s 435us/step - loss: 1.4232 - mean_absolute_error: 0.5377\n",
            "Epoch 253/300\n",
            "338/338 [==============================] - 0s 446us/step - loss: 1.3550 - mean_absolute_error: 0.5071\n",
            "Epoch 254/300\n",
            "338/338 [==============================] - 0s 455us/step - loss: 1.3043 - mean_absolute_error: 0.4802\n",
            "Epoch 255/300\n",
            "338/338 [==============================] - 0s 433us/step - loss: 1.4947 - mean_absolute_error: 0.5293\n",
            "Epoch 256/300\n",
            "338/338 [==============================] - 0s 452us/step - loss: 1.3158 - mean_absolute_error: 0.5181\n",
            "Epoch 257/300\n",
            "338/338 [==============================] - 0s 453us/step - loss: 1.5323 - mean_absolute_error: 0.5307\n",
            "Epoch 258/300\n",
            "338/338 [==============================] - 0s 428us/step - loss: 1.4678 - mean_absolute_error: 0.5333\n",
            "Epoch 259/300\n",
            "338/338 [==============================] - 0s 444us/step - loss: 1.6496 - mean_absolute_error: 0.5686\n",
            "Epoch 260/300\n",
            "338/338 [==============================] - 0s 446us/step - loss: 1.4633 - mean_absolute_error: 0.5324\n",
            "Epoch 261/300\n",
            "338/338 [==============================] - 0s 446us/step - loss: 1.3962 - mean_absolute_error: 0.5110\n",
            "Epoch 262/300\n",
            "338/338 [==============================] - 0s 438us/step - loss: 1.2648 - mean_absolute_error: 0.5093\n",
            "Epoch 263/300\n",
            "338/338 [==============================] - 0s 449us/step - loss: 1.2885 - mean_absolute_error: 0.5052\n",
            "Epoch 264/300\n",
            "338/338 [==============================] - 0s 469us/step - loss: 1.3092 - mean_absolute_error: 0.5193\n",
            "Epoch 265/300\n",
            "338/338 [==============================] - 0s 440us/step - loss: 1.2068 - mean_absolute_error: 0.4846\n",
            "Epoch 266/300\n",
            "338/338 [==============================] - 0s 433us/step - loss: 1.3875 - mean_absolute_error: 0.5188\n",
            "Epoch 267/300\n",
            "338/338 [==============================] - 0s 451us/step - loss: 1.3580 - mean_absolute_error: 0.5046\n",
            "Epoch 268/300\n",
            "338/338 [==============================] - 0s 449us/step - loss: 1.4165 - mean_absolute_error: 0.5168\n",
            "Epoch 269/300\n",
            "338/338 [==============================] - 0s 452us/step - loss: 1.3728 - mean_absolute_error: 0.5030\n",
            "Epoch 270/300\n",
            "338/338 [==============================] - 0s 452us/step - loss: 1.1885 - mean_absolute_error: 0.4818\n",
            "Epoch 271/300\n",
            "338/338 [==============================] - 0s 432us/step - loss: 1.1428 - mean_absolute_error: 0.4689\n",
            "Epoch 272/300\n",
            "338/338 [==============================] - 0s 442us/step - loss: 1.2782 - mean_absolute_error: 0.4976\n",
            "Epoch 273/300\n",
            "338/338 [==============================] - 0s 450us/step - loss: 1.6181 - mean_absolute_error: 0.5496\n",
            "Epoch 274/300\n",
            "338/338 [==============================] - 0s 453us/step - loss: 1.5003 - mean_absolute_error: 0.5620\n",
            "Epoch 275/300\n",
            "338/338 [==============================] - 0s 440us/step - loss: 1.3542 - mean_absolute_error: 0.5072\n",
            "Epoch 276/300\n",
            "338/338 [==============================] - 0s 450us/step - loss: 1.5336 - mean_absolute_error: 0.5411\n",
            "Epoch 277/300\n",
            "338/338 [==============================] - 0s 452us/step - loss: 1.3549 - mean_absolute_error: 0.5279\n",
            "Epoch 278/300\n",
            "338/338 [==============================] - 0s 453us/step - loss: 1.4560 - mean_absolute_error: 0.5329\n",
            "Epoch 279/300\n",
            "338/338 [==============================] - 0s 454us/step - loss: 1.1890 - mean_absolute_error: 0.4945\n",
            "Epoch 280/300\n",
            "338/338 [==============================] - 0s 450us/step - loss: 1.2693 - mean_absolute_error: 0.5053\n",
            "Epoch 281/300\n",
            "338/338 [==============================] - 0s 513us/step - loss: 1.4002 - mean_absolute_error: 0.5120\n",
            "Epoch 282/300\n",
            "338/338 [==============================] - 0s 430us/step - loss: 1.2884 - mean_absolute_error: 0.5136\n",
            "Epoch 283/300\n",
            "338/338 [==============================] - 0s 459us/step - loss: 1.5026 - mean_absolute_error: 0.5097\n",
            "Epoch 284/300\n",
            "338/338 [==============================] - 0s 457us/step - loss: 1.4111 - mean_absolute_error: 0.5225\n",
            "Epoch 285/300\n",
            "338/338 [==============================] - 0s 441us/step - loss: 1.2826 - mean_absolute_error: 0.5209\n",
            "Epoch 286/300\n",
            "338/338 [==============================] - 0s 460us/step - loss: 1.6421 - mean_absolute_error: 0.5410\n",
            "Epoch 287/300\n",
            "338/338 [==============================] - 0s 441us/step - loss: 1.3281 - mean_absolute_error: 0.5082\n",
            "Epoch 288/300\n",
            "338/338 [==============================] - 0s 449us/step - loss: 1.5054 - mean_absolute_error: 0.5345\n",
            "Epoch 289/300\n",
            "338/338 [==============================] - 0s 443us/step - loss: 1.2426 - mean_absolute_error: 0.4886\n",
            "Epoch 290/300\n",
            "338/338 [==============================] - 0s 450us/step - loss: 1.1958 - mean_absolute_error: 0.4941\n",
            "Epoch 291/300\n",
            "338/338 [==============================] - 0s 444us/step - loss: 1.1597 - mean_absolute_error: 0.4637\n",
            "Epoch 292/300\n",
            "338/338 [==============================] - 0s 438us/step - loss: 1.1977 - mean_absolute_error: 0.5002\n",
            "Epoch 293/300\n",
            "338/338 [==============================] - 0s 455us/step - loss: 1.3370 - mean_absolute_error: 0.4928\n",
            "Epoch 294/300\n",
            "338/338 [==============================] - 0s 451us/step - loss: 1.1582 - mean_absolute_error: 0.4811\n",
            "Epoch 295/300\n",
            "338/338 [==============================] - 0s 444us/step - loss: 1.4123 - mean_absolute_error: 0.4937\n",
            "Epoch 296/300\n",
            "338/338 [==============================] - 0s 457us/step - loss: 1.3167 - mean_absolute_error: 0.4852\n",
            "Epoch 297/300\n",
            "338/338 [==============================] - 0s 457us/step - loss: 1.3989 - mean_absolute_error: 0.5239\n",
            "Epoch 298/300\n",
            "338/338 [==============================] - 0s 450us/step - loss: 1.1583 - mean_absolute_error: 0.4782\n",
            "Epoch 299/300\n",
            "338/338 [==============================] - 0s 444us/step - loss: 1.1979 - mean_absolute_error: 0.4474\n",
            "Epoch 300/300\n",
            "338/338 [==============================] - 0s 513us/step - loss: 1.2378 - mean_absolute_error: 0.4904\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_7Sqppj7m8R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#row wise'\n",
        "\n",
        "\n",
        "# print(X_test_c.shape)\n",
        "\n",
        "X_rob_test_c = scaler_rob_x.transform(X_test_c)\n",
        "\n",
        "# print(X_rob_test_c.shape)\n",
        "\n",
        "Y_rob_test_c = scaler_rob_y.transform(y_test_c)\n",
        "\n",
        "\n",
        "X_new_test_c = factor_fit.transform(X_rob_test_c[:,0:10000])\n",
        "# print(X_new_test.shape)\n",
        "\n",
        "\n",
        "X_new_test_c = np.concatenate((X_new_test_c,X_rob_test_c[:,10000:10002]),axis=1)\n",
        "# print(X_new_test_c.shape)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWeuyQL1-Lwx",
        "colab_type": "code",
        "outputId": "e60478d5-8162-4b21-c01a-a40b75f7c400",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
        "import math\n",
        "from sklearn.metrics import max_error\n",
        "\n",
        "pred_c = estimator1.predict((X_new_test_c))\n",
        "print(pred_c.shape)\n",
        "\n",
        "mse = (mean_squared_error(Y_rob_test_c,pred_c))\n",
        "\n",
        "print(mse)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(85, 2)\n",
            "2.5646421105021915\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWOYg5cB_kNl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(len(y_test_c)):\n",
        "  \n",
        "#   print(y_test_c[i],\"ytest[i]\")\n",
        "#   print(X_test_c[i].shape)\n",
        "  X_c = (scaler_rob_x.transform(X_test_c[i].reshape(1, -1)))\n",
        "\n",
        "  I = factor_fit.transform(X_c[:,0:10000])\n",
        "  I = np.concatenate((I,X_c[:,10000:10002]),axis=1)\n",
        "#   print(I.shape,\"I shape\")\n",
        "\n",
        "  pred_c = estimator1.predict(I)\n",
        "#   print(pred_c.shape,\"pred_c.shape\")\n",
        "  \n",
        " \n",
        "\n",
        "  \n",
        "  final = scaler_rob_y.inverse_transform(pred_c.reshape(1, -1))\n",
        "                                          \n",
        "  final[0][0]= np.round(final[0][0])\n",
        "                                          \n",
        "#   print(final[0],\"final\")\n",
        "\n",
        "  h = abs(final[0]-y_test_c[i])\n",
        "#   print(h,\"h\")\n",
        "  o=np.divide(h,y_test_c[i])\n",
        "#   print(o*100,\"percentage\") \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLLEstlI_apj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLoaA8xH-sH1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mteG-TDEKwRK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for i in range(len(y_test)):\n",
        "#   print(y_test[i],\"ytest[i]\")\n",
        "#   X=X_test[i]\n",
        "# #   print(X.reshape(1, -1).shape)\n",
        "#   pred = estimator.predict(pca_fit.transform(X.reshape(1, -1)))\n",
        "#   print(pred)\n",
        "#   print(\"-------\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77N2HEb_WMQu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from sklearn.metrics import r2_score\n",
        "  \n",
        "# r2_score(Y_new_test[:,:], pred[:,:], multioutput='variance_weighted') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ru0aw2zJZFqG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "# for i in range(len(y_test)):\n",
        "  \n",
        "#   print(y_test[i],\"ytest[i]\")\n",
        "  \n",
        "  \n",
        "# #   print(X_test[i])\n",
        "# #   X_test[i]= X_test[i].transpose()\n",
        "# #   print(X_test[i].reshape(-1, 1).shape,\"X_test fitted \")\n",
        "# #   scaler_rob_x = RobustScaler().fit((X_test[i].reshape(-1, 1)))\n",
        "# #   print(X_test[i].reshape(-1, 1))                            \n",
        "# #   X = (scaler_stan_x.transform(X_test[i].reshape(-1, 1)))\n",
        "  \n",
        "# #   pred = estimator.predict(X)\n",
        "# #   print(pred.shape,\"pred.shape\")\n",
        "#   print()\n",
        "# #   y_test_ti = y_test[i].transpose()\n",
        "# #   print(y_test_ti.reshape(-1, 1).shape,\"ytest tranposed shape\")\n",
        "# #   scaler_rob_y = RobustScaler().fit(y_test_ti.reshape(-1, 1))\n",
        "#   final = scaler_stan_y.inverse_transform(pred[i].reshape(-1, 1))\n",
        "                                          \n",
        "# #   print(final_t.shape)\n",
        "# #   final = final_t.transpose()\n",
        "                                          \n",
        "#   print(final)\n",
        "# #   Y_new_test_t = scaler_rob_y.transform(y_test_ti)\n",
        "# #   Y_new_test = Y_new_test_t.transpose()\n",
        "\n",
        "# #   X= X.tranpose()\n",
        "# #   # print(scaler_stan_y.transform(y_test[50].reshape(1, -1)))\n",
        "# #   # print(scaler_stan_y.inverse_transform(Y_new_test[50]))\n",
        "# #   pred = (estimator.predict(X))\n",
        "# # #   print(scaler_stan_y.inverse_transform(estimator.predict(X)))\n",
        "# #   mul = math.sqrt(np.sum(y_test[i]**2))\n",
        "# # #   print(\"L\")\n",
        "# # #   print(y_test[58])\n",
        "# # #   print(Y_new_test[58]*mul)\n",
        "# # #   print(pred[58]*mul)\n",
        "# #   pred = pred.tranform()\n",
        "# #   l = scaler_rob_y.inverse_transform(pred)\n",
        "# #   l=l.transpose()\n",
        "# # #   l = (estimator.predict(X))*mul\n",
        "# #   print(l,\"l\")\n",
        "# #   h = abs(l-y_test[i])\n",
        "# # #   print(h,\"h\")\n",
        "# #   o=np.divide(h,y_test[i])\n",
        "# #   print(o*100,\"percentage\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2Aa35__Ladk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hF7_yiFZoEp6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(history.history.keys())\n",
        "# # \"Loss\"\n",
        "# plt.plot(history.history['loss'])\n",
        "# plt.plot(history.history['val_loss'])\n",
        "# plt.title('model loss')\n",
        "# plt.ylabel('loss')\n",
        "\n",
        "# plt.xlabel('epoch')\n",
        "# plt.legend(['train', 'validation'], loc='upper left')\n",
        "# plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVUAjAbtrf2q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # \"mean_squared_error\"\n",
        "# plt.plot(history.history['mean_squared_error'])\n",
        "# plt.plot(history.history['val_mean_squared_error'])\n",
        "# plt.title('model mean_squared_error')\n",
        "# plt.ylabel('mean_squared_error')\n",
        "\n",
        "# plt.xlabel('epoch')\n",
        "# plt.legend(['train', 'validation'], loc='upper left')\n",
        "# plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THDe2uxhr04e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#  # \"acc\"\n",
        "# plt.plot(history.history['acc'])\n",
        "# plt.plot(history.history['val_acc'])\n",
        "\n",
        "# plt.title('model acc')\n",
        "# plt.ylabel('acc')\n",
        "\n",
        "# plt.xlabel('epoch')\n",
        "# plt.legend(['train', 'validation'], loc='upper left')\n",
        "\n",
        "# plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBOC8pfUsB_t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sJT7BL1HgBV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
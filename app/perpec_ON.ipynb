{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "lXfPT7BuejLb",
    "outputId": "c6808d39-90c9-4ac3-a567-15d716059419"
   },
   "outputs": [],
   "source": [
    "# # Run this cell to mount your Google Drive.\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "819EGBI8fLUl",
    "outputId": "93d6fddc-7353-4a53-d34e-1427242fa67d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "# from keras.backend import manual_variable_initialization \n",
    "# # manual_variable_initialization(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N1bkqWDgXIbi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 246
    },
    "colab_type": "code",
    "id": "RgWz2tXdfNax",
    "outputId": "50345be1-3694-4638-a873-88697a7d0bc7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s.no</th>\n",
       "      <th>id</th>\n",
       "      <th>dir</th>\n",
       "      <th>path</th>\n",
       "      <th>date</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>x3</th>\n",
       "      <th>...</th>\n",
       "      <th>x9996</th>\n",
       "      <th>y9996</th>\n",
       "      <th>x9997</th>\n",
       "      <th>y9997</th>\n",
       "      <th>x9998</th>\n",
       "      <th>y9998</th>\n",
       "      <th>x9999</th>\n",
       "      <th>y9999</th>\n",
       "      <th>x10000</th>\n",
       "      <th>y10000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ON_1_20181031_173504_104</td>\n",
       "      <td>104</td>\n",
       "      <td>C:\\Hilink\\BB4A\\RESULT\\BBM2\\BBM2\\NOMINAL\\MANUAL...</td>\n",
       "      <td>31/10/2018</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>OFF_4_20181031_173921_104</td>\n",
       "      <td>104</td>\n",
       "      <td>C:\\Hilink\\BB4A\\RESULT\\BBM2\\BBM2\\NOMINAL\\MANUAL...</td>\n",
       "      <td>31/10/2018</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>OFF_2_20181031_173628_104</td>\n",
       "      <td>104</td>\n",
       "      <td>C:\\Hilink\\BB4A\\RESULT\\BBM2\\BBM2\\NOMINAL\\MANUAL...</td>\n",
       "      <td>31/10/2018</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>ON_3_20181031_173800_104</td>\n",
       "      <td>104</td>\n",
       "      <td>C:\\Hilink\\BB4A\\RESULT\\BBM2\\BBM2\\NOMINAL\\MANUAL...</td>\n",
       "      <td>31/10/2018</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>OFF_4_20181102_085018_103</td>\n",
       "      <td>103</td>\n",
       "      <td>C:\\Hilink\\BB4A\\RESULT\\BBM2\\BBM2\\NOMINAL\\MANUAL...</td>\n",
       "      <td>02/11/2018</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>25.2</td>\n",
       "      <td>0.05</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 20005 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  s.no                         id  dir  \\\n",
       "0    1   ON_1_20181031_173504_104  104   \n",
       "1    2  OFF_4_20181031_173921_104  104   \n",
       "2    3  OFF_2_20181031_173628_104  104   \n",
       "3    4   ON_3_20181031_173800_104  104   \n",
       "4    5  OFF_4_20181102_085018_103  103   \n",
       "\n",
       "                                                path        date   x1    y1  \\\n",
       "0  C:\\Hilink\\BB4A\\RESULT\\BBM2\\BBM2\\NOMINAL\\MANUAL...  31/10/2018  0.2  0.03   \n",
       "1  C:\\Hilink\\BB4A\\RESULT\\BBM2\\BBM2\\NOMINAL\\MANUAL...  31/10/2018  0.4  0.12   \n",
       "2  C:\\Hilink\\BB4A\\RESULT\\BBM2\\BBM2\\NOMINAL\\MANUAL...  31/10/2018  0.2  0.13   \n",
       "3  C:\\Hilink\\BB4A\\RESULT\\BBM2\\BBM2\\NOMINAL\\MANUAL...  31/10/2018  0.2  0.03   \n",
       "4  C:\\Hilink\\BB4A\\RESULT\\BBM2\\BBM2\\NOMINAL\\MANUAL...  02/11/2018  0.2  0.15   \n",
       "\n",
       "    x2    y2   x3  ... x9996 y9996 x9997 y9997 x9998 y9998 x9999 y9999 x10000  \\\n",
       "0  0.2  0.03  0.2  ...   0.2  0.14   0.2  0.14   0.2  0.14   0.2  0.14    0.2   \n",
       "1  0.2  0.12  0.2  ...  25.0  0.03  25.0  0.03  25.0  0.03  25.0  0.03   25.0   \n",
       "2  0.0  0.12  0.0  ...  25.0  0.03  25.0  0.03  25.0  0.02  25.0  0.02   25.0   \n",
       "3  0.4  0.02  0.4  ...   0.2  0.14   0.0  0.14   0.2  0.14   0.2  0.14    0.2   \n",
       "4  0.2  0.16  0.2  ...  25.0  0.05  25.0  0.06  25.0  0.05  25.2  0.05   25.0   \n",
       "\n",
       "  y10000  \n",
       "0   0.14  \n",
       "1   0.03  \n",
       "2   0.03  \n",
       "3   0.14  \n",
       "4   0.05  \n",
       "\n",
       "[5 rows x 20005 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_p = pd.read_csv(\"points.csv\",dtype=object,error_bad_lines=False) \n",
    "data_p.head()\n",
    "data_p[\"id\"] = data_p[\"id\"].map(str) +\"_\"+ data_p[\"dir\"]\n",
    "data_p.head()\n",
    "# data_p.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 234
    },
    "colab_type": "code",
    "id": "zRQG6QqkfPaM",
    "outputId": "7e2cdf06-3933-4496-c78e-813e4afed97b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s.no</th>\n",
       "      <th>id</th>\n",
       "      <th>dir</th>\n",
       "      <th>_file_</th>\n",
       "      <th>power_state_value</th>\n",
       "      <th>current_rise/fall_time_value (mS)</th>\n",
       "      <th>current_stabilised_value (mA)</th>\n",
       "      <th>current_max/min_value (mA)</th>\n",
       "      <th>power_state_spec</th>\n",
       "      <th>current_rise/fall_time_spec (mS)</th>\n",
       "      <th>current_stabilised_spec (mA)</th>\n",
       "      <th>current_max/min_spec (mA)</th>\n",
       "      <th>power_state_N/NC</th>\n",
       "      <th>current_rise/fall_time_C/NC</th>\n",
       "      <th>current_stabilised_C/NC</th>\n",
       "      <th>current_max/min_C/NC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ON_1_20181031_173504_104</td>\n",
       "      <td>104</td>\n",
       "      <td>HEGSE_72.HTM</td>\n",
       "      <td>1</td>\n",
       "      <td>89.990000000000</td>\n",
       "      <td>150.000000000000</td>\n",
       "      <td>405.992200000000</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>510.204</td>\n",
       "      <td>800</td>\n",
       "      <td>C</td>\n",
       "      <td>NC</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>OFF_2_20181031_173628_104</td>\n",
       "      <td>104</td>\n",
       "      <td>HEGSE_72.HTM</td>\n",
       "      <td>0</td>\n",
       "      <td>7.992000000000</td>\n",
       "      <td>30.000000000000</td>\n",
       "      <td>-56.000000000000</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>510.204</td>\n",
       "      <td>-100</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>ON_3_20181031_173800_104</td>\n",
       "      <td>104</td>\n",
       "      <td>HEGSE_72.HTM</td>\n",
       "      <td>1</td>\n",
       "      <td>89.950000000000</td>\n",
       "      <td>140.000000000000</td>\n",
       "      <td>405.992200000000</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>495.049</td>\n",
       "      <td>800</td>\n",
       "      <td>C</td>\n",
       "      <td>NC</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>OFF_4_20181031_173921_104</td>\n",
       "      <td>104</td>\n",
       "      <td>HEGSE_72.HTM</td>\n",
       "      <td>0</td>\n",
       "      <td>7.997000000000</td>\n",
       "      <td>30.000000000000</td>\n",
       "      <td>-58.000000000000</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>495.049</td>\n",
       "      <td>-100</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>ON_1_20181102_084600_103</td>\n",
       "      <td>103</td>\n",
       "      <td>HEGSE_72.HTM</td>\n",
       "      <td>1</td>\n",
       "      <td>56.650000000000</td>\n",
       "      <td>169.800000000000</td>\n",
       "      <td>405.992200000000</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>510.204</td>\n",
       "      <td>800</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  s.no                         id  dir         _file_  power_state_value  \\\n",
       "0    1   ON_1_20181031_173504_104  104   HEGSE_72.HTM                  1   \n",
       "1    2  OFF_2_20181031_173628_104  104   HEGSE_72.HTM                  0   \n",
       "2    3   ON_3_20181031_173800_104  104   HEGSE_72.HTM                  1   \n",
       "3    4  OFF_4_20181031_173921_104  104   HEGSE_72.HTM                  0   \n",
       "4    5   ON_1_20181102_084600_103  103   HEGSE_72.HTM                  1   \n",
       "\n",
       "  current_rise/fall_time_value (mS) current_stabilised_value (mA)  \\\n",
       "0                   89.990000000000              150.000000000000   \n",
       "1                    7.992000000000               30.000000000000   \n",
       "2                   89.950000000000              140.000000000000   \n",
       "3                    7.997000000000               30.000000000000   \n",
       "4                   56.650000000000              169.800000000000   \n",
       "\n",
       "  current_max/min_value (mA)  power_state_spec  \\\n",
       "0           405.992200000000                 1   \n",
       "1           -56.000000000000                 0   \n",
       "2           405.992200000000                 1   \n",
       "3           -58.000000000000                 0   \n",
       "4           405.992200000000                 1   \n",
       "\n",
       "  current_rise/fall_time_spec (mS) current_stabilised_spec (mA)  \\\n",
       "0                               60                      510.204   \n",
       "1                               10                      510.204   \n",
       "2                               60                      495.049   \n",
       "3                               10                      495.049   \n",
       "4                               60                      510.204   \n",
       "\n",
       "  current_max/min_spec (mA) power_state_N/NC current_rise/fall_time_C/NC  \\\n",
       "0                       800                C                          NC   \n",
       "1                      -100                C                           C   \n",
       "2                       800                C                          NC   \n",
       "3                      -100                C                           C   \n",
       "4                       800                C                           C   \n",
       "\n",
       "  current_stabilised_C/NC current_max/min_C/NC  \n",
       "0                       C                    C  \n",
       "1                       C                    C  \n",
       "2                       C                    C  \n",
       "3                       C                    C  \n",
       "4                       C                    C  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data_v = pd.read_csv(\"values.csv\",dtype=object,error_bad_lines=False )\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "data_v['power_state_spec'] = le.fit_transform(data_v['power_state_spec'].astype('str'))\n",
    "\n",
    "data_v['power_state_value'] = le.fit_transform(data_v['power_state_value'].astype('str'))\n",
    "data_v[\"id\"] = data_v[\"id\"].map(str) +\"_\"+data_v[\"dir\"]\n",
    "data_v.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SS5hHAvgfRzw"
   },
   "outputs": [],
   "source": [
    "arr_v = data_v.values\n",
    "arr_p = data_p.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TSE1FojVfUlN"
   },
   "outputs": [],
   "source": [
    "arr_v = arr_v[0:]\n",
    "# print(arr_v)\n",
    "arr_p = arr_p[0:]\n",
    "# print(arr_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "pZMozxZNfdAU",
    "outputId": "1371ad9a-922e-48c1-833a-a5cfa5c01b81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426 ON\n",
      "398 OFF\n"
     ]
    }
   ],
   "source": [
    "ON_list =[]\n",
    "OFF_list = []\n",
    "for i in range(len(arr_p)):\n",
    "    s = arr_p[i][1]\n",
    "    s = str(s)\n",
    "    \n",
    "#     print(type(st))\n",
    "    if s.find(\"N\") == -1:\n",
    "        OFF_list.append(arr_p[i])\n",
    "    \n",
    "    else:\n",
    "        ON_list.append(arr_p[i])\n",
    "# calculating for ON\n",
    "print(len(ON_list),\"ON\")\n",
    "print(len(OFF_list),\"OFF\")\n",
    "arr_on_p = np.array(ON_list)\n",
    "# print(arr_on_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hbaq7jn6fde0"
   },
   "outputs": [],
   "source": [
    "arr_on_p = np.delete(arr_on_p, 3,  axis=1)\n",
    "arr_on_p_n = arr_on_p[:, 1::2]\n",
    "arr_on_p_f = np.delete(arr_on_p_n, 1,  axis=1)\n",
    "# print(len(arr_on_p_f))\n",
    "# print(len(arr_on_p_f[0]))\n",
    "# print(arr_on_p_f[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 246
    },
    "colab_type": "code",
    "id": "nntpfcxlgZsO",
    "outputId": "d43b0254-360c-4905-dc50-0c58612e00d8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y0</th>\n",
       "      <th>y1</th>\n",
       "      <th>y2</th>\n",
       "      <th>y3</th>\n",
       "      <th>y4</th>\n",
       "      <th>y5</th>\n",
       "      <th>y6</th>\n",
       "      <th>y7</th>\n",
       "      <th>y8</th>\n",
       "      <th>y9</th>\n",
       "      <th>...</th>\n",
       "      <th>y9991</th>\n",
       "      <th>y9992</th>\n",
       "      <th>y9993</th>\n",
       "      <th>y9994</th>\n",
       "      <th>y9995</th>\n",
       "      <th>y9996</th>\n",
       "      <th>y9997</th>\n",
       "      <th>y9998</th>\n",
       "      <th>y9999</th>\n",
       "      <th>y10000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ON_1_20181031_173504_104</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>...</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ON_3_20181031_173800_104</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>...</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ON_3_20181102_084856_103</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ON_1_20181102_084600_103</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ON_1_20181102_085847_102</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 10001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         y0    y1    y2    y3    y4    y5    y6    y7    y8  \\\n",
       "0  ON_1_20181031_173504_104  0.03  0.03  0.03  0.03  0.03  0.03  0.03  0.03   \n",
       "1  ON_3_20181031_173800_104  0.03  0.02  0.04  0.03  0.03  0.03  0.04  0.03   \n",
       "2  ON_3_20181102_084856_103  0.06  0.06  0.06  0.06  0.06  0.06  0.06  0.06   \n",
       "3  ON_1_20181102_084600_103  0.05  0.06  0.06  0.06  0.06  0.06  0.05  0.06   \n",
       "4  ON_1_20181102_085847_102  0.06  0.06  0.06  0.06  0.06  0.06  0.06  0.06   \n",
       "\n",
       "     y9  ... y9991 y9992 y9993 y9994 y9995 y9996 y9997 y9998 y9999 y10000  \n",
       "0  0.03  ...  0.15  0.14  0.14  0.14  0.15  0.14  0.14  0.14  0.14   0.14  \n",
       "1  0.03  ...  0.14  0.15  0.14  0.14  0.15  0.14  0.14  0.14  0.14   0.14  \n",
       "2  0.06  ...  0.17  0.17  0.17  0.16  0.17  0.17  0.17  0.17  0.17   0.17  \n",
       "3  0.06  ...  0.17  0.16  0.16  0.17  0.17  0.17  0.17  0.17  0.16   0.17  \n",
       "4  0.06  ...  0.17  0.17  0.17  0.17  0.17  0.17  0.17  0.17  0.17   0.17  \n",
       "\n",
       "[5 rows x 10001 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = arr_on_p_f\n",
    "\n",
    "df=pd.DataFrame(data=data[0:,0:],index=[i for i in range(data.shape[0])],\n",
    "                columns=['y'+str(i) for i in range(data.shape[1])])\n",
    "df.head()\n",
    "# df.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "colab_type": "code",
    "id": "0SaXXr_ggcFp",
    "outputId": "ca27a21d-91be-4121-8efe-6dd58c9d8431"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(426, 10001)\n",
      "(423, 10001)\n",
      "(426, 10001)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y0</th>\n",
       "      <th>y1</th>\n",
       "      <th>y2</th>\n",
       "      <th>y3</th>\n",
       "      <th>y4</th>\n",
       "      <th>y5</th>\n",
       "      <th>y6</th>\n",
       "      <th>y7</th>\n",
       "      <th>y8</th>\n",
       "      <th>y9</th>\n",
       "      <th>...</th>\n",
       "      <th>y9991</th>\n",
       "      <th>y9992</th>\n",
       "      <th>y9993</th>\n",
       "      <th>y9994</th>\n",
       "      <th>y9995</th>\n",
       "      <th>y9996</th>\n",
       "      <th>y9997</th>\n",
       "      <th>y9998</th>\n",
       "      <th>y9999</th>\n",
       "      <th>y10000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ON_1_20181031_173504_104</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>...</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ON_3_20181031_173800_104</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>...</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ON_3_20181102_084856_103</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ON_1_20181102_084600_103</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ON_1_20181102_085847_102</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 10001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         y0    y1    y2    y3    y4    y5    y6    y7    y8  \\\n",
       "0  ON_1_20181031_173504_104  0.03  0.03  0.03  0.03  0.03  0.03  0.03  0.03   \n",
       "1  ON_3_20181031_173800_104  0.03  0.02  0.04  0.03  0.03  0.03  0.04  0.03   \n",
       "2  ON_3_20181102_084856_103  0.06  0.06  0.06  0.06  0.06  0.06  0.06  0.06   \n",
       "3  ON_1_20181102_084600_103  0.05  0.06  0.06  0.06  0.06  0.06  0.05  0.06   \n",
       "4  ON_1_20181102_085847_102  0.06  0.06  0.06  0.06  0.06  0.06  0.06  0.06   \n",
       "\n",
       "     y9  ... y9991 y9992 y9993 y9994 y9995 y9996 y9997 y9998 y9999 y10000  \n",
       "0  0.03  ...  0.15  0.14  0.14  0.14  0.15  0.14  0.14  0.14  0.14   0.14  \n",
       "1  0.03  ...  0.14  0.15  0.14  0.14  0.15  0.14  0.14  0.14  0.14   0.14  \n",
       "2  0.06  ...  0.17  0.17  0.17  0.16  0.17  0.17  0.17  0.17  0.17   0.17  \n",
       "3  0.06  ...  0.17  0.16  0.16  0.17  0.17  0.17  0.17  0.17  0.16   0.17  \n",
       "4  0.06  ...  0.17  0.17  0.17  0.17  0.17  0.17  0.17  0.17  0.17   0.17  \n",
       "\n",
       "[5 rows x 10001 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "# for j in range(10000):\n",
    "#   var = \"y\"+str(j+1)\n",
    "#   df[var].fillna(df[var].mean(), inplace=True)\n",
    "df_no_miss = df.dropna()\n",
    "print(df_no_miss.shape)\n",
    "print(df.shape)\n",
    "df_no_miss.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "VMYfPRjHghm3",
    "outputId": "dbf33109-20a1-436e-c2b4-9fb1621e1d18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "423\n"
     ]
    }
   ],
   "source": [
    "arr_p_no = df_no_miss.values\n",
    "print(len(arr_p_no))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 246
    },
    "colab_type": "code",
    "id": "LGF8F0segjoF",
    "outputId": "26312138-8059-4a36-e75b-69b8b4b3f616"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>y1</th>\n",
       "      <th>y2</th>\n",
       "      <th>y3</th>\n",
       "      <th>y4</th>\n",
       "      <th>y5</th>\n",
       "      <th>y6</th>\n",
       "      <th>y7</th>\n",
       "      <th>y8</th>\n",
       "      <th>y9</th>\n",
       "      <th>...</th>\n",
       "      <th>y9991</th>\n",
       "      <th>y9992</th>\n",
       "      <th>y9993</th>\n",
       "      <th>y9994</th>\n",
       "      <th>y9995</th>\n",
       "      <th>y9996</th>\n",
       "      <th>y9997</th>\n",
       "      <th>y9998</th>\n",
       "      <th>y9999</th>\n",
       "      <th>y10000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ON_1_20181031_173504_104</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>...</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ON_3_20181031_173800_104</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>...</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ON_3_20181102_084856_103</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ON_1_20181102_084600_103</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ON_1_20181102_085847_102</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 10001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id    y1    y2    y3    y4    y5    y6    y7    y8  \\\n",
       "0  ON_1_20181031_173504_104  0.03  0.03  0.03  0.03  0.03  0.03  0.03  0.03   \n",
       "1  ON_3_20181031_173800_104  0.03  0.02  0.04  0.03  0.03  0.03  0.04  0.03   \n",
       "2  ON_3_20181102_084856_103  0.06  0.06  0.06  0.06  0.06  0.06  0.06  0.06   \n",
       "3  ON_1_20181102_084600_103  0.05  0.06  0.06  0.06  0.06  0.06  0.05  0.06   \n",
       "4  ON_1_20181102_085847_102  0.06  0.06  0.06  0.06  0.06  0.06  0.06  0.06   \n",
       "\n",
       "     y9  ... y9991 y9992 y9993 y9994 y9995 y9996 y9997 y9998 y9999 y10000  \n",
       "0  0.03  ...  0.15  0.14  0.14  0.14  0.15  0.14  0.14  0.14  0.14   0.14  \n",
       "1  0.03  ...  0.14  0.15  0.14  0.14  0.15  0.14  0.14  0.14  0.14   0.14  \n",
       "2  0.06  ...  0.17  0.17  0.17  0.16  0.17  0.17  0.17  0.17  0.17   0.17  \n",
       "3  0.06  ...  0.17  0.16  0.16  0.17  0.17  0.17  0.17  0.17  0.16   0.17  \n",
       "4  0.06  ...  0.17  0.17  0.17  0.17  0.17  0.17  0.17  0.17  0.17   0.17  \n",
       "\n",
       "[5 rows x 10001 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1= df_no_miss.rename(index=str, columns={\"y0\": \"id\"})\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "OgI9lWPHgl_2",
    "outputId": "a21663e5-9263-4230-fde2-1721c3984a23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(423, 10001)\n",
      "(423, 10016)\n"
     ]
    }
   ],
   "source": [
    "print(df1.shape)\n",
    "df2 = data_v\n",
    "# print(df2.shape)\n",
    "combine = (pd.merge(df1, df2, how='left', on='id'))\n",
    "# print(df1.unique)\n",
    "print(combine.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 263
    },
    "colab_type": "code",
    "id": "_Frd3KdYgoVN",
    "outputId": "11f0509c-a31b-436c-cd41-7b3ddb0d17be"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>y1</th>\n",
       "      <th>y2</th>\n",
       "      <th>y3</th>\n",
       "      <th>y4</th>\n",
       "      <th>y5</th>\n",
       "      <th>y6</th>\n",
       "      <th>y7</th>\n",
       "      <th>y8</th>\n",
       "      <th>y9</th>\n",
       "      <th>...</th>\n",
       "      <th>current_stabilised_value (mA)</th>\n",
       "      <th>current_max/min_value (mA)</th>\n",
       "      <th>power_state_spec</th>\n",
       "      <th>current_rise/fall_time_spec (mS)</th>\n",
       "      <th>current_stabilised_spec (mA)</th>\n",
       "      <th>current_max/min_spec (mA)</th>\n",
       "      <th>power_state_N/NC</th>\n",
       "      <th>current_rise/fall_time_C/NC</th>\n",
       "      <th>current_stabilised_C/NC</th>\n",
       "      <th>current_max/min_C/NC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ON_1_20181031_173504_104</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>...</td>\n",
       "      <td>150.000000000000</td>\n",
       "      <td>405.992200000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60</td>\n",
       "      <td>510.204</td>\n",
       "      <td>800</td>\n",
       "      <td>C</td>\n",
       "      <td>NC</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ON_3_20181031_173800_104</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>...</td>\n",
       "      <td>140.000000000000</td>\n",
       "      <td>405.992200000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60</td>\n",
       "      <td>495.049</td>\n",
       "      <td>800</td>\n",
       "      <td>C</td>\n",
       "      <td>NC</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ON_3_20181102_084856_103</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>...</td>\n",
       "      <td>166.300000000000</td>\n",
       "      <td>405.992200000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60</td>\n",
       "      <td>495.049</td>\n",
       "      <td>800</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ON_1_20181102_084600_103</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>...</td>\n",
       "      <td>169.800000000000</td>\n",
       "      <td>405.992200000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60</td>\n",
       "      <td>510.204</td>\n",
       "      <td>800</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ON_1_20181102_085847_102</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>...</td>\n",
       "      <td>170.000000000000</td>\n",
       "      <td>401.312500000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60</td>\n",
       "      <td>510.204</td>\n",
       "      <td>800</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 10016 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id    y1    y2    y3    y4    y5    y6    y7    y8  \\\n",
       "0  ON_1_20181031_173504_104  0.03  0.03  0.03  0.03  0.03  0.03  0.03  0.03   \n",
       "1  ON_3_20181031_173800_104  0.03  0.02  0.04  0.03  0.03  0.03  0.04  0.03   \n",
       "2  ON_3_20181102_084856_103  0.06  0.06  0.06  0.06  0.06  0.06  0.06  0.06   \n",
       "3  ON_1_20181102_084600_103  0.05  0.06  0.06  0.06  0.06  0.06  0.05  0.06   \n",
       "4  ON_1_20181102_085847_102  0.06  0.06  0.06  0.06  0.06  0.06  0.06  0.06   \n",
       "\n",
       "     y9  ... current_stabilised_value (mA) current_max/min_value (mA)  \\\n",
       "0  0.03  ...              150.000000000000           405.992200000000   \n",
       "1  0.03  ...              140.000000000000           405.992200000000   \n",
       "2  0.06  ...              166.300000000000           405.992200000000   \n",
       "3  0.06  ...              169.800000000000           405.992200000000   \n",
       "4  0.06  ...              170.000000000000           401.312500000000   \n",
       "\n",
       "  power_state_spec current_rise/fall_time_spec (mS)  \\\n",
       "0              1.0                               60   \n",
       "1              1.0                               60   \n",
       "2              1.0                               60   \n",
       "3              1.0                               60   \n",
       "4              1.0                               60   \n",
       "\n",
       "  current_stabilised_spec (mA) current_max/min_spec (mA) power_state_N/NC  \\\n",
       "0                      510.204                       800                C   \n",
       "1                      495.049                       800                C   \n",
       "2                      495.049                       800                C   \n",
       "3                      510.204                       800                C   \n",
       "4                      510.204                       800                C   \n",
       "\n",
       "  current_rise/fall_time_C/NC current_stabilised_C/NC current_max/min_C/NC  \n",
       "0                          NC                       C                    C  \n",
       "1                          NC                       C                    C  \n",
       "2                           C                       C                    C  \n",
       "3                           C                       C                    C  \n",
       "4                           C                       C                    C  \n",
       "\n",
       "[5 rows x 10016 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 263
    },
    "colab_type": "code",
    "id": "djNeEIiPgq7w",
    "outputId": "d24ce3be-3c68-4aa6-ec6d-1bcd3bd0447d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>y1</th>\n",
       "      <th>y2</th>\n",
       "      <th>y3</th>\n",
       "      <th>y4</th>\n",
       "      <th>y5</th>\n",
       "      <th>y6</th>\n",
       "      <th>y7</th>\n",
       "      <th>y8</th>\n",
       "      <th>y9</th>\n",
       "      <th>...</th>\n",
       "      <th>current_stabilised_value (mA)</th>\n",
       "      <th>current_max/min_value (mA)</th>\n",
       "      <th>power_state_spec</th>\n",
       "      <th>current_rise/fall_time_spec (mS)</th>\n",
       "      <th>current_stabilised_spec (mA)</th>\n",
       "      <th>current_max/min_spec (mA)</th>\n",
       "      <th>power_state_N/NC</th>\n",
       "      <th>current_rise/fall_time_C/NC</th>\n",
       "      <th>current_stabilised_C/NC</th>\n",
       "      <th>current_max/min_C/NC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ON_1_20181031_173504_104</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>...</td>\n",
       "      <td>150.000000000000</td>\n",
       "      <td>405.992200000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60</td>\n",
       "      <td>510.204</td>\n",
       "      <td>800</td>\n",
       "      <td>C</td>\n",
       "      <td>NC</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ON_3_20181031_173800_104</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>...</td>\n",
       "      <td>140.000000000000</td>\n",
       "      <td>405.992200000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60</td>\n",
       "      <td>495.049</td>\n",
       "      <td>800</td>\n",
       "      <td>C</td>\n",
       "      <td>NC</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ON_3_20181102_084856_103</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>...</td>\n",
       "      <td>166.300000000000</td>\n",
       "      <td>405.992200000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60</td>\n",
       "      <td>495.049</td>\n",
       "      <td>800</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ON_1_20181102_084600_103</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>...</td>\n",
       "      <td>169.800000000000</td>\n",
       "      <td>405.992200000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60</td>\n",
       "      <td>510.204</td>\n",
       "      <td>800</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ON_1_20181102_085847_102</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>...</td>\n",
       "      <td>170.000000000000</td>\n",
       "      <td>401.312500000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60</td>\n",
       "      <td>510.204</td>\n",
       "      <td>800</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 10013 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id    y1    y2    y3    y4    y5    y6    y7    y8  \\\n",
       "0  ON_1_20181031_173504_104  0.03  0.03  0.03  0.03  0.03  0.03  0.03  0.03   \n",
       "1  ON_3_20181031_173800_104  0.03  0.02  0.04  0.03  0.03  0.03  0.04  0.03   \n",
       "2  ON_3_20181102_084856_103  0.06  0.06  0.06  0.06  0.06  0.06  0.06  0.06   \n",
       "3  ON_1_20181102_084600_103  0.05  0.06  0.06  0.06  0.06  0.06  0.05  0.06   \n",
       "4  ON_1_20181102_085847_102  0.06  0.06  0.06  0.06  0.06  0.06  0.06  0.06   \n",
       "\n",
       "     y9  ... current_stabilised_value (mA) current_max/min_value (mA)  \\\n",
       "0  0.03  ...              150.000000000000           405.992200000000   \n",
       "1  0.03  ...              140.000000000000           405.992200000000   \n",
       "2  0.06  ...              166.300000000000           405.992200000000   \n",
       "3  0.06  ...              169.800000000000           405.992200000000   \n",
       "4  0.06  ...              170.000000000000           401.312500000000   \n",
       "\n",
       "  power_state_spec current_rise/fall_time_spec (mS)  \\\n",
       "0              1.0                               60   \n",
       "1              1.0                               60   \n",
       "2              1.0                               60   \n",
       "3              1.0                               60   \n",
       "4              1.0                               60   \n",
       "\n",
       "  current_stabilised_spec (mA) current_max/min_spec (mA) power_state_N/NC  \\\n",
       "0                      510.204                       800                C   \n",
       "1                      495.049                       800                C   \n",
       "2                      495.049                       800                C   \n",
       "3                      510.204                       800                C   \n",
       "4                      510.204                       800                C   \n",
       "\n",
       "  current_rise/fall_time_C/NC current_stabilised_C/NC current_max/min_C/NC  \n",
       "0                          NC                       C                    C  \n",
       "1                          NC                       C                    C  \n",
       "2                           C                       C                    C  \n",
       "3                           C                       C                    C  \n",
       "4                           C                       C                    C  \n",
       "\n",
       "[5 rows x 10013 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine.iloc[:,0:10010].head()\n",
    "k = combine.drop(['s.no','dir','_file_'], axis = 1) \n",
    "\n",
    "k.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 263
    },
    "colab_type": "code",
    "id": "2vbEb4-ogtJg",
    "outputId": "65d9c504-b261-4ecd-9102-3883bcdc8782"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y1</th>\n",
       "      <th>y2</th>\n",
       "      <th>y3</th>\n",
       "      <th>y4</th>\n",
       "      <th>y5</th>\n",
       "      <th>y6</th>\n",
       "      <th>y7</th>\n",
       "      <th>y8</th>\n",
       "      <th>y9</th>\n",
       "      <th>y10</th>\n",
       "      <th>...</th>\n",
       "      <th>y9999</th>\n",
       "      <th>y10000</th>\n",
       "      <th>power_state_value</th>\n",
       "      <th>current_rise/fall_time_value (mS)</th>\n",
       "      <th>current_stabilised_value (mA)</th>\n",
       "      <th>current_max/min_value (mA)</th>\n",
       "      <th>power_state_spec</th>\n",
       "      <th>current_rise/fall_time_spec (mS)</th>\n",
       "      <th>current_stabilised_spec (mA)</th>\n",
       "      <th>current_max/min_spec (mA)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>...</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>89.990000000000</td>\n",
       "      <td>150.000000000000</td>\n",
       "      <td>405.992200000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60</td>\n",
       "      <td>510.204</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>...</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>89.950000000000</td>\n",
       "      <td>140.000000000000</td>\n",
       "      <td>405.992200000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60</td>\n",
       "      <td>495.049</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.970000000000</td>\n",
       "      <td>166.300000000000</td>\n",
       "      <td>405.992200000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60</td>\n",
       "      <td>495.049</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>56.650000000000</td>\n",
       "      <td>169.800000000000</td>\n",
       "      <td>405.992200000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60</td>\n",
       "      <td>510.204</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37.040000000000</td>\n",
       "      <td>170.000000000000</td>\n",
       "      <td>401.312500000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60</td>\n",
       "      <td>510.204</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 10008 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     y1    y2    y3    y4    y5    y6    y7    y8    y9   y10  ... y9999  \\\n",
       "0  0.03  0.03  0.03  0.03  0.03  0.03  0.03  0.03  0.03  0.03  ...  0.14   \n",
       "1  0.03  0.02  0.04  0.03  0.03  0.03  0.04  0.03  0.03  0.03  ...  0.14   \n",
       "2  0.06  0.06  0.06  0.06  0.06  0.06  0.06  0.06  0.06  0.06  ...  0.17   \n",
       "3  0.05  0.06  0.06  0.06  0.06  0.06  0.05  0.06  0.06  0.06  ...  0.16   \n",
       "4  0.06  0.06  0.06  0.06  0.06  0.06  0.06  0.06  0.06  0.06  ...  0.17   \n",
       "\n",
       "  y10000 power_state_value current_rise/fall_time_value (mS)  \\\n",
       "0   0.14               1.0                   89.990000000000   \n",
       "1   0.14               1.0                   89.950000000000   \n",
       "2   0.17               1.0                   36.970000000000   \n",
       "3   0.17               1.0                   56.650000000000   \n",
       "4   0.17               1.0                   37.040000000000   \n",
       "\n",
       "  current_stabilised_value (mA) current_max/min_value (mA) power_state_spec  \\\n",
       "0              150.000000000000           405.992200000000              1.0   \n",
       "1              140.000000000000           405.992200000000              1.0   \n",
       "2              166.300000000000           405.992200000000              1.0   \n",
       "3              169.800000000000           405.992200000000              1.0   \n",
       "4              170.000000000000           401.312500000000              1.0   \n",
       "\n",
       "  current_rise/fall_time_spec (mS) current_stabilised_spec (mA)  \\\n",
       "0                               60                      510.204   \n",
       "1                               60                      495.049   \n",
       "2                               60                      495.049   \n",
       "3                               60                      510.204   \n",
       "4                               60                      510.204   \n",
       "\n",
       "  current_max/min_spec (mA)  \n",
       "0                       800  \n",
       "1                       800  \n",
       "2                       800  \n",
       "3                       800  \n",
       "4                       800  \n",
       "\n",
       "[5 rows x 10008 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_1 = k.iloc[:,0:10009]\n",
    "# filling the missing values\n",
    "\n",
    "# print(input_1.iloc[:,10008])\n",
    "miss = input_1.iloc[:,1:]\n",
    "miss.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 263
    },
    "colab_type": "code",
    "id": "5i0q3j2zgvS1",
    "outputId": "d7bdae54-970a-43dc-ddb0-69ff22e33f91"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y1</th>\n",
       "      <th>y2</th>\n",
       "      <th>y3</th>\n",
       "      <th>y4</th>\n",
       "      <th>y5</th>\n",
       "      <th>y6</th>\n",
       "      <th>y7</th>\n",
       "      <th>y8</th>\n",
       "      <th>y9</th>\n",
       "      <th>y10</th>\n",
       "      <th>...</th>\n",
       "      <th>y9999</th>\n",
       "      <th>y10000</th>\n",
       "      <th>power_state_value</th>\n",
       "      <th>current_rise/fall_time_value (mS)</th>\n",
       "      <th>current_stabilised_value (mA)</th>\n",
       "      <th>current_max/min_value (mA)</th>\n",
       "      <th>power_state_spec</th>\n",
       "      <th>current_rise/fall_time_spec (mS)</th>\n",
       "      <th>current_stabilised_spec (mA)</th>\n",
       "      <th>current_max/min_spec (mA)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>...</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>89.99</td>\n",
       "      <td>150.0</td>\n",
       "      <td>405.9922</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>510.204</td>\n",
       "      <td>800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>...</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>89.95</td>\n",
       "      <td>140.0</td>\n",
       "      <td>405.9922</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>495.049</td>\n",
       "      <td>800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.97</td>\n",
       "      <td>166.3</td>\n",
       "      <td>405.9922</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>495.049</td>\n",
       "      <td>800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>56.65</td>\n",
       "      <td>169.8</td>\n",
       "      <td>405.9922</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>510.204</td>\n",
       "      <td>800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37.04</td>\n",
       "      <td>170.0</td>\n",
       "      <td>401.3125</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>510.204</td>\n",
       "      <td>800.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 10008 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     y1    y2    y3    y4    y5    y6    y7    y8    y9   y10  ...  y9999  \\\n",
       "0  0.03  0.03  0.03  0.03  0.03  0.03  0.03  0.03  0.03  0.03  ...   0.14   \n",
       "1  0.03  0.02  0.04  0.03  0.03  0.03  0.04  0.03  0.03  0.03  ...   0.14   \n",
       "2  0.06  0.06  0.06  0.06  0.06  0.06  0.06  0.06  0.06  0.06  ...   0.17   \n",
       "3  0.05  0.06  0.06  0.06  0.06  0.06  0.05  0.06  0.06  0.06  ...   0.16   \n",
       "4  0.06  0.06  0.06  0.06  0.06  0.06  0.06  0.06  0.06  0.06  ...   0.17   \n",
       "\n",
       "   y10000  power_state_value  current_rise/fall_time_value (mS)  \\\n",
       "0    0.14                1.0                              89.99   \n",
       "1    0.14                1.0                              89.95   \n",
       "2    0.17                1.0                              36.97   \n",
       "3    0.17                1.0                              56.65   \n",
       "4    0.17                1.0                              37.04   \n",
       "\n",
       "   current_stabilised_value (mA)  current_max/min_value (mA)  \\\n",
       "0                          150.0                    405.9922   \n",
       "1                          140.0                    405.9922   \n",
       "2                          166.3                    405.9922   \n",
       "3                          169.8                    405.9922   \n",
       "4                          170.0                    401.3125   \n",
       "\n",
       "   power_state_spec  current_rise/fall_time_spec (mS)  \\\n",
       "0               1.0                              60.0   \n",
       "1               1.0                              60.0   \n",
       "2               1.0                              60.0   \n",
       "3               1.0                              60.0   \n",
       "4               1.0                              60.0   \n",
       "\n",
       "   current_stabilised_spec (mA)  current_max/min_spec (mA)  \n",
       "0                       510.204                      800.0  \n",
       "1                       495.049                      800.0  \n",
       "2                       495.049                      800.0  \n",
       "3                       510.204                      800.0  \n",
       "4                       510.204                      800.0  \n",
       "\n",
       "[5 rows x 10008 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_1 = k.iloc[:,0:10009]\n",
    "# filling the missing values\n",
    "\n",
    "miss = input_1.iloc[:,1:]\n",
    "miss.head()\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "for column in (miss.iloc[:,10000:]):\n",
    "  su = 0\n",
    "  div = 0\n",
    "  for r in range(miss.shape[0]):\n",
    "    if (pd.isna(miss[column][r]))== False:\n",
    "      su = float(miss[column][r])+su\n",
    "\n",
    "      div = div+1\n",
    "\n",
    "  fin = float(su/div)\n",
    "\n",
    "  miss[column].fillna(float(fin),inplace=True)\n",
    "#########converting ever\n",
    "# thing into float\n",
    "miss =miss.astype('float64')\n",
    "# print(miss.dtypes)\n",
    "miss.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jBZnARyHgyfK"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble.forest import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import robust_scale\n",
    "\n",
    "scaler_min_x = MinMaxScaler()\n",
    "scaler_min_y = MinMaxScaler()\n",
    "\n",
    "scaler_norm_x = Normalizer()\n",
    "scaler_norm_y = Normalizer()\n",
    "\n",
    "scaler_stan_x = StandardScaler()\n",
    "scaler_stan_y = StandardScaler()\n",
    "\n",
    "scalar_qt_x =QuantileTransformer(output_distribution='uniform')\n",
    "scalar_qt_y =QuantileTransformer(output_distribution='uniform')\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 161
    },
    "colab_type": "code",
    "id": "eyHICz0yg2BJ",
    "outputId": "67294fc3-9c83-42a2-dc0a-261d494b5951"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/preprocessing/data.py:2239: UserWarning: n_quantiles (1000) is greater than the total number of samples (423). n_quantiles is set to n_samples.\n",
      "  % (self.n_quantiles, n_samples))\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/preprocessing/data.py:2239: UserWarning: n_quantiles (1000) is greater than the total number of samples (423). n_quantiles is set to n_samples.\n",
      "  % (self.n_quantiles, n_samples))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "410.0\n",
      "405.9922\n",
      "(423, 10002)\n"
     ]
    }
   ],
   "source": [
    "rand_na = miss\n",
    "# print(miss.shape)\n",
    "input_1_arr = rand_na.values\n",
    "input_1_arr[:,:]= input_1_arr[:,:].astype('float64')\n",
    "\n",
    "X = input_1_arr[:,0:10000]*1000\n",
    "Y = input_1_arr[:,10002:10004]\n",
    "# print(X.shape)\n",
    "# print(Y.shape)\n",
    "# print(Y)\n",
    "y=np.reshape(Y, (-1,1))\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.20)\n",
    "X_train= X\n",
    "y_train= Y\n",
    "\n",
    "\n",
    "# ######minmax\n",
    "scaler_min_x = MinMaxScaler().fit(X_train)\n",
    "scaler_min_y = MinMaxScaler().fit(y_train)\n",
    "\n",
    "X_minmax_train = scaler_min_x.transform(X_train)\n",
    "Y_minmax_train = scaler_min_y.transform(y_train)\n",
    "\n",
    "\n",
    "# print(X)\n",
    "# print(Y)\n",
    "#####standard\n",
    "\n",
    "scaler_stan_x = StandardScaler().fit(X_train)\n",
    "scaler_stan_y = StandardScaler().fit(y_train)\n",
    "\n",
    "\n",
    "X_stan_train = scaler_stan_x.transform(X_train)\n",
    "Y_stan_train = scaler_stan_y.transform(y_train)\n",
    "\n",
    "#######normlised\n",
    "scaler_norm_x = Normalizer().fit(X_train)\n",
    "scaler_norm_y = Normalizer().fit(y_train)\n",
    "\n",
    "\n",
    "X_norm_train = scaler_norm_x.transform(X_train)\n",
    "Y_norm_train = scaler_norm_y.transform(y_train)\n",
    "\n",
    "\n",
    "# ################qt\n",
    "\n",
    "scaler_qt_x =  QuantileTransformer(output_distribution='normal').fit(X_train)\n",
    "scaler_qt_y =  QuantileTransformer(output_distribution='normal').fit(y_train)\n",
    "\n",
    "\n",
    "X_qt_train = scaler_qt_x.transform(X_train)\n",
    "Y_qt_train = scaler_qt_y.transform(y_train)\n",
    "\n",
    "\n",
    "##robust\n",
    "\n",
    "##robust\n",
    "print(np.amax(X_train[0,:]))\n",
    "print(np.amax(y_train[0,:]))\n",
    "\n",
    "X_train = np.concatenate((X_train, y_train), axis=1)\n",
    "# print(np.amax(X_train[0,:]))\n",
    "X_train_t = X_train.transpose()\n",
    "# y_train_t = y_train.transpose()\n",
    "# print(X_train,\"after\")\n",
    "# print(y_train.shape,\"after\")\n",
    "\n",
    "scaler_rob_x = MinMaxScaler().fit(X_train_t)\n",
    "# scaler_rob_y = RobustScaler().fit(y_train_t)\n",
    "\n",
    "\n",
    "X_rob_train = scaler_rob_x.transform(X_train_t)\n",
    "# Y_rob_train = scaler_rob_x.transform(y_train_t)\n",
    "\n",
    "X_rob_train = X_rob_train.transpose()\n",
    "# Y_rob_train = Y_rob_train.transpose()\n",
    "\n",
    "print(X_rob_train.shape)\n",
    "# print(Y_rob_train.shape)\n",
    "# print(Y_rob_train)\n",
    "\n",
    "Y_rob_train = X_rob_train[:,10000:10002]\n",
    "X_rob_train = X_rob_train[:,0:10000]\n",
    "# print(Y_rob_train)\n",
    "# print(X_rob_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "RlJlt7DghBIG",
    "outputId": "88bba53c-b75d-458f-cb84-41297679341b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(423, 30)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import FactorAnalysis\n",
    "\n",
    "transformer = FactorAnalysis(n_components=30, random_state=0)\n",
    "factor_fit = transformer.fit(X_rob_train)\n",
    "X_new = factor_fit.transform(X_rob_train)\n",
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D5rmicgppLVP"
   },
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "pickle.dump(factor_fit, open( \"./app/MODEL/factor_fit_on.pkl\", \"wb\" ) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1VKNQkEahFjV"
   },
   "outputs": [],
   "source": [
    "def baseline_model_30(optimizer='adam'):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(28, activation='relu', \n",
    "                    kernel_initializer = 'he_normal', \n",
    "                    input_shape=(30,)))\n",
    "    model.add(BatchNormalization())\n",
    "#     model.add(Dropout(0.5))\n",
    "#     model.add(Dense(30, activation='relu',\n",
    "#                     kernel_initializer = 'he_normal'))\n",
    "#       model.add(BatchNormalization())\n",
    "#     model.add(Dropout(0.5))\n",
    "    model.add(Dense(12, activation='relu',\n",
    "                    kernel_initializer = 'he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "#     model.add(Dropout(0.5))\n",
    "    model.add(Dense(9, activation='relu',\n",
    "                    kernel_initializer = 'he_normal'))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(Dropout(0.5))\n",
    "    model.add(Dense(2, activation='linear', \n",
    "                    kernel_initializer='he_normal'))\n",
    "    model.compile(loss = 'mse', optimizer=optimizer, metrics=['mae'])\n",
    "#     model.summary()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "4thveclshIbz",
    "outputId": "f1f13189-5035-4910-cd20-25a91590c6fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "[array([[-3.30190593e-03,  3.35075818e-02,  2.67684102e-01,\n",
      "         1.17216315e-02,  4.13080722e-01, -4.09473293e-02,\n",
      "        -3.25645268e-01,  7.03441128e-02, -2.21359015e-01,\n",
      "         1.91263601e-01, -3.11688244e-01,  2.64019705e-02,\n",
      "         4.20207456e-02,  5.09603648e-03, -1.75092846e-01,\n",
      "         1.57767922e-01,  1.76742807e-01, -3.58492523e-01,\n",
      "         2.66578734e-01, -1.19954646e-01, -4.50166538e-02,\n",
      "         1.31254122e-01,  4.04463440e-01, -4.22014557e-02,\n",
      "        -2.19220340e-01, -1.57251909e-01,  1.50504470e-01,\n",
      "         4.29330617e-01],\n",
      "       [ 1.59135729e-01,  4.98907454e-02,  3.97246093e-01,\n",
      "        -3.58208686e-01, -3.62375379e-01, -1.59355670e-01,\n",
      "         1.70376450e-01, -1.70957342e-01,  3.37092727e-01,\n",
      "        -2.44644225e-01,  3.45548689e-02, -9.10185128e-02,\n",
      "         3.23140323e-01, -2.89740771e-01, -5.68562150e-01,\n",
      "         3.07472289e-01,  2.47859538e-01,  9.57533270e-02,\n",
      "         1.16877593e-01,  4.37159389e-02,  2.31452376e-01,\n",
      "         1.16711780e-01, -3.91012877e-01,  1.54998109e-01,\n",
      "         3.69632751e-01,  3.69031906e-01,  4.18034911e-01,\n",
      "        -8.99869651e-02],\n",
      "       [ 3.22032899e-01, -8.67357850e-02,  3.23158324e-01,\n",
      "         2.41260201e-01, -3.84421766e-01, -8.45472366e-02,\n",
      "        -5.13900936e-01,  2.32110813e-01, -7.46984035e-03,\n",
      "        -4.77387100e-01,  1.94550470e-01, -3.11107248e-01,\n",
      "        -2.33587593e-01,  5.32281585e-02,  3.66649270e-01,\n",
      "         4.05667663e-01,  2.03122392e-01,  1.34836301e-01,\n",
      "        -7.30182081e-02, -2.25042015e-01, -4.23566848e-02,\n",
      "         8.50115940e-02, -4.17808861e-01, -2.37616450e-01,\n",
      "        -2.48649642e-01,  1.59984723e-01, -5.78754187e-01,\n",
      "         4.75306720e-01],\n",
      "       [-5.26335716e-01,  1.68708265e-01, -3.35696846e-01,\n",
      "         8.81566331e-02,  2.04665452e-01, -4.01883610e-02,\n",
      "        -3.20084870e-01, -2.52574235e-02, -5.33421993e-01,\n",
      "        -4.76006754e-02, -3.72395724e-01, -3.91549140e-01,\n",
      "        -1.87857702e-01,  3.64670083e-02, -1.82923600e-01,\n",
      "        -1.11905813e-01, -6.89598396e-02,  4.22241203e-02,\n",
      "         2.14034736e-01,  1.50375411e-01, -2.94617489e-02,\n",
      "        -4.38493460e-01, -4.81107086e-01, -1.12742350e-01,\n",
      "        -3.06389898e-01,  2.20846082e-03,  4.83790338e-01,\n",
      "        -4.79245961e-01],\n",
      "       [ 4.81173545e-01,  2.60748357e-01, -1.13103986e-02,\n",
      "        -3.08638036e-01, -1.29314259e-01,  9.63859484e-02,\n",
      "         2.74712622e-01, -5.78029864e-02,  8.17125440e-02,\n",
      "        -5.65491378e-01, -1.05013758e-01, -1.83522508e-01,\n",
      "        -1.73575297e-01, -1.75560132e-01, -2.61111557e-01,\n",
      "         1.21788763e-01,  4.82466400e-01, -3.88521165e-01,\n",
      "         1.93247303e-01,  5.82485721e-02,  5.61769485e-01,\n",
      "         2.57304251e-01,  1.90771595e-01, -5.69740891e-01,\n",
      "        -2.54331172e-01,  4.21552872e-03,  4.15578038e-01,\n",
      "         1.29251644e-01],\n",
      "       [ 2.64565289e-01, -1.29612818e-01,  1.01706319e-01,\n",
      "        -2.61988398e-02,  8.45031533e-03, -4.98915054e-02,\n",
      "        -4.49659497e-01,  5.82289249e-02, -3.17874670e-01,\n",
      "        -4.52852339e-01, -1.74452543e-01,  3.12904775e-01,\n",
      "         7.39283115e-03,  2.18184605e-01,  1.19965024e-01,\n",
      "        -3.06134433e-01,  3.55218165e-02, -1.92966387e-01,\n",
      "        -1.88914582e-01, -2.20417321e-01, -4.14477676e-01,\n",
      "         1.85421392e-01,  7.70753026e-02, -1.69576723e-02,\n",
      "        -1.99160621e-01,  2.15707660e-01,  2.53272980e-01,\n",
      "         3.62855964e-03],\n",
      "       [-6.10718690e-02, -5.03392816e-01,  1.61195144e-01,\n",
      "        -1.71307132e-01,  1.49040222e-01,  2.84765847e-03,\n",
      "         1.67748153e-01,  3.31949115e-01,  2.27723032e-01,\n",
      "         2.40561679e-01,  8.83668810e-02, -9.56899300e-02,\n",
      "        -3.60587314e-02, -2.89824069e-01, -3.33839953e-01,\n",
      "        -3.69739115e-01,  4.94206585e-02,  4.48002487e-01,\n",
      "         3.42730224e-01, -4.69117820e-01,  1.02181837e-01,\n",
      "         1.18442392e-02, -2.10436657e-01,  3.51825863e-01,\n",
      "         3.84697802e-02,  1.40583292e-01,  5.07840455e-01,\n",
      "        -5.36402285e-01],\n",
      "       [-5.54572903e-02,  5.88851050e-02, -3.27688456e-01,\n",
      "        -2.82442607e-02, -2.65151560e-01,  2.90101439e-01,\n",
      "        -1.08840521e-02, -1.31297797e-01, -8.85780677e-02,\n",
      "        -1.22972213e-01,  1.36446476e-01,  1.22054704e-01,\n",
      "         4.20616120e-01,  1.68028548e-02,  7.55188689e-02,\n",
      "         3.81153762e-01, -1.77943874e-02, -1.30483836e-01,\n",
      "         1.63883597e-01, -2.10579231e-01, -2.48119816e-01,\n",
      "        -3.56703788e-01,  1.37491316e-01, -5.74339880e-04,\n",
      "         4.29195940e-01, -3.59483153e-01, -2.88467318e-01,\n",
      "        -1.90156102e-01],\n",
      "       [-1.28820762e-01,  1.47933394e-01, -1.15624219e-01,\n",
      "        -1.65622041e-01,  2.29438245e-01, -6.98559508e-02,\n",
      "         2.28613436e-01, -4.91149575e-01,  2.82456148e-02,\n",
      "        -4.09730636e-02,  7.73013309e-02, -1.37978479e-01,\n",
      "        -8.88128430e-02,  3.85668874e-02,  1.40833542e-01,\n",
      "        -3.68654311e-01, -3.28940265e-02,  2.15796512e-02,\n",
      "        -5.25573343e-02,  2.58208901e-01,  3.32719693e-03,\n",
      "        -1.10880770e-01,  2.48065479e-02,  1.27569437e-01,\n",
      "         1.34291038e-01,  1.58361405e-01, -1.53009444e-01,\n",
      "         4.49562728e-01],\n",
      "       [-3.97920460e-01,  1.69718154e-02,  6.99740872e-02,\n",
      "         1.56403169e-01, -2.41276905e-01,  4.33790714e-01,\n",
      "         2.11032018e-01, -1.67571351e-01, -1.96397766e-01,\n",
      "        -3.30039501e-01,  1.70349672e-01,  2.14204013e-01,\n",
      "         2.25860819e-01, -1.93080008e-01,  2.15501785e-01,\n",
      "        -4.60251272e-02, -2.50596762e-01,  5.59253916e-02,\n",
      "        -1.40175462e-01, -8.18465874e-02, -3.13927442e-01,\n",
      "         1.54565766e-01, -1.88707799e-01, -2.79205650e-01,\n",
      "         1.55637428e-01,  2.82736927e-01, -1.67200163e-01,\n",
      "         1.55290484e-01],\n",
      "       [ 1.62115078e-02,  3.27212274e-01, -1.36982217e-01,\n",
      "        -3.48298311e-01, -2.29582414e-01,  4.95871715e-02,\n",
      "         4.57189560e-01, -1.82908494e-02,  2.52897143e-01,\n",
      "         2.99276471e-01,  4.59441930e-01,  3.09734583e-01,\n",
      "         1.53387904e-01, -1.94588691e-01,  2.66810864e-01,\n",
      "         2.68929973e-02, -3.67255509e-01, -5.25646619e-02,\n",
      "         1.72115028e-01, -5.75256050e-01,  3.08785588e-02,\n",
      "         8.72962002e-04,  1.78669527e-01, -3.08173746e-01,\n",
      "         1.70345947e-01, -4.38692212e-01,  4.83481348e-01,\n",
      "         3.58985931e-01],\n",
      "       [-4.17283587e-02,  4.65947598e-01, -8.70657191e-02,\n",
      "         4.37650010e-02, -1.66681215e-01,  3.43768187e-02,\n",
      "        -4.19035912e-01,  2.45444462e-01, -1.32816598e-01,\n",
      "         1.81058839e-01,  2.53514349e-02, -3.62346292e-01,\n",
      "         9.51323807e-02,  3.28872800e-01, -2.75059819e-01,\n",
      "        -1.92137778e-01, -8.23390782e-02, -1.86895043e-01,\n",
      "        -2.01960206e-02, -6.25055507e-02, -2.37001628e-01,\n",
      "         5.32287955e-01, -4.26406771e-01, -4.81833033e-02,\n",
      "         4.03908283e-01, -2.67647207e-01, -4.15752865e-02,\n",
      "        -1.50869593e-01],\n",
      "       [-2.34742448e-01, -2.49282226e-01,  2.39097983e-01,\n",
      "         2.59565283e-02,  1.52039558e-01, -3.95158350e-01,\n",
      "        -3.55210483e-01, -5.53908162e-02, -3.74602675e-01,\n",
      "         2.65463620e-01,  1.89109862e-01,  7.96128884e-02,\n",
      "         3.36223990e-01, -5.26497960e-01,  4.00795311e-01,\n",
      "        -1.26858369e-01,  2.68199295e-01, -3.96854013e-01,\n",
      "         5.96682243e-02, -3.27259094e-01,  5.03435552e-01,\n",
      "         1.21623866e-01,  3.96612734e-01,  1.07729651e-01,\n",
      "        -2.35487476e-01, -3.44874799e-01, -8.66372287e-02,\n",
      "         5.21296740e-01],\n",
      "       [-1.09029539e-01,  4.85242724e-01,  3.21925968e-01,\n",
      "         3.76682520e-01,  4.86730516e-01,  1.90726593e-02,\n",
      "         4.14698124e-02,  6.11720197e-02,  3.59497458e-01,\n",
      "         2.84765922e-02,  6.89214766e-02, -5.51944792e-01,\n",
      "         1.07616127e-01,  2.25377921e-02, -3.65572512e-01,\n",
      "        -2.23884881e-01,  1.21120751e-01, -1.87387969e-02,\n",
      "        -1.61941409e-01, -4.45058763e-01,  2.05266178e-02,\n",
      "         2.02262804e-01, -9.40743461e-02,  5.56134619e-02,\n",
      "        -5.53058796e-02, -4.56568718e-01, -2.96530515e-01,\n",
      "        -4.55813147e-02],\n",
      "       [ 2.21295357e-02, -1.15614399e-04,  3.17303449e-01,\n",
      "         1.50565132e-01, -1.07113548e-01,  9.97446328e-02,\n",
      "        -5.24606168e-01, -3.14489633e-01,  1.45890281e-01,\n",
      "        -7.62960117e-04,  3.46132755e-01,  8.61980021e-02,\n",
      "         1.21592127e-01, -1.39343083e-01,  3.87589723e-01,\n",
      "         1.38528213e-01,  3.94866019e-01,  1.89831376e-01,\n",
      "        -3.58196676e-01,  1.75809488e-01,  2.91660503e-02,\n",
      "         3.32891643e-02, -8.31980333e-02,  5.36706373e-02,\n",
      "         5.05848639e-02, -3.87158729e-02,  5.43080270e-01,\n",
      "        -1.15254506e-01],\n",
      "       [ 3.87182683e-01,  3.52645695e-01, -4.76567261e-02,\n",
      "         2.88986951e-01,  6.53822049e-02,  1.05099663e-01,\n",
      "        -9.13333073e-02, -3.77940446e-01, -1.53903142e-01,\n",
      "         1.18121468e-01,  4.28914696e-01, -3.77427280e-01,\n",
      "         1.31919995e-01, -1.55670285e-01, -1.57056659e-01,\n",
      "         4.86406565e-01, -2.82268345e-01,  1.46295488e-01,\n",
      "        -6.78568706e-02, -1.95345536e-01,  3.69947284e-01,\n",
      "        -1.37098342e-01, -1.41008511e-01, -1.60501212e-01,\n",
      "         7.70120025e-02,  3.85560840e-01,  7.79179903e-03,\n",
      "         3.73619616e-01],\n",
      "       [-2.58625094e-02, -2.20943149e-02, -4.15554672e-01,\n",
      "        -2.14893386e-01,  3.18218291e-01, -2.26115853e-01,\n",
      "         2.33775720e-01,  2.20383927e-02,  4.95620102e-01,\n",
      "         4.32832867e-01,  3.32108468e-01, -2.54495144e-01,\n",
      "        -1.45125747e-01,  3.94406021e-02, -2.73098737e-01,\n",
      "         1.13612525e-01,  2.83015609e-01, -3.17449391e-01,\n",
      "         2.02969518e-02,  4.09281850e-01, -1.15685284e-01,\n",
      "        -9.44304913e-02,  1.69456810e-01,  4.01145130e-01,\n",
      "        -3.17619532e-01,  9.28238705e-02, -3.49037498e-01,\n",
      "         1.13531031e-01],\n",
      "       [-1.56187534e-01, -1.45421147e-01, -3.38920832e-01,\n",
      "        -4.62983578e-01, -3.38762323e-03,  2.00518206e-01,\n",
      "        -6.54274002e-02,  2.32652545e-01, -2.98091117e-02,\n",
      "         2.49939442e-01,  1.94277391e-02, -4.39836413e-01,\n",
      "         5.12574673e-01,  5.44823289e-01,  6.77958429e-02,\n",
      "         2.63345748e-01,  1.46301202e-02, -1.21930085e-01,\n",
      "         1.17598757e-01,  9.42297876e-02, -7.56702125e-02,\n",
      "        -9.63473022e-02, -5.08562446e-01,  1.68179542e-01,\n",
      "         5.44013157e-02, -1.66003242e-01, -3.09197992e-01,\n",
      "        -1.51754795e-02],\n",
      "       [-2.66837943e-02, -2.15222854e-02, -2.76325524e-01,\n",
      "        -1.04995608e-01, -2.26868168e-01,  3.28246832e-01,\n",
      "         3.46805453e-01, -3.54690433e-01, -4.28513229e-01,\n",
      "        -2.32882291e-01,  2.14770228e-01, -1.86898887e-01,\n",
      "        -2.71167159e-01, -2.33745426e-01, -1.37132395e-03,\n",
      "        -1.54445276e-01, -5.11442125e-02, -1.70977369e-01,\n",
      "        -1.49498671e-01,  4.88614917e-01,  1.06967844e-01,\n",
      "         9.11949053e-02,  2.77240928e-02, -3.24090123e-02,\n",
      "         6.74203560e-02, -1.84244186e-01,  6.27168491e-02,\n",
      "        -2.22874582e-01],\n",
      "       [ 2.08361790e-01, -2.63011694e-01, -1.48160234e-01,\n",
      "         2.26061139e-02,  1.72363698e-01, -8.59781951e-02,\n",
      "        -4.20780592e-02,  5.73022328e-02, -4.85498190e-01,\n",
      "        -1.36370555e-01, -1.65995762e-01, -4.88096654e-01,\n",
      "         2.82900810e-01,  2.21199363e-01,  1.70842245e-01,\n",
      "        -3.33416998e-01, -2.66157418e-01,  1.59693900e-02,\n",
      "        -2.59898484e-01, -3.20203692e-01, -1.74661890e-01,\n",
      "        -3.25201899e-02,  5.52723825e-01, -5.50292321e-02,\n",
      "        -1.08099148e-01,  1.30471159e-02, -1.41977862e-01,\n",
      "         4.44964096e-02],\n",
      "       [ 6.93809912e-02, -3.66200984e-01, -2.12999716e-01,\n",
      "         4.45674479e-01, -2.42439374e-01, -4.58395571e-01,\n",
      "         4.29534644e-01, -9.44177434e-02, -3.18716071e-03,\n",
      "         1.06041409e-01,  2.05914956e-02, -3.73813659e-01,\n",
      "        -9.77825299e-02,  1.50886133e-01, -2.57740229e-01,\n",
      "         1.93806916e-01,  3.94352496e-01, -3.11374813e-01,\n",
      "         9.12082791e-02,  1.10248156e-01, -9.11632031e-02,\n",
      "         4.93109345e-01, -2.46568746e-03, -2.23567575e-01,\n",
      "        -3.04724455e-01, -2.31534168e-01,  3.28948706e-01,\n",
      "        -4.86380517e-01],\n",
      "       [ 5.78631341e-01,  3.83194357e-01, -1.26541972e-01,\n",
      "        -2.66381323e-01,  3.27956676e-02,  5.43144383e-02,\n",
      "         4.82974738e-01,  5.17196178e-01,  5.06010532e-01,\n",
      "         4.77739006e-01,  4.98795539e-01,  1.94583744e-01,\n",
      "         3.69026542e-01, -2.91935891e-01, -3.52838218e-01,\n",
      "        -1.40035614e-01,  2.54224420e-01,  2.34836638e-01,\n",
      "        -4.51614857e-01,  3.16347778e-02, -3.37115288e-01,\n",
      "         1.79906338e-01, -1.78136900e-01,  3.89003724e-01,\n",
      "         2.55985588e-01, -1.24608278e-01, -3.60917181e-01,\n",
      "         6.34389073e-02],\n",
      "       [-7.00663403e-02, -1.16769873e-01, -2.84527212e-01,\n",
      "         7.91354999e-02, -4.99170795e-02,  2.44601414e-01,\n",
      "        -1.33927122e-01, -2.09446728e-01,  1.38856933e-01,\n",
      "        -5.22934914e-01, -1.24436058e-01,  2.80606244e-02,\n",
      "         9.49961841e-02, -2.33181149e-01,  2.78108150e-01,\n",
      "        -2.21399218e-01, -2.97612280e-01, -1.85753047e-01,\n",
      "         3.33293974e-01,  8.84348676e-02,  2.32491791e-01,\n",
      "        -4.64528948e-01,  2.70941872e-02,  2.72738584e-03,\n",
      "         4.04694170e-01, -2.34915480e-01,  4.65842098e-01,\n",
      "         7.17375576e-02],\n",
      "       [-4.32530455e-02, -3.15117925e-01, -9.53524373e-03,\n",
      "        -1.95593104e-01,  3.54377478e-01, -2.08317742e-01,\n",
      "         2.58230686e-01, -6.86116815e-02,  2.00290382e-02,\n",
      "        -9.68812704e-02, -1.95816472e-01,  1.18689358e-01,\n",
      "        -1.65807709e-01, -4.12377626e-01, -2.62797207e-01,\n",
      "        -2.02075005e-01,  5.64898193e-01, -4.43377465e-01,\n",
      "        -1.23033047e-01,  9.14041996e-02, -2.22891048e-01,\n",
      "        -2.63196439e-01,  9.72255599e-03,  5.61067462e-01,\n",
      "         5.05848527e-01,  7.77556375e-02, -1.32539421e-01,\n",
      "         1.37143761e-01],\n",
      "       [-1.08435966e-01, -2.30338916e-01,  1.39048308e-01,\n",
      "        -3.62707734e-01, -3.38495135e-01, -3.80305231e-01,\n",
      "        -1.88854396e-01,  2.90873572e-02,  5.99741563e-02,\n",
      "        -4.28523034e-01, -1.89913496e-01, -1.05810642e-01,\n",
      "        -5.30244350e-01,  4.31850553e-01, -1.62603319e-01,\n",
      "        -5.79150140e-01,  1.37583435e-01, -4.65851516e-01,\n",
      "         2.74436306e-02,  4.25907612e-01, -5.11503339e-01,\n",
      "        -2.52375901e-01, -1.05058625e-01, -4.15247738e-01,\n",
      "         8.24870616e-02, -1.63390964e-01, -5.39280325e-02,\n",
      "         5.79456426e-02],\n",
      "       [ 1.22684747e-01, -6.35419711e-02, -2.46261567e-01,\n",
      "         1.09515548e-01,  3.39065194e-02, -1.95272714e-01,\n",
      "         2.04199836e-01, -1.49815768e-01,  3.15509201e-03,\n",
      "        -2.91406102e-02,  3.17404531e-02, -3.56698692e-01,\n",
      "        -1.35408968e-01,  2.49055833e-01,  2.90184561e-02,\n",
      "         5.17242067e-02,  1.13354810e-01,  4.87845033e-01,\n",
      "        -1.64727047e-01,  1.02853104e-01,  4.42045331e-02,\n",
      "        -2.17613757e-01, -3.12215179e-01, -1.59782141e-01,\n",
      "        -1.94636211e-01, -3.09918851e-01,  2.37615988e-01,\n",
      "         3.53264689e-01],\n",
      "       [-2.13323161e-02,  3.07672501e-01, -7.36089842e-03,\n",
      "        -1.11174121e-01, -2.38585681e-01, -4.56222981e-01,\n",
      "        -3.91463697e-01, -4.71174777e-01,  2.50709534e-01,\n",
      "        -7.59878196e-03,  2.71257311e-01, -4.44524735e-01,\n",
      "         1.40254691e-01, -3.46428335e-01, -4.05202985e-01,\n",
      "        -4.53369021e-02, -5.33927642e-02, -1.08700782e-01,\n",
      "        -1.43795207e-01,  1.77083045e-01, -1.44423470e-01,\n",
      "         4.31161076e-02, -1.14247106e-01,  2.27480620e-01,\n",
      "         1.09120384e-01, -3.72583956e-01, -7.68049806e-02,\n",
      "        -1.59927040e-01],\n",
      "       [ 2.39582375e-01, -4.58933741e-01, -7.59143010e-02,\n",
      "        -4.36997443e-01, -1.60933405e-01, -2.53072649e-01,\n",
      "         7.64456168e-02,  4.66332078e-01,  4.33187932e-01,\n",
      "         1.76469702e-02, -3.85073662e-01, -5.56657612e-02,\n",
      "        -1.30498767e-01,  3.20540696e-01, -2.05394804e-01,\n",
      "        -2.88621396e-01, -6.39811531e-02,  4.07962888e-01,\n",
      "         1.26024529e-01,  7.49838725e-02,  2.94384778e-01,\n",
      "         8.64776783e-03, -1.58792764e-01, -1.66258559e-01,\n",
      "         1.48121387e-01, -3.96155685e-01,  5.10397673e-01,\n",
      "        -2.44772285e-01],\n",
      "       [-1.59837723e-01, -2.69901007e-01,  1.42191583e-02,\n",
      "         5.06142974e-01, -1.60127074e-01,  2.55415440e-01,\n",
      "        -5.04906118e-01,  5.42940259e-01,  1.62203405e-02,\n",
      "        -3.54646802e-01, -2.15493202e-01, -3.23950917e-01,\n",
      "         5.80535382e-02, -3.07535321e-01, -5.48009202e-03,\n",
      "         2.07922459e-01,  3.01807076e-01, -4.86283600e-01,\n",
      "        -9.00020972e-02, -1.92996308e-01,  3.90145481e-01,\n",
      "         3.31626713e-01,  2.48839185e-01,  1.08055495e-01,\n",
      "        -1.51779041e-01, -4.48096335e-01, -2.61455894e-01,\n",
      "         3.79316160e-03],\n",
      "       [ 2.68437564e-01,  2.83526510e-01, -1.24054328e-01,\n",
      "         2.35384945e-02,  1.81783840e-01,  1.30032837e-01,\n",
      "         2.04133883e-01, -4.86797482e-01, -9.72076729e-02,\n",
      "         4.17733788e-01, -1.80702150e-01,  2.34154299e-01,\n",
      "        -4.09528911e-02, -2.95224905e-01, -2.30750397e-01,\n",
      "        -1.33639276e-01,  1.87121436e-01, -1.25967696e-01,\n",
      "         3.05866152e-01,  2.92807162e-01,  8.84929597e-02,\n",
      "        -3.59970368e-02,  1.14959374e-01,  2.62947101e-02,\n",
      "         4.05465990e-01, -2.97417939e-01, -6.99484795e-02,\n",
      "        -3.34441572e-01]], dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), array([[ 1.59380034e-01, -3.17921162e-01,  3.43911834e-02,\n",
      "         1.75062403e-01,  4.79949892e-01,  1.05367057e-01,\n",
      "         1.03275724e-01, -4.59015854e-02, -2.28500903e-01,\n",
      "        -6.81354851e-02,  3.19919974e-01, -3.28304142e-01],\n",
      "       [-2.62856692e-01,  5.50808370e-01, -2.70704359e-01,\n",
      "        -3.24992239e-01,  2.45247602e-01, -1.99448928e-01,\n",
      "        -2.28060596e-02, -5.82628064e-02,  9.79065523e-02,\n",
      "         1.90515369e-01,  5.11840582e-01,  1.31878018e-01],\n",
      "       [ 5.00233650e-01, -4.74734306e-01, -1.30648553e-01,\n",
      "        -1.78608149e-02, -2.75693208e-01,  7.75492415e-02,\n",
      "         1.03899091e-01,  3.37948918e-01, -1.43994018e-01,\n",
      "        -3.84332798e-02,  3.04785818e-01, -8.90987217e-02],\n",
      "       [-2.28613600e-01,  1.37555122e-01,  3.45454067e-01,\n",
      "        -4.02972847e-01,  3.97259772e-01, -8.31506029e-02,\n",
      "        -1.57605987e-02,  4.83796209e-01,  4.25250232e-02,\n",
      "         8.66899714e-02,  2.42619991e-01,  2.35245749e-01],\n",
      "       [-5.10106921e-01, -4.08114523e-01,  5.96267134e-02,\n",
      "        -2.19765574e-01,  5.31903744e-01,  6.00769930e-02,\n",
      "         1.18441522e-01,  2.05967382e-01, -8.24232027e-02,\n",
      "         8.97312313e-02, -2.12197155e-01,  2.52558738e-01],\n",
      "       [-1.90094575e-01,  5.08894563e-01, -3.46541554e-02,\n",
      "         3.00684404e-02, -3.81406844e-01,  1.02560095e-01,\n",
      "        -9.37273651e-02,  5.16825736e-01, -5.34994364e-01,\n",
      "         3.83135468e-01, -7.07278624e-02,  5.82114160e-01],\n",
      "       [-2.36229420e-01,  4.56566274e-01, -4.51833487e-01,\n",
      "        -2.70105779e-01, -8.71500522e-02,  4.18108404e-02,\n",
      "        -1.16358690e-01,  1.90552890e-01, -2.29310438e-01,\n",
      "         8.97144154e-02,  2.74282396e-01,  3.29124361e-01],\n",
      "       [ 1.41345724e-01,  7.43268058e-02,  1.02169186e-01,\n",
      "         5.56133151e-01,  8.63121226e-02,  4.94034290e-01,\n",
      "        -5.97057678e-02,  4.84708667e-01, -5.25609732e-01,\n",
      "        -2.71399707e-01, -2.89950699e-01,  4.81104515e-02],\n",
      "       [-4.86413762e-02,  6.43951967e-02,  6.59097284e-02,\n",
      "        -3.42966497e-01,  2.77066112e-01, -2.87660398e-02,\n",
      "         2.40417555e-01,  4.54198182e-01, -2.64750980e-02,\n",
      "        -3.53550136e-01,  2.23635696e-02, -2.02956274e-01],\n",
      "       [ 1.88568547e-01,  4.69784409e-01, -1.73290968e-01,\n",
      "        -1.03855588e-01, -3.81752610e-01,  1.69677977e-02,\n",
      "        -1.89034805e-01, -5.03876656e-02, -9.16552395e-02,\n",
      "         9.20038391e-03,  3.30742627e-01, -3.65263164e-01],\n",
      "       [-1.30059570e-01, -1.73521593e-01, -3.98287654e-01,\n",
      "        -1.01163805e-01, -8.69145021e-02,  1.19991735e-01,\n",
      "        -9.79313627e-02,  4.74773735e-01,  1.84956416e-01,\n",
      "        -1.25732541e-01, -1.07437484e-02,  2.19133377e-01],\n",
      "       [ 1.51439324e-01,  1.45592868e-01,  9.48149487e-02,\n",
      "         1.47422761e-01, -2.75779605e-01, -1.64502993e-01,\n",
      "         3.09430212e-01,  2.72406340e-02,  1.83944359e-01,\n",
      "        -4.96231228e-01, -7.38896951e-02, -3.27997804e-02],\n",
      "       [-3.80624294e-01,  2.89580643e-01, -2.37983055e-02,\n",
      "        -1.23290077e-01,  4.69512135e-01, -2.61095822e-01,\n",
      "        -1.20009020e-01, -2.91139364e-01,  4.67204630e-01,\n",
      "        -9.44930017e-02,  5.63328207e-01,  5.30817688e-01],\n",
      "       [-1.74430847e-01,  6.09819666e-02,  3.64178978e-02,\n",
      "        -6.59051677e-03,  2.05801383e-01, -9.10536423e-02,\n",
      "        -2.90049613e-01,  3.95576298e-01,  1.35878459e-01,\n",
      "         8.18548128e-02,  3.26578975e-01,  6.34720176e-02],\n",
      "       [ 3.31855714e-01,  1.21455759e-01,  5.16000509e-01,\n",
      "        -3.72535527e-01, -1.71478808e-01, -4.82535869e-01,\n",
      "        -1.36922449e-01,  3.26939315e-01, -5.51968098e-01,\n",
      "        -4.32607830e-01, -1.92295104e-01,  4.06368136e-01],\n",
      "       [ 1.56037003e-01,  4.94259357e-01, -4.83734071e-01,\n",
      "        -1.20619245e-01, -2.76191622e-01,  3.69513780e-01,\n",
      "        -2.68267304e-01, -5.74271202e-01, -2.80355006e-01,\n",
      "         4.27751429e-02,  4.21862900e-01, -3.69418740e-01],\n",
      "       [ 1.49478957e-01, -3.30565363e-01, -3.88662010e-01,\n",
      "        -4.56705660e-01,  5.52248992e-02, -1.86115101e-01,\n",
      "         4.25813466e-01, -5.14096379e-01,  5.84740080e-02,\n",
      "         5.20677790e-02, -3.66746704e-03, -4.37949508e-01],\n",
      "       [-2.67914623e-01,  2.84987777e-01, -5.12614369e-01,\n",
      "        -3.10163110e-01, -4.47727233e-01, -4.75737482e-01,\n",
      "         7.14104697e-02, -3.31827164e-01, -2.98559099e-01,\n",
      "        -2.07614869e-01,  3.42453450e-01,  2.40513563e-01],\n",
      "       [-1.59270555e-01, -3.65208089e-01, -2.12567061e-01,\n",
      "        -1.55243039e-01,  1.70338124e-01,  3.10730040e-01,\n",
      "        -2.51998633e-01, -1.58293590e-01,  6.40386567e-02,\n",
      "        -1.91439614e-01, -1.67499945e-01,  2.59639978e-01],\n",
      "       [-1.19669132e-01,  2.82439053e-01, -1.24549598e-01,\n",
      "         2.70216763e-01, -3.47258449e-01, -2.45027944e-01,\n",
      "        -8.14314410e-02, -3.73572693e-03,  1.51438102e-01,\n",
      "        -1.11097962e-01,  5.58160365e-01,  2.84534574e-01],\n",
      "       [-2.22217124e-02,  5.42855978e-01,  8.30589756e-02,\n",
      "        -5.54258883e-01, -4.30320174e-01, -3.09212059e-02,\n",
      "        -1.33149981e-01,  3.30715388e-01, -2.09016338e-01,\n",
      "         3.86061490e-01,  4.01278228e-01,  4.34638262e-01],\n",
      "       [ 6.06546462e-01, -4.65596914e-01, -2.03971580e-01,\n",
      "         8.62964168e-02,  4.11026210e-01, -3.59843578e-03,\n",
      "        -2.63345629e-01, -2.39710703e-01,  8.76295716e-02,\n",
      "        -2.62601703e-01,  8.69445503e-02,  1.38336226e-01],\n",
      "       [ 3.32255244e-01,  2.18816638e-01, -5.86289883e-01,\n",
      "        -4.07326669e-01,  3.20764966e-02, -2.52326548e-01,\n",
      "         1.54546723e-01,  6.02895208e-02,  2.40814731e-01,\n",
      "        -5.93589783e-01, -3.71754318e-02, -2.89878219e-01],\n",
      "       [ 2.15012580e-01,  1.07083559e-01, -4.17885184e-01,\n",
      "        -2.93547183e-01, -4.80862483e-02, -2.89783746e-01,\n",
      "         3.41929728e-04,  4.78059128e-02,  1.44294679e-01,\n",
      "         4.88060653e-01,  1.47401011e-02,  7.14290664e-02],\n",
      "       [-8.35440531e-02,  5.17719835e-02,  9.74272788e-02,\n",
      "         4.09101844e-01, -1.92731336e-01,  1.42651787e-02,\n",
      "         3.08393184e-02,  3.22054178e-01,  5.88390827e-01,\n",
      "         2.51205385e-01,  8.38382319e-02, -4.87519324e-01],\n",
      "       [-1.19083405e-01, -2.27192968e-01,  5.69135129e-01,\n",
      "         5.74011803e-02, -1.81580126e-01,  2.71585584e-01,\n",
      "        -7.81663731e-02,  2.12894708e-01, -3.46754432e-01,\n",
      "         2.43856668e-01,  1.63445055e-01, -9.98192281e-02],\n",
      "       [-7.89183658e-03, -3.11427802e-01,  1.71666771e-01,\n",
      "         8.21382701e-02,  2.20780954e-01,  5.50835311e-01,\n",
      "         3.17059427e-01, -1.25331268e-01, -1.91936523e-01,\n",
      "        -2.62881637e-01,  3.60698998e-01, -7.17453957e-02],\n",
      "       [ 1.42572194e-01, -1.10471368e-01, -4.70248284e-03,\n",
      "         9.80733261e-02, -4.96421725e-01, -4.03762728e-01,\n",
      "        -2.99540982e-02,  9.05859694e-02, -5.48858404e-01,\n",
      "         2.00311229e-01, -1.83990419e-01, -4.18396652e-01]], dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), array([[-0.18591543, -0.05438626,  0.5672398 , -0.04683581,  0.09020757,\n",
      "         0.75269794,  0.4880231 , -0.26199743,  0.02413114],\n",
      "       [-0.3054414 ,  0.5815166 ,  0.1643585 ,  0.09009662, -0.20085052,\n",
      "         0.43415132, -0.5938308 , -0.12490503, -0.20031424],\n",
      "       [-0.5478914 , -0.11527622, -0.21255971,  0.03896037,  0.43986714,\n",
      "         0.08804998, -0.2616009 ,  0.3046736 ,  0.12654753],\n",
      "       [ 0.07647693, -0.7325855 ,  0.6367199 , -0.22748144,  0.26725897,\n",
      "         0.31280732,  0.08320747,  0.5450593 ,  0.04971839],\n",
      "       [ 0.5051068 , -0.10874564,  0.19159587, -0.24038565, -0.04384996,\n",
      "         0.5422078 ,  0.24189682,  0.11193389, -0.0079811 ],\n",
      "       [-0.38037223, -0.32477292, -0.1683289 ,  0.6869695 ,  0.48788732,\n",
      "        -0.37150422, -0.04021512, -0.6627038 , -0.14743035],\n",
      "       [-0.2051416 , -0.51061505,  0.68715745, -0.12366504,  0.61410135,\n",
      "         0.26864502,  0.32308975,  0.43537706, -0.32626998],\n",
      "       [-0.8280053 ,  0.0682731 , -0.16629227, -0.596494  , -0.46700412,\n",
      "         0.4135095 , -0.25393254, -0.64385146, -0.27255997],\n",
      "       [-0.07396316,  0.8089807 , -0.6279884 , -0.3351682 , -0.26564312,\n",
      "        -0.26295874, -0.2258919 , -0.83262205, -0.8862251 ],\n",
      "       [ 0.23651008,  0.5403976 , -0.50874627, -0.07349731, -0.50694215,\n",
      "        -0.07112612,  0.00301181,  0.1199022 , -0.3243036 ],\n",
      "       [ 0.18981184, -0.2287397 , -0.28808498, -0.22999068,  0.35110807,\n",
      "         0.22914541,  0.84464705,  0.02256638,  0.04064518],\n",
      "       [ 0.2793802 , -0.2803426 ,  0.12875077,  0.53992784,  0.2591446 ,\n",
      "         0.19277771,  0.3007171 , -0.07565717,  0.84102565]],\n",
      "      dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), array([[-0.22580394, -0.34746414],\n",
      "       [ 0.18600833,  0.19345008],\n",
      "       [ 0.8828188 ,  0.6146183 ],\n",
      "       [-0.5837615 ,  0.11248893],\n",
      "       [ 0.21684735,  0.30770835],\n",
      "       [-0.8047218 ,  0.14766905],\n",
      "       [-0.76760876, -0.20078054],\n",
      "       [ 0.5936355 ,  0.5624655 ],\n",
      "       [ 0.26337847, -0.00813245]], dtype=float32), array([0., 0.], dtype=float32)]\n",
      "(423, 30)\n",
      "(423, 2)\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "423/423 [==============================] - 1s 1ms/step - loss: 0.7191 - mean_absolute_error: 0.6367\n",
      "Epoch 2/200\n",
      "423/423 [==============================] - 0s 267us/step - loss: 0.3387 - mean_absolute_error: 0.4509\n",
      "Epoch 3/200\n",
      "423/423 [==============================] - 0s 284us/step - loss: 0.2510 - mean_absolute_error: 0.3767\n",
      "Epoch 4/200\n",
      "423/423 [==============================] - 0s 294us/step - loss: 0.1859 - mean_absolute_error: 0.3306\n",
      "Epoch 5/200\n",
      "423/423 [==============================] - 0s 287us/step - loss: 0.1405 - mean_absolute_error: 0.2841\n",
      "Epoch 6/200\n",
      "423/423 [==============================] - 0s 284us/step - loss: 0.1225 - mean_absolute_error: 0.2663\n",
      "Epoch 7/200\n",
      "423/423 [==============================] - 0s 276us/step - loss: 0.1028 - mean_absolute_error: 0.2401\n",
      "Epoch 8/200\n",
      "423/423 [==============================] - 0s 274us/step - loss: 0.0818 - mean_absolute_error: 0.2208\n",
      "Epoch 9/200\n",
      "423/423 [==============================] - 0s 275us/step - loss: 0.0696 - mean_absolute_error: 0.1964\n",
      "Epoch 10/200\n",
      "423/423 [==============================] - 0s 261us/step - loss: 0.0654 - mean_absolute_error: 0.1880\n",
      "Epoch 11/200\n",
      "423/423 [==============================] - 0s 272us/step - loss: 0.0659 - mean_absolute_error: 0.1897\n",
      "Epoch 12/200\n",
      "423/423 [==============================] - 0s 274us/step - loss: 0.0571 - mean_absolute_error: 0.1745\n",
      "Epoch 13/200\n",
      "423/423 [==============================] - 0s 268us/step - loss: 0.0508 - mean_absolute_error: 0.1656\n",
      "Epoch 14/200\n",
      "423/423 [==============================] - 0s 263us/step - loss: 0.0492 - mean_absolute_error: 0.1629\n",
      "Epoch 15/200\n",
      "423/423 [==============================] - 0s 262us/step - loss: 0.0453 - mean_absolute_error: 0.1552\n",
      "Epoch 16/200\n",
      "423/423 [==============================] - 0s 259us/step - loss: 0.0388 - mean_absolute_error: 0.1433\n",
      "Epoch 17/200\n",
      "423/423 [==============================] - 0s 264us/step - loss: 0.0382 - mean_absolute_error: 0.1359\n",
      "Epoch 18/200\n",
      "423/423 [==============================] - 0s 264us/step - loss: 0.0378 - mean_absolute_error: 0.1404\n",
      "Epoch 19/200\n",
      "423/423 [==============================] - 0s 297us/step - loss: 0.0363 - mean_absolute_error: 0.1324\n",
      "Epoch 20/200\n",
      "423/423 [==============================] - 0s 296us/step - loss: 0.0349 - mean_absolute_error: 0.1283\n",
      "Epoch 21/200\n",
      "423/423 [==============================] - 0s 288us/step - loss: 0.0348 - mean_absolute_error: 0.1293\n",
      "Epoch 22/200\n",
      "423/423 [==============================] - 0s 286us/step - loss: 0.0325 - mean_absolute_error: 0.1258\n",
      "Epoch 23/200\n",
      "423/423 [==============================] - 0s 276us/step - loss: 0.0307 - mean_absolute_error: 0.1161\n",
      "Epoch 24/200\n",
      "423/423 [==============================] - 0s 270us/step - loss: 0.0317 - mean_absolute_error: 0.1204\n",
      "Epoch 25/200\n",
      "423/423 [==============================] - 0s 267us/step - loss: 0.0279 - mean_absolute_error: 0.1088\n",
      "Epoch 26/200\n",
      "423/423 [==============================] - 0s 263us/step - loss: 0.0282 - mean_absolute_error: 0.1086\n",
      "Epoch 27/200\n",
      "423/423 [==============================] - 0s 262us/step - loss: 0.0270 - mean_absolute_error: 0.1056\n",
      "Epoch 28/200\n",
      "423/423 [==============================] - 0s 265us/step - loss: 0.0251 - mean_absolute_error: 0.1048\n",
      "Epoch 29/200\n",
      "423/423 [==============================] - 0s 268us/step - loss: 0.0259 - mean_absolute_error: 0.1037\n",
      "Epoch 30/200\n",
      "423/423 [==============================] - 0s 279us/step - loss: 0.0240 - mean_absolute_error: 0.0995\n",
      "Epoch 31/200\n",
      "423/423 [==============================] - 0s 290us/step - loss: 0.0236 - mean_absolute_error: 0.0977\n",
      "Epoch 32/200\n",
      "423/423 [==============================] - 0s 296us/step - loss: 0.0248 - mean_absolute_error: 0.1003\n",
      "Epoch 33/200\n",
      "423/423 [==============================] - 0s 294us/step - loss: 0.0235 - mean_absolute_error: 0.0956\n",
      "Epoch 34/200\n",
      "423/423 [==============================] - 0s 297us/step - loss: 0.0241 - mean_absolute_error: 0.0976\n",
      "Epoch 35/200\n",
      "423/423 [==============================] - 0s 294us/step - loss: 0.0222 - mean_absolute_error: 0.0899\n",
      "Epoch 36/200\n",
      "423/423 [==============================] - 0s 297us/step - loss: 0.0236 - mean_absolute_error: 0.0960\n",
      "Epoch 37/200\n",
      "423/423 [==============================] - 0s 313us/step - loss: 0.0238 - mean_absolute_error: 0.0939\n",
      "Epoch 38/200\n",
      "423/423 [==============================] - 0s 282us/step - loss: 0.0226 - mean_absolute_error: 0.0916\n",
      "Epoch 39/200\n",
      "423/423 [==============================] - 0s 276us/step - loss: 0.0232 - mean_absolute_error: 0.0898\n",
      "Epoch 40/200\n",
      "423/423 [==============================] - 0s 267us/step - loss: 0.0227 - mean_absolute_error: 0.0903\n",
      "Epoch 41/200\n",
      "423/423 [==============================] - 0s 268us/step - loss: 0.0216 - mean_absolute_error: 0.0890\n",
      "Epoch 42/200\n",
      "423/423 [==============================] - 0s 263us/step - loss: 0.0209 - mean_absolute_error: 0.0869\n",
      "Epoch 43/200\n",
      "423/423 [==============================] - 0s 270us/step - loss: 0.0216 - mean_absolute_error: 0.0882\n",
      "Epoch 44/200\n",
      "423/423 [==============================] - 0s 275us/step - loss: 0.0211 - mean_absolute_error: 0.0851\n",
      "Epoch 45/200\n",
      "423/423 [==============================] - 0s 313us/step - loss: 0.0198 - mean_absolute_error: 0.0824\n",
      "Epoch 46/200\n",
      "423/423 [==============================] - 0s 301us/step - loss: 0.0200 - mean_absolute_error: 0.0820\n",
      "Epoch 47/200\n",
      "423/423 [==============================] - 0s 267us/step - loss: 0.0196 - mean_absolute_error: 0.0829\n",
      "Epoch 48/200\n",
      "423/423 [==============================] - 0s 276us/step - loss: 0.0203 - mean_absolute_error: 0.0849\n",
      "Epoch 49/200\n",
      "423/423 [==============================] - 0s 272us/step - loss: 0.0212 - mean_absolute_error: 0.0843\n",
      "Epoch 50/200\n",
      "423/423 [==============================] - 0s 279us/step - loss: 0.0200 - mean_absolute_error: 0.0836\n",
      "Epoch 51/200\n",
      "423/423 [==============================] - 0s 286us/step - loss: 0.0197 - mean_absolute_error: 0.0823\n",
      "Epoch 52/200\n",
      "423/423 [==============================] - 0s 274us/step - loss: 0.0199 - mean_absolute_error: 0.0815\n",
      "Epoch 53/200\n",
      "423/423 [==============================] - 0s 261us/step - loss: 0.0194 - mean_absolute_error: 0.0805\n",
      "Epoch 54/200\n",
      "423/423 [==============================] - 0s 281us/step - loss: 0.0197 - mean_absolute_error: 0.0788\n",
      "Epoch 55/200\n",
      "423/423 [==============================] - 0s 275us/step - loss: 0.0183 - mean_absolute_error: 0.0765\n",
      "Epoch 56/200\n",
      "423/423 [==============================] - 0s 290us/step - loss: 0.0187 - mean_absolute_error: 0.0759\n",
      "Epoch 57/200\n",
      "423/423 [==============================] - 0s 353us/step - loss: 0.0191 - mean_absolute_error: 0.0812\n",
      "Epoch 58/200\n",
      "423/423 [==============================] - 0s 410us/step - loss: 0.0186 - mean_absolute_error: 0.0776\n",
      "Epoch 59/200\n",
      "423/423 [==============================] - 0s 272us/step - loss: 0.0176 - mean_absolute_error: 0.0751\n",
      "Epoch 60/200\n",
      "423/423 [==============================] - 0s 260us/step - loss: 0.0195 - mean_absolute_error: 0.0777\n",
      "Epoch 61/200\n",
      "423/423 [==============================] - 0s 272us/step - loss: 0.0174 - mean_absolute_error: 0.0749\n",
      "Epoch 62/200\n",
      "423/423 [==============================] - 0s 269us/step - loss: 0.0182 - mean_absolute_error: 0.0751\n",
      "Epoch 63/200\n",
      "423/423 [==============================] - 0s 269us/step - loss: 0.0186 - mean_absolute_error: 0.0766\n",
      "Epoch 64/200\n",
      "423/423 [==============================] - 0s 273us/step - loss: 0.0183 - mean_absolute_error: 0.0749\n",
      "Epoch 65/200\n",
      "423/423 [==============================] - 0s 269us/step - loss: 0.0181 - mean_absolute_error: 0.0734\n",
      "Epoch 66/200\n",
      "423/423 [==============================] - 0s 277us/step - loss: 0.0177 - mean_absolute_error: 0.0717\n",
      "Epoch 67/200\n",
      "423/423 [==============================] - 0s 271us/step - loss: 0.0173 - mean_absolute_error: 0.0730\n",
      "Epoch 68/200\n",
      "423/423 [==============================] - 0s 272us/step - loss: 0.0179 - mean_absolute_error: 0.0756\n",
      "Epoch 69/200\n",
      "423/423 [==============================] - 0s 267us/step - loss: 0.0175 - mean_absolute_error: 0.0721\n",
      "Epoch 70/200\n",
      "423/423 [==============================] - 0s 263us/step - loss: 0.0164 - mean_absolute_error: 0.0702\n",
      "Epoch 71/200\n",
      "423/423 [==============================] - 0s 272us/step - loss: 0.0180 - mean_absolute_error: 0.0742\n",
      "Epoch 72/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "423/423 [==============================] - 0s 282us/step - loss: 0.0168 - mean_absolute_error: 0.0710\n",
      "Epoch 73/200\n",
      "423/423 [==============================] - 0s 317us/step - loss: 0.0169 - mean_absolute_error: 0.0703\n",
      "Epoch 74/200\n",
      "423/423 [==============================] - 0s 349us/step - loss: 0.0165 - mean_absolute_error: 0.0710\n",
      "Epoch 75/200\n",
      "423/423 [==============================] - 0s 315us/step - loss: 0.0162 - mean_absolute_error: 0.0699\n",
      "Epoch 76/200\n",
      "423/423 [==============================] - 0s 264us/step - loss: 0.0166 - mean_absolute_error: 0.0702\n",
      "Epoch 77/200\n",
      "423/423 [==============================] - 0s 270us/step - loss: 0.0159 - mean_absolute_error: 0.0686\n",
      "Epoch 78/200\n",
      "423/423 [==============================] - 0s 262us/step - loss: 0.0170 - mean_absolute_error: 0.0683\n",
      "Epoch 79/200\n",
      "423/423 [==============================] - 0s 263us/step - loss: 0.0155 - mean_absolute_error: 0.0670\n",
      "Epoch 80/200\n",
      "423/423 [==============================] - 0s 267us/step - loss: 0.0159 - mean_absolute_error: 0.0709\n",
      "Epoch 81/200\n",
      "423/423 [==============================] - 0s 270us/step - loss: 0.0155 - mean_absolute_error: 0.0664\n",
      "Epoch 82/200\n",
      "423/423 [==============================] - 0s 266us/step - loss: 0.0158 - mean_absolute_error: 0.0686\n",
      "Epoch 83/200\n",
      "423/423 [==============================] - 0s 271us/step - loss: 0.0150 - mean_absolute_error: 0.0638\n",
      "Epoch 84/200\n",
      "423/423 [==============================] - 0s 262us/step - loss: 0.0147 - mean_absolute_error: 0.0647\n",
      "Epoch 85/200\n",
      "423/423 [==============================] - 0s 270us/step - loss: 0.0164 - mean_absolute_error: 0.0674\n",
      "Epoch 86/200\n",
      "423/423 [==============================] - 0s 266us/step - loss: 0.0149 - mean_absolute_error: 0.0654\n",
      "Epoch 87/200\n",
      "423/423 [==============================] - 0s 275us/step - loss: 0.0151 - mean_absolute_error: 0.0644\n",
      "Epoch 88/200\n",
      "423/423 [==============================] - 0s 271us/step - loss: 0.0156 - mean_absolute_error: 0.0681\n",
      "Epoch 89/200\n",
      "423/423 [==============================] - 0s 259us/step - loss: 0.0160 - mean_absolute_error: 0.0661\n",
      "Epoch 90/200\n",
      "423/423 [==============================] - 0s 263us/step - loss: 0.0145 - mean_absolute_error: 0.0657\n",
      "Epoch 91/200\n",
      "423/423 [==============================] - 0s 265us/step - loss: 0.0158 - mean_absolute_error: 0.0667\n",
      "Epoch 92/200\n",
      "423/423 [==============================] - 0s 270us/step - loss: 0.0147 - mean_absolute_error: 0.0648\n",
      "Epoch 93/200\n",
      "423/423 [==============================] - 0s 278us/step - loss: 0.0135 - mean_absolute_error: 0.0613\n",
      "Epoch 94/200\n",
      "423/423 [==============================] - 0s 280us/step - loss: 0.0142 - mean_absolute_error: 0.0634\n",
      "Epoch 95/200\n",
      "423/423 [==============================] - 0s 265us/step - loss: 0.0149 - mean_absolute_error: 0.0660\n",
      "Epoch 96/200\n",
      "423/423 [==============================] - 0s 261us/step - loss: 0.0144 - mean_absolute_error: 0.0630\n",
      "Epoch 97/200\n",
      "423/423 [==============================] - 0s 264us/step - loss: 0.0137 - mean_absolute_error: 0.0622\n",
      "Epoch 98/200\n",
      "423/423 [==============================] - 0s 269us/step - loss: 0.0143 - mean_absolute_error: 0.0632\n",
      "Epoch 99/200\n",
      "423/423 [==============================] - 0s 268us/step - loss: 0.0144 - mean_absolute_error: 0.0644\n",
      "Epoch 100/200\n",
      "423/423 [==============================] - 0s 269us/step - loss: 0.0142 - mean_absolute_error: 0.0640\n",
      "Epoch 101/200\n",
      "423/423 [==============================] - 0s 264us/step - loss: 0.0135 - mean_absolute_error: 0.0603\n",
      "Epoch 102/200\n",
      "423/423 [==============================] - 0s 268us/step - loss: 0.0138 - mean_absolute_error: 0.0632\n",
      "Epoch 103/200\n",
      "423/423 [==============================] - 0s 269us/step - loss: 0.0136 - mean_absolute_error: 0.0594\n",
      "Epoch 104/200\n",
      "423/423 [==============================] - 0s 272us/step - loss: 0.0140 - mean_absolute_error: 0.0604\n",
      "Epoch 105/200\n",
      "423/423 [==============================] - 0s 268us/step - loss: 0.0131 - mean_absolute_error: 0.0602\n",
      "Epoch 106/200\n",
      "423/423 [==============================] - 0s 267us/step - loss: 0.0142 - mean_absolute_error: 0.0598\n",
      "Epoch 107/200\n",
      "423/423 [==============================] - 0s 268us/step - loss: 0.0124 - mean_absolute_error: 0.0581\n",
      "Epoch 108/200\n",
      "423/423 [==============================] - 0s 267us/step - loss: 0.0127 - mean_absolute_error: 0.0587\n",
      "Epoch 109/200\n",
      "423/423 [==============================] - 0s 262us/step - loss: 0.0125 - mean_absolute_error: 0.0590\n",
      "Epoch 110/200\n",
      "423/423 [==============================] - 0s 265us/step - loss: 0.0128 - mean_absolute_error: 0.0589\n",
      "Epoch 111/200\n",
      "423/423 [==============================] - 0s 273us/step - loss: 0.0126 - mean_absolute_error: 0.0583\n",
      "Epoch 112/200\n",
      "423/423 [==============================] - 0s 264us/step - loss: 0.0128 - mean_absolute_error: 0.0580\n",
      "Epoch 113/200\n",
      "423/423 [==============================] - 0s 266us/step - loss: 0.0125 - mean_absolute_error: 0.0595\n",
      "Epoch 114/200\n",
      "423/423 [==============================] - 0s 270us/step - loss: 0.0119 - mean_absolute_error: 0.0569\n",
      "Epoch 115/200\n",
      "423/423 [==============================] - 0s 274us/step - loss: 0.0133 - mean_absolute_error: 0.0592\n",
      "Epoch 116/200\n",
      "423/423 [==============================] - 0s 265us/step - loss: 0.0128 - mean_absolute_error: 0.0572\n",
      "Epoch 117/200\n",
      "423/423 [==============================] - 0s 262us/step - loss: 0.0126 - mean_absolute_error: 0.0571\n",
      "Epoch 118/200\n",
      "423/423 [==============================] - 0s 265us/step - loss: 0.0134 - mean_absolute_error: 0.0558\n",
      "Epoch 119/200\n",
      "423/423 [==============================] - 0s 273us/step - loss: 0.0127 - mean_absolute_error: 0.0579\n",
      "Epoch 120/200\n",
      "423/423 [==============================] - 0s 262us/step - loss: 0.0117 - mean_absolute_error: 0.0547\n",
      "Epoch 121/200\n",
      "423/423 [==============================] - 0s 266us/step - loss: 0.0117 - mean_absolute_error: 0.0540\n",
      "Epoch 122/200\n",
      "423/423 [==============================] - 0s 269us/step - loss: 0.0110 - mean_absolute_error: 0.0529\n",
      "Epoch 123/200\n",
      "423/423 [==============================] - 0s 268us/step - loss: 0.0122 - mean_absolute_error: 0.0557\n",
      "Epoch 124/200\n",
      "423/423 [==============================] - 0s 265us/step - loss: 0.0115 - mean_absolute_error: 0.0555\n",
      "Epoch 125/200\n",
      "423/423 [==============================] - 0s 272us/step - loss: 0.0124 - mean_absolute_error: 0.0582\n",
      "Epoch 126/200\n",
      "423/423 [==============================] - 0s 267us/step - loss: 0.0125 - mean_absolute_error: 0.0556\n",
      "Epoch 127/200\n",
      "423/423 [==============================] - 0s 276us/step - loss: 0.0118 - mean_absolute_error: 0.0542\n",
      "Epoch 128/200\n",
      "423/423 [==============================] - 0s 264us/step - loss: 0.0121 - mean_absolute_error: 0.0533\n",
      "Epoch 129/200\n",
      "423/423 [==============================] - 0s 266us/step - loss: 0.0119 - mean_absolute_error: 0.0546\n",
      "Epoch 130/200\n",
      "423/423 [==============================] - 0s 276us/step - loss: 0.0124 - mean_absolute_error: 0.0582\n",
      "Epoch 131/200\n",
      "423/423 [==============================] - 0s 271us/step - loss: 0.0119 - mean_absolute_error: 0.0531\n",
      "Epoch 132/200\n",
      "423/423 [==============================] - 0s 261us/step - loss: 0.0111 - mean_absolute_error: 0.0506\n",
      "Epoch 133/200\n",
      "423/423 [==============================] - 0s 263us/step - loss: 0.0122 - mean_absolute_error: 0.0542\n",
      "Epoch 134/200\n",
      "423/423 [==============================] - 0s 268us/step - loss: 0.0114 - mean_absolute_error: 0.0522\n",
      "Epoch 135/200\n",
      "423/423 [==============================] - 0s 266us/step - loss: 0.0116 - mean_absolute_error: 0.0521\n",
      "Epoch 136/200\n",
      "423/423 [==============================] - 0s 268us/step - loss: 0.0115 - mean_absolute_error: 0.0537\n",
      "Epoch 137/200\n",
      "423/423 [==============================] - 0s 264us/step - loss: 0.0122 - mean_absolute_error: 0.0545\n",
      "Epoch 138/200\n",
      "423/423 [==============================] - 0s 263us/step - loss: 0.0119 - mean_absolute_error: 0.0535\n",
      "Epoch 139/200\n",
      "423/423 [==============================] - 0s 272us/step - loss: 0.0116 - mean_absolute_error: 0.0520\n",
      "Epoch 140/200\n",
      "423/423 [==============================] - 0s 269us/step - loss: 0.0108 - mean_absolute_error: 0.0511\n",
      "Epoch 141/200\n",
      "423/423 [==============================] - 0s 325us/step - loss: 0.0110 - mean_absolute_error: 0.0524\n",
      "Epoch 142/200\n",
      "423/423 [==============================] - 0s 329us/step - loss: 0.0116 - mean_absolute_error: 0.0549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 143/200\n",
      "423/423 [==============================] - 0s 327us/step - loss: 0.0116 - mean_absolute_error: 0.0526\n",
      "Epoch 144/200\n",
      "423/423 [==============================] - 0s 274us/step - loss: 0.0113 - mean_absolute_error: 0.0518\n",
      "Epoch 145/200\n",
      "423/423 [==============================] - 0s 321us/step - loss: 0.0116 - mean_absolute_error: 0.0543\n",
      "Epoch 146/200\n",
      "423/423 [==============================] - 0s 269us/step - loss: 0.0119 - mean_absolute_error: 0.0532\n",
      "Epoch 147/200\n",
      "423/423 [==============================] - 0s 262us/step - loss: 0.0109 - mean_absolute_error: 0.0488\n",
      "Epoch 148/200\n",
      "423/423 [==============================] - 0s 258us/step - loss: 0.0109 - mean_absolute_error: 0.0504\n",
      "Epoch 149/200\n",
      "423/423 [==============================] - 0s 261us/step - loss: 0.0109 - mean_absolute_error: 0.0500\n",
      "Epoch 150/200\n",
      "423/423 [==============================] - 0s 264us/step - loss: 0.0112 - mean_absolute_error: 0.0495\n",
      "Epoch 151/200\n",
      "423/423 [==============================] - 0s 259us/step - loss: 0.0109 - mean_absolute_error: 0.0506\n",
      "Epoch 152/200\n",
      "423/423 [==============================] - 0s 263us/step - loss: 0.0114 - mean_absolute_error: 0.0525\n",
      "Epoch 153/200\n",
      "423/423 [==============================] - 0s 265us/step - loss: 0.0111 - mean_absolute_error: 0.0508\n",
      "Epoch 154/200\n",
      "423/423 [==============================] - 0s 267us/step - loss: 0.0121 - mean_absolute_error: 0.0538\n",
      "Epoch 155/200\n",
      "423/423 [==============================] - 0s 264us/step - loss: 0.0110 - mean_absolute_error: 0.0522\n",
      "Epoch 156/200\n",
      "423/423 [==============================] - 0s 264us/step - loss: 0.0113 - mean_absolute_error: 0.0511\n",
      "Epoch 157/200\n",
      "423/423 [==============================] - 0s 267us/step - loss: 0.0109 - mean_absolute_error: 0.0518\n",
      "Epoch 158/200\n",
      "423/423 [==============================] - 0s 261us/step - loss: 0.0113 - mean_absolute_error: 0.0510\n",
      "Epoch 159/200\n",
      "423/423 [==============================] - 0s 264us/step - loss: 0.0105 - mean_absolute_error: 0.0510\n",
      "Epoch 160/200\n",
      "423/423 [==============================] - 0s 267us/step - loss: 0.0115 - mean_absolute_error: 0.0522\n",
      "Epoch 161/200\n",
      "423/423 [==============================] - 0s 264us/step - loss: 0.0119 - mean_absolute_error: 0.0521\n",
      "Epoch 162/200\n",
      "423/423 [==============================] - 0s 268us/step - loss: 0.0105 - mean_absolute_error: 0.0487\n",
      "Epoch 163/200\n",
      "423/423 [==============================] - 0s 302us/step - loss: 0.0103 - mean_absolute_error: 0.0496\n",
      "Epoch 164/200\n",
      "423/423 [==============================] - 0s 310us/step - loss: 0.0102 - mean_absolute_error: 0.0496\n",
      "Epoch 165/200\n",
      "423/423 [==============================] - 0s 263us/step - loss: 0.0105 - mean_absolute_error: 0.0504\n",
      "Epoch 166/200\n",
      "423/423 [==============================] - 0s 260us/step - loss: 0.0099 - mean_absolute_error: 0.0507\n",
      "Epoch 167/200\n",
      "423/423 [==============================] - 0s 261us/step - loss: 0.0100 - mean_absolute_error: 0.0498\n",
      "Epoch 168/200\n",
      "423/423 [==============================] - 0s 266us/step - loss: 0.0111 - mean_absolute_error: 0.0491\n",
      "Epoch 169/200\n",
      "423/423 [==============================] - 0s 268us/step - loss: 0.0103 - mean_absolute_error: 0.0497\n",
      "Epoch 170/200\n",
      "423/423 [==============================] - 0s 267us/step - loss: 0.0110 - mean_absolute_error: 0.0503\n",
      "Epoch 171/200\n",
      "423/423 [==============================] - 0s 273us/step - loss: 0.0107 - mean_absolute_error: 0.0488\n",
      "Epoch 172/200\n",
      "423/423 [==============================] - 0s 267us/step - loss: 0.0105 - mean_absolute_error: 0.0497\n",
      "Epoch 173/200\n",
      "423/423 [==============================] - 0s 266us/step - loss: 0.0109 - mean_absolute_error: 0.0510\n",
      "Epoch 174/200\n",
      "423/423 [==============================] - 0s 268us/step - loss: 0.0099 - mean_absolute_error: 0.0482\n",
      "Epoch 175/200\n",
      "423/423 [==============================] - 0s 267us/step - loss: 0.0098 - mean_absolute_error: 0.0501\n",
      "Epoch 176/200\n",
      "423/423 [==============================] - 0s 267us/step - loss: 0.0099 - mean_absolute_error: 0.0500\n",
      "Epoch 177/200\n",
      "423/423 [==============================] - 0s 267us/step - loss: 0.0102 - mean_absolute_error: 0.0491\n",
      "Epoch 178/200\n",
      "423/423 [==============================] - 0s 263us/step - loss: 0.0120 - mean_absolute_error: 0.0526\n",
      "Epoch 179/200\n",
      "423/423 [==============================] - 0s 263us/step - loss: 0.0103 - mean_absolute_error: 0.0498\n",
      "Epoch 180/200\n",
      "423/423 [==============================] - 0s 264us/step - loss: 0.0104 - mean_absolute_error: 0.0476\n",
      "Epoch 181/200\n",
      "423/423 [==============================] - 0s 267us/step - loss: 0.0115 - mean_absolute_error: 0.0507\n",
      "Epoch 182/200\n",
      "423/423 [==============================] - 0s 266us/step - loss: 0.0104 - mean_absolute_error: 0.0502\n",
      "Epoch 183/200\n",
      "423/423 [==============================] - 0s 278us/step - loss: 0.0104 - mean_absolute_error: 0.0490\n",
      "Epoch 184/200\n",
      "423/423 [==============================] - 0s 268us/step - loss: 0.0109 - mean_absolute_error: 0.0492\n",
      "Epoch 185/200\n",
      "423/423 [==============================] - 0s 262us/step - loss: 0.0099 - mean_absolute_error: 0.0482\n",
      "Epoch 186/200\n",
      "423/423 [==============================] - 0s 268us/step - loss: 0.0103 - mean_absolute_error: 0.0470\n",
      "Epoch 187/200\n",
      "423/423 [==============================] - 0s 266us/step - loss: 0.0100 - mean_absolute_error: 0.0459\n",
      "Epoch 188/200\n",
      "423/423 [==============================] - 0s 266us/step - loss: 0.0109 - mean_absolute_error: 0.0495\n",
      "Epoch 189/200\n",
      "423/423 [==============================] - 0s 267us/step - loss: 0.0104 - mean_absolute_error: 0.0480\n",
      "Epoch 190/200\n",
      "423/423 [==============================] - 0s 268us/step - loss: 0.0096 - mean_absolute_error: 0.0477\n",
      "Epoch 191/200\n",
      "423/423 [==============================] - 0s 274us/step - loss: 0.0098 - mean_absolute_error: 0.0462\n",
      "Epoch 192/200\n",
      "423/423 [==============================] - 0s 278us/step - loss: 0.0102 - mean_absolute_error: 0.0484\n",
      "Epoch 193/200\n",
      "423/423 [==============================] - 0s 268us/step - loss: 0.0096 - mean_absolute_error: 0.0484\n",
      "Epoch 194/200\n",
      "423/423 [==============================] - 0s 261us/step - loss: 0.0097 - mean_absolute_error: 0.0482\n",
      "Epoch 195/200\n",
      "423/423 [==============================] - 0s 266us/step - loss: 0.0114 - mean_absolute_error: 0.0503\n",
      "Epoch 196/200\n",
      "423/423 [==============================] - 0s 268us/step - loss: 0.0099 - mean_absolute_error: 0.0462\n",
      "Epoch 197/200\n",
      "423/423 [==============================] - 0s 263us/step - loss: 0.0113 - mean_absolute_error: 0.0503\n",
      "Epoch 198/200\n",
      "423/423 [==============================] - 0s 263us/step - loss: 0.0108 - mean_absolute_error: 0.0476\n",
      "Epoch 199/200\n",
      "423/423 [==============================] - 0s 310us/step - loss: 0.0107 - mean_absolute_error: 0.0475\n",
      "Epoch 200/200\n",
      "423/423 [==============================] - 0s 329us/step - loss: 0.0099 - mean_absolute_error: 0.0481\n"
     ]
    }
   ],
   "source": [
    "model = baseline_model_30()\n",
    "\n",
    "print (model.get_weights())\n",
    "# estimator = train_data_nn(X_new, Y_rob_train)\n",
    "\n",
    "print(X_new.shape)\n",
    "print(y_train.shape)\n",
    "history = model.fit(X_new,  Y_rob_train, epochs=200, batch_size=5,  verbose=1, validation_split=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2KIpX4xqhVAU"
   },
   "outputs": [],
   "source": [
    "def visualize_learning_curve(history):\n",
    "    # list all data in history\n",
    "    print(history.history.keys())\n",
    "    # summarize history for accuracy\n",
    "    plt.plot(history.history['loss'])\n",
    "#     plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.show()\n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['mean_absolute_error'])\n",
    "#     plt.plot(history.history['val_mean_absolute_error'])\n",
    "    plt.title('model mean_absolute_error')\n",
    "    plt.ylabel('mean_absolute_error')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I65fooUhhsKq"
   },
   "outputs": [],
   "source": [
    "\n",
    "# print(X_test.shape)\n",
    "# X_test_t = X_test.transpose()\n",
    "# print(X_test_t.shape)\n",
    "# scaler_rob_x = MinMaxScaler().fit(X_test_t)\n",
    "# X_new_test_t = scaler_rob_x.transform(X_test_t)\n",
    "# X_new_test = X_new_test_t.transpose()\n",
    "# print(X_new_test.shape)\n",
    "\n",
    "# y_test_t = y_test.transpose()\n",
    "# # scaler_rob_y = RobustScaler().fit(y_test_t)\n",
    "# Y_new_test_t = scaler_rob_x.transform(y_test_t)\n",
    "# Y_new_test = Y_new_test_t.transpose()\n",
    "\n",
    "# X_new_test = factor_fit.transform(X_new_test)\n",
    "# print(X_new_test.shape)\n",
    "\n",
    "# visualize_learning_curve(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "colab_type": "code",
    "id": "46dPn9dGh0Cz",
    "outputId": "24cd3972-a178-4a49-b029-9d8e02fccd99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01660702163439875\n",
      "dict_keys(['loss', 'mean_absolute_error'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "import math\n",
    "# from sklearn.metrics import max_error\n",
    "\n",
    "pred = model.predict((X_new))\n",
    "# print(pred)\n",
    "\n",
    "mse = (mean_squared_error(Y_rob_train,pred))\n",
    "\n",
    "print(mse)\n",
    "visualize_learning_curve(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "pRkF_i2xh6JG",
    "outputId": "b5293546-9fcf-403c-c146-8c2746a0bc84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[150.     405.9922] y\n",
      "[121.95505 413.75494]\n",
      "[140.     405.9922] y\n",
      "[120.48144 384.35986]\n",
      "[166.3    405.9922] y\n",
      "[145.05386 412.32504]\n",
      "[169.8    405.9922] y\n",
      "[126.44206 410.13956]\n",
      "[170.     401.3125] y\n",
      "[123.02895 399.83334]\n",
      "[165.6    401.3125] y\n",
      "[148.42896 404.93948]\n",
      "[0.14      0.4013125] y\n",
      "[ 20.618408 387.35318 ]\n",
      "[0.14      0.4013125] y\n",
      "[ 86.7335  385.50674]\n",
      "[150.     648.7813] y\n",
      "[144.23267 642.0848 ]\n",
      "[145.     607.4063] y\n",
      "[144.8572 606.7817]\n",
      "[150.     624.5469] y\n",
      "[148.12968 617.03925]\n",
      "[155.     630.7813] y\n",
      "[166.23186 629.8402 ]\n",
      "[145.     625.6719] y\n",
      "[135.80963 620.6267 ]\n",
      "[145. 606.] y\n",
      "[135.97372 602.6025 ]\n",
      "[140.1    589.8125] y\n",
      "[151.34833 585.60645]\n",
      "[140.    569.875] y\n",
      "[142.43434 568.50964]\n",
      "[130.     626.3907] y\n",
      "[184.79236 625.3649 ]\n",
      "[120.     610.4219] y\n",
      "[164.54382 608.276  ]\n",
      "[170.     401.3125] y\n",
      "[117.89168 398.0574 ]\n",
      "[166.     401.3125] y\n",
      "[169.37   405.1433]\n",
      "[170.     401.3125] y\n",
      "[120.858444 399.08298 ]\n",
      "[168.9    401.3125] y\n",
      "[151.28717 404.6252 ]\n",
      "[166.4    401.3125] y\n",
      "[149.02705 408.82077]\n",
      "[ 26.33768194 498.06189793] y\n",
      "[117.22457 408.80066]\n",
      "[170.     401.3125] y\n",
      "[118.95956 398.42654]\n",
      "[-200.      182.6875] y\n",
      "[-125.159065  175.84988 ]\n",
      "[-200.      203.0313] y\n",
      "[-181.93309  184.6918 ]\n",
      "[129.9    590.7188] y\n",
      "[118.51037 582.67065]\n",
      "[120.     563.5313] y\n",
      "[138.39745 561.50024]\n",
      "[127.9   583.375] y\n",
      "[128.85165 576.45294]\n",
      "[120.     562.6719] y\n",
      "[130.0164  558.60297]\n",
      "[120.     563.0469] y\n",
      "[130.58472 558.79944]\n",
      "[129.6    583.5625] y\n",
      "[126.84996 575.7609 ]\n",
      "[ 60.    585.375] y\n",
      "[ 81.546265 587.11847 ]\n",
      "[ 69.4 606. ] y\n",
      "[ 92.35384 607.26215]\n",
      "[150.     401.3125] y\n",
      "[113.481964 401.69952 ]\n",
      "[150.     401.3125] y\n",
      "[143.61581 401.72504]\n",
      "[150.     401.3125] y\n",
      "[118.45186 375.89438]\n",
      "[150.     401.3125] y\n",
      "[108.56969 395.9964 ]\n",
      "[150.     401.3125] y\n",
      "[ 79.62765 394.03848]\n",
      "[150.     401.3125] y\n",
      "[105.724686 399.01788 ]\n",
      "[140.     589.5938] y\n",
      "[137.01012 585.81635]\n",
      "[140.    578.125] y\n",
      "[145.72246 579.70184]\n",
      "[145.     582.6563] y\n",
      "[126.13237 572.9296 ]\n",
      "[140.     576.2188] y\n",
      "[142.3979  578.55255]\n",
      "[140.     572.5625] y\n",
      "[127.18256 564.1663 ]\n",
      "[145.     588.1563] y\n",
      "[140.08649 586.8798 ]\n",
      "[140.     562.5625] y\n",
      "[137.42007 558.5791 ]\n",
      "[130.     564.2657] y\n",
      "[132.7524  559.54877]\n",
      "[135.     566.4063] y\n",
      "[137.39442 567.69653]\n",
      "[140.     565.6719] y\n",
      "[129.99869 565.1399 ]\n",
      "[140.     557.3907] y\n",
      "[134.58604 557.5994 ]\n",
      "[ 26.33768194 498.06189793] y\n",
      "[123.79419 581.2476 ]\n",
      "[135.     567.7813] y\n",
      "[142.53748 569.4745 ]\n",
      "[189.3    646.4219] y\n",
      "[189.07866 644.1704 ]\n",
      "[180.     629.3282] y\n",
      "[183.89241 623.6018 ]\n",
      "[190.     651.8438] y\n",
      "[196.02971 645.06335]\n",
      "[180.     627.0157] y\n",
      "[173.32468 629.81824]\n",
      "[180.     628.5938] y\n",
      "[176.23329 631.4104 ]\n",
      "[190.     651.2344] y\n",
      "[180.36053 650.69324]\n",
      "[ 26.33768194 498.06189793] y\n",
      "[-2121.6494    217.20337]\n",
      "[120.     456.6563] y\n",
      "[ 81.57443 460.92673]\n",
      "[120.     472.9688] y\n",
      "[ 90.70036 473.20786]\n",
      "[120.     656.3438] y\n",
      "[131.00803 652.5771 ]\n",
      "[120.     637.3125] y\n",
      "[121.654495 627.7922  ]\n",
      "[140.     669.3282] y\n",
      "[148.29913 662.72943]\n",
      "[125.     572.7344] y\n",
      "[137.4556 557.7169]\n",
      "[155.     683.9532] y\n",
      "[183.15019 678.73706]\n",
      "[165.     621.5625] y\n",
      "[170.57709 614.16144]\n",
      "[115.     639.6875] y\n",
      "[125.906204 632.7759  ]\n",
      "[110.     638.4063] y\n",
      "[126.71144 633.05426]\n",
      "[180.     732.4063] y\n",
      "[181.55255 721.23303]\n",
      "[175.     711.4688] y\n",
      "[183.71603 703.723  ]\n",
      "[180.     660.5313] y\n",
      "[176.0493 655.4464]\n",
      "[180.     733.2813] y\n",
      "[183.9983  722.07855]\n",
      "[175.     712.8282] y\n",
      "[183.38057 703.6124 ]\n",
      "[175.     638.0157] y\n",
      "[184.97173 627.7485 ]\n",
      "[160.5    401.3125] y\n",
      "[114.17993 399.35754]\n",
      "[160.     401.3125] y\n",
      "[126.46542 403.60458]\n",
      "[160.     401.3125] y\n",
      "[156.63632 402.98547]\n",
      "[160.8    401.3125] y\n",
      "[118.028366 397.089   ]\n",
      "[160.     401.3125] y\n",
      "[132.1664  377.32532]\n",
      "[160.     401.3125] y\n",
      "[126.83296 397.8603 ]\n",
      "[155.     606.1875] y\n",
      "[162.44661 607.6957 ]\n",
      "[140.     578.4063] y\n",
      "[126.85752 573.1803 ]\n",
      "[140.     580.4688] y\n",
      "[128.86707 573.875  ]\n",
      "[140.     581.2188] y\n",
      "[143.07545 578.7868 ]\n",
      "[150.    599.875] y\n",
      "[151.5718 597.3933]\n",
      "[ 68.3    589.9532] y\n",
      "[ 79.630844 595.3811  ]\n",
      "[ 70.     607.5782] y\n",
      "[ 92.072266 610.2091  ]\n",
      "[148.6    401.3125] y\n",
      "[113.11834 401.57385]\n",
      "[140.5    401.3125] y\n",
      "[115.51885 391.8964 ]\n",
      "[141.9    401.3125] y\n",
      "[118.43074 403.4103 ]\n",
      "[141.9    401.3125] y\n",
      "[113.474106 401.69684 ]\n",
      "[149.     401.3125] y\n",
      "[125.55751 405.874  ]\n",
      "[149.3    401.3125] y\n",
      "[122.297585 404.7471  ]\n",
      "[181.2    401.3125] y\n",
      "[157.8333  402.50345]\n",
      "[188.3    401.3125] y\n",
      "[171.17647 410.52032]\n",
      "[188.9    401.3125] y\n",
      "[168.36894 406.17926]\n",
      "[181.7    401.3125] y\n",
      "[187.34656 404.51328]\n",
      "[181.     401.3125] y\n",
      "[164.30495 408.93576]\n",
      "[188.2    401.3125] y\n",
      "[164.26952 394.45383]\n",
      "[120.3   565.875] y\n",
      "[139.16113 570.8906 ]\n",
      "[130.     581.9219] y\n",
      "[111.1706  570.34064]\n",
      "[130.     584.1563] y\n",
      "[124.645065 574.9987  ]\n",
      "[130.     585.7969] y\n",
      "[136.0466 588.0665]\n",
      "[122.8    566.7657] y\n",
      "[133.06487 568.78314]\n",
      "[120.3    566.6563] y\n",
      "[130.52249 567.9043 ]\n",
      "[159.5    401.3125] y\n",
      "[129.8926  404.78937]\n",
      "[159.9    401.3125] y\n",
      "[154.9422  402.72516]\n",
      "[159.6    401.3125] y\n",
      "[131.54868 378.28564]\n",
      "[160.2    401.3125] y\n",
      "[118.81346 400.95932]\n",
      "[160.7    401.3125] y\n",
      "[118.79486 397.45438]\n",
      "[160.1    401.3125] y\n",
      "[106.61455 396.74222]\n",
      "[ 60.1    602.4375] y\n",
      "[ 89.34484 599.27295]\n",
      "[ 60.     586.1094] y\n",
      "[ 81.70293 586.271  ]\n",
      "[140.     401.3125] y\n",
      "[106.92832 402.0172 ]\n",
      "[143.2    401.3125] y\n",
      "[108.28516 401.86615]\n",
      "[170.     612.8125] y\n",
      "[169.73344 602.63885]\n",
      "[170.4    627.6563] y\n",
      "[179.08385 626.53326]\n",
      "[113.4    633.1719] y\n",
      "[143.48848 627.1444 ]\n",
      "[ 10.4   469.125] y\n",
      "[ 44.924267 465.13306 ]\n",
      "[-49.8    -44.2656] y\n",
      "[-49.42034  -40.404297]\n",
      "[-50.     -45.0313] y\n",
      "[-49.942204 -49.040543]\n",
      "[-200.     -202.6406] y\n",
      "[-199.9422  -199.04054]\n",
      "[-200.     -202.6406] y\n",
      "[-199.9422  -199.04054]\n",
      "[157.1    401.3125] y\n",
      "[131.17279 389.68994]\n",
      "[160.     401.3125] y\n",
      "[105.45132 396.3401 ]\n",
      "[120.     654.4063] y\n",
      "[137.42577 653.2061 ]\n",
      "[110.     631.3125] y\n",
      "[124.60651 630.86414]\n",
      "[120.     652.0157] y\n",
      "[136.19414 651.7026 ]\n",
      "[110.     632.4063] y\n",
      "[135.99489 624.86255]\n",
      "[110.     632.8438] y\n",
      "[134.89928 627.98944]\n",
      "[120.2    658.3282] y\n",
      "[149.07628 653.87177]\n",
      "[120.     557.4844] y\n",
      "[112.713196 552.62134 ]\n",
      "[120.     541.4063] y\n",
      "[117.22755 539.6185 ]\n",
      "[120.     539.7657] y\n",
      "[102.36758 545.5265 ]\n",
      "[120. 554.] y\n",
      "[122.40391 544.2618 ]\n",
      "[120.     556.4844] y\n",
      "[114.382195 553.1983  ]\n",
      "[120.     538.9532] y\n",
      "[119.93055 538.8749 ]\n",
      "[115.7    653.3125] y\n",
      "[138.75208 648.523  ]\n",
      "[ 26.33768194 498.06189793] y\n",
      "[135.30258 650.1254 ]\n",
      "[110.6    561.1407] y\n",
      "[126.48773 559.9664 ]\n",
      "[120.     557.4844] y\n",
      "[112.713196 552.62134 ]\n",
      "[120.     541.4063] y\n",
      "[117.22755 539.6185 ]\n",
      "[120.     539.7657] y\n",
      "[102.36758 545.5265 ]\n",
      "[120. 554.] y\n",
      "[122.40391 544.2618 ]\n",
      "[120.     556.4844] y\n",
      "[114.382195 553.1983  ]\n",
      "[120.     538.9532] y\n",
      "[119.93055 538.8749 ]\n",
      "[ 70.     456.6563] y\n",
      "[ 81.57443 460.92673]\n",
      "[ 70.     472.9688] y\n",
      "[ 90.70036 473.20786]\n",
      "[162.     401.3125] y\n",
      "[141.15807 406.1005 ]\n",
      "[160.1    401.3125] y\n",
      "[135.11826 384.21243]\n",
      "[ 26.33768194 498.06189793] y\n",
      "[ 92.47315 707.1451 ]\n",
      "[ 60.5    708.6094] y\n",
      "[116.84483 698.5252 ]\n",
      "[ 69.6    730.4844] y\n",
      "[114.12396 721.1727 ]\n",
      "[-63.1   394.625] y\n",
      "[-40.260376 386.9106  ]\n",
      "[-130.      310.1094] y\n",
      "[-101.17447  299.60556]\n",
      "[110.     646.3438] y\n",
      "[131.00803 652.5771 ]\n",
      "[110.     627.3125] y\n",
      "[121.654495 627.7922  ]\n",
      "[-2560.     0.] y\n",
      "[-2121.6494    217.20337]\n",
      "[-2560.     0.] y\n",
      "[-2121.6494    217.20337]\n",
      "[-2560.         6.2031] y\n",
      "[-2121.6494    217.20337]\n",
      "[-2560.     0.] y\n",
      "[-2121.6494    217.20337]\n",
      "[-2560.     0.] y\n",
      "[-2121.6494    217.20337]\n",
      "[120.9 710. ] y\n",
      "[ 99.709496 651.5574  ]\n",
      "[123.3    668.1719] y\n",
      "[ 92.92465 608.88293]\n",
      "[120.9    652.8282] y\n",
      "[ 96.395676 587.2757  ]\n",
      "[129.8    732.0782] y\n",
      "[106.88263 670.2364 ]\n",
      "[122.4    654.0469] y\n",
      "[ 90.30207 585.1692 ]\n",
      "[126.9    669.1407] y\n",
      "[ 98.56628 606.2144 ]\n",
      "[ 26.33768194 498.06189793] y\n",
      "[-9.9422035 -9.040541 ]\n",
      "[120.    650.375] y\n",
      "[135.56491 651.91614]\n",
      "[110.    634.125] y\n",
      "[136.73746 625.7566 ]\n",
      "[110.     629.8282] y\n",
      "[124.24744 628.63513]\n",
      "[110.     631.1719] y\n",
      "[130.1112  627.88544]\n",
      "[120.     653.2032] y\n",
      "[139.5676  652.19354]\n",
      "[120.     653.9844] y\n",
      "[123.247   655.74927]\n",
      "[ 26.33768194 498.06189793] y\n",
      "[-9.9422035 -9.040541 ]\n",
      "[ 26.33768194 498.06189793] y\n",
      "[-9.9422035 -9.040541 ]\n",
      "[-10.     -10.0781] y\n",
      "[ -5.4269924 -18.179668 ]\n",
      "[-10.     -11.3438] y\n",
      "[ -5.727012 -14.736251]\n",
      "[-10.     -10.4063] y\n",
      "[ -4.3382573 -11.235252 ]\n",
      "[-10.     -11.4063] y\n",
      "[ -0.97816706 -20.090641  ]\n",
      "[-11.6    -10.4531] y\n",
      "[ -8.610498 -10.934738]\n",
      "[-10.     -10.9219] y\n",
      "[ -5.263386 -18.303625]\n",
      "[120.     654.4063] y\n",
      "[137.42577 653.2061 ]\n",
      "[120.     641.3125] y\n",
      "[124.60651 630.86414]\n",
      "[130.     662.0157] y\n",
      "[136.19414 651.7026 ]\n",
      "[120.     642.4063] y\n",
      "[135.99489 624.86255]\n",
      "[120.     642.8438] y\n",
      "[134.89928 627.98944]\n",
      "[120.2    658.3282] y\n",
      "[149.07628 653.87177]\n",
      "[190.     401.3125] y\n",
      "[159.88419 402.48163]\n",
      "[186.1    401.3125] y\n",
      "[168.1883  406.38788]\n",
      "[2.63376819e+01 5.29080000e-03] y\n",
      "[132.92816 368.31445]\n",
      "[ 26.33768194 498.06189793] y\n",
      "[ 71.94724 392.2478 ]\n",
      "[ 26.33768194 498.06189793] y\n",
      "[120.132324 390.88965 ]\n",
      "[180.8    401.3125] y\n",
      "[153.71214 382.84555]\n",
      "[188.     401.3125] y\n",
      "[163.62717 408.70145]\n",
      "[2.63376819e+01 2.05730000e-03] y\n",
      "[134.38911 384.22443]\n",
      "[2.63376819e+01 2.15390000e-03] y\n",
      "[124.821304 391.56064 ]\n",
      "[180.     687.2344] y\n",
      "[175.37363 661.69   ]\n",
      "[187.3    680.0625] y\n",
      "[194.23083 684.30975]\n",
      "[149.5    401.3125] y\n",
      "[110.766106 400.76068 ]\n",
      "[149.8    401.3125] y\n",
      "[109.32827 400.26364]\n",
      "[140.     401.3125] y\n",
      "[118.36131 403.38632]\n",
      "[-100.      -37.4375] y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-96.411    -42.402115]\n",
      "[140.     401.3125] y\n",
      "[109.49867 399.963  ]\n",
      "[140.     401.3125] y\n",
      "[121.411476 402.7572  ]\n",
      "[139.7    674.6094] y\n",
      "[145.61848 669.1254 ]\n",
      "[135.1    659.0782] y\n",
      "[147.2317  649.04034]\n",
      "[145.     590.4063] y\n",
      "[135.91647 585.4383 ]\n",
      "[160.     401.3125] y\n",
      "[103.78096 395.76266]\n",
      "[159.3    401.3125] y\n",
      "[150.91049 402.23962]\n",
      "[160.     401.3125] y\n",
      "[111.6908  398.49707]\n",
      "[160.     401.3125] y\n",
      "[117.02457 396.36438]\n",
      "[159.4    401.3125] y\n",
      "[129.7757  384.43637]\n",
      "[158.8    401.3125] y\n",
      "[127.01149 403.79337]\n",
      "[150.     405.9922] y\n",
      "[123.333725 377.90085 ]\n",
      "[150.     405.9922] y\n",
      "[114.909065 413.90244 ]\n",
      "[140.     405.9922] y\n",
      "[144.11714 412.7789 ]\n",
      "[140.     405.9922] y\n",
      "[122.25433 416.44168]\n",
      "[150.     405.9922] y\n",
      "[122.13   413.8154]\n",
      "[140.     405.9922] y\n",
      "[105.266594 408.9765  ]\n",
      "[139.7    674.6094] y\n",
      "[145.61848 669.1254 ]\n",
      "[135.1    659.0782] y\n",
      "[147.2317  649.04034]\n",
      "[155.     648.0313] y\n",
      "[159.2303 648.2556]\n",
      "[125.     610.0782] y\n",
      "[122.12054 603.70764]\n",
      "[150.     649.2032] y\n",
      "[147.74883 643.48096]\n",
      "[140.     639.8282] y\n",
      "[133.60484 634.4589 ]\n",
      "[130.     609.7344] y\n",
      "[119.104324 602.68646 ]\n",
      "[130.     612.7969] y\n",
      "[116.337204 608.0977  ]\n",
      "[120.5    708.6094] y\n",
      "[116.84483 698.5252 ]\n",
      "[129.6    730.4844] y\n",
      "[114.12396 721.1727 ]\n",
      "[140.     700.8907] y\n",
      "[178.52916 680.65955]\n",
      "[139.9    683.2344] y\n",
      "[216.11336 686.9923 ]\n",
      "[130.    644.375] y\n",
      "[ 83.856514 644.07227 ]\n",
      "[126.2    623.7657] y\n",
      "[ 87.21081 618.3624 ]\n",
      "[135.     620.5782] y\n",
      "[130.08249 615.967  ]\n",
      "[120.     599.1875] y\n",
      "[109.44871 593.383  ]\n",
      "[135.     619.7969] y\n",
      "[135.30588 617.7727 ]\n",
      "[120.     604.9063] y\n",
      "[105.68129 591.3287 ]\n",
      "[130.     627.7657] y\n",
      "[124.635345 622.39185 ]\n",
      "[120.     596.8438] y\n",
      "[107.16462 592.375  ]\n",
      "[ 26.33768194 498.06189793] y\n",
      "[ 63.8947 391.3786]\n",
      "[ 26.33768194 498.06189793] y\n",
      "[118.12733 400.72214]\n",
      "[ 26.33768194 498.06189793] y\n",
      "[117.31613 400.44174]\n",
      "[ 26.33768194 498.06189793] y\n",
      "[122.361336 388.60632 ]\n",
      "[ 26.33768194 498.06189793] y\n",
      "[111.786644 396.51968 ]\n",
      "[ 26.33768194 498.06189793] y\n",
      "[138.15088 402.70212]\n",
      "[ 26.33768194 498.06189793] y\n",
      "[106.60683 396.73953]\n",
      "[ 26.33768194 498.06189793] y\n",
      "[-211.33618    21.635492]\n",
      "[150.1    401.3125] y\n",
      "[122.61398 402.27313]\n",
      "[150.6    401.3125] y\n",
      "[125.11773 403.13867]\n",
      "[156.     401.3125] y\n",
      "[131.19287 405.23886]\n",
      "[154.1    401.3125] y\n",
      "[118.38705 400.81192]\n",
      "[154.6    401.3125] y\n",
      "[128.16801 406.77646]\n",
      "[150.3    401.3125] y\n",
      "[133.08005 372.30093]\n",
      "[160.6    401.3125] y\n",
      "[121.82164 401.99927]\n",
      "[160.     401.3125] y\n",
      "[137.16124 363.7221 ]\n",
      "[160.     401.3125] y\n",
      "[143.47241 402.26685]\n",
      "[162.     401.3125] y\n",
      "[115.63347 397.8949 ]\n",
      "[161.9    401.3125] y\n",
      "[123.926636 402.72696 ]\n",
      "[160.     401.3125] y\n",
      "[122.929436 402.38223 ]\n",
      "[105.     582.2188] y\n",
      "[121.05463 578.92413]\n",
      "[105.     583.8282] y\n",
      "[116.22145 577.2533 ]\n",
      "[100.     561.8438] y\n",
      "[106.33047 555.58136]\n",
      "[105.     577.5313] y\n",
      "[112.33937 575.91125]\n",
      "[100.    562.625] y\n",
      "[108.657936 556.386   ]\n",
      "[100.     562.1094] y\n",
      "[107.796 556.088]\n",
      "[140.1    589.8125] y\n",
      "[151.34833 585.60645]\n",
      "[140.    569.875] y\n",
      "[142.43434 568.50964]\n",
      "[190.     700.8907] y\n",
      "[178.52916 680.65955]\n",
      "[189.9    683.2344] y\n",
      "[216.11336 686.9923 ]\n",
      "[-2560.     0.] y\n",
      "[-2121.6494    217.20337]\n",
      "[-2560.     0.] y\n",
      "[-2121.6494    217.20337]\n",
      "[120.1    602.4375] y\n",
      "[ 89.34484 599.27295]\n",
      "[120.     586.1094] y\n",
      "[ 81.70293 586.271  ]\n",
      "[250.     746.7188] y\n",
      "[253.87828 746.4055 ]\n",
      "[245.     729.9375] y\n",
      "[251.06442 729.7633 ]\n",
      "[250.     729.4844] y\n",
      "[243.9134 724.4037]\n",
      "[250.     748.3125] y\n",
      "[254.92221 746.76636]\n",
      "[245.     731.0938] y\n",
      "[247.39302 728.4942 ]\n",
      "[250.     748.2188] y\n",
      "[252.09229 745.7881 ]\n",
      "[ 26.33768194 498.06189793] y\n",
      "[ 46.084297 388.87024 ]\n",
      "[ 26.33768194 498.06189793] y\n",
      "[ 93.19115 408.97794]\n",
      "[ 26.33768194 498.06189793] y\n",
      "[-221.39241 -158.12148]\n",
      "[ 26.33768194 498.06189793] y\n",
      "[-18.411152  19.763441]\n",
      "[ 26.33768194 498.06189793] y\n",
      "[0.56042016 9.591594  ]\n",
      "[ 26.33768194 498.06189793] y\n",
      "[120.67234 401.60193]\n",
      "[ 26.33768194 498.06189793] y\n",
      "[0.57082176 9.593374  ]\n",
      "[ 26.33768194 498.06189793] y\n",
      "[-24.727076 -83.86751 ]\n",
      "[ 26.33768194 498.06189793] y\n",
      "[0.5735296 9.593958 ]\n",
      "[ 26.33768194 498.06189793] y\n",
      "[-39.942204 -39.040543]\n",
      "[ 26.33768194 498.06189793] y\n",
      "[104.87578 401.30768]\n",
      "[ 26.33768194 498.06189793] y\n",
      "[ 95.78081 395.5803 ]\n",
      "[ 26.33768194 498.06189793] y\n",
      "[ 65.49935 391.71902]\n",
      "[ 26.33768194 498.06189793] y\n",
      "[112.97562 408.06754]\n",
      "[ 26.33768194 498.06189793] y\n",
      "[ 71.29248 392.60547]\n",
      "[ 26.33768194 498.06189793] y\n",
      "[14.654745   1.7775983]\n",
      "[ 26.33768194 498.06189793] y\n",
      "[ 94.49845  119.401924]\n",
      "[ 26.33768194 498.06189793] y\n",
      "[112.918335 101.15172 ]\n",
      "[ 26.33768194 498.06189793] y\n",
      "[0.571692 9.593659]\n",
      "[ 26.33768194 498.06189793] y\n",
      "[-2121.6494    217.20337]\n",
      "[ 26.33768194 498.06189793] y\n",
      "[ 26.442749 157.52614 ]\n",
      "[ 26.33768194 498.06189793] y\n",
      "[121.068726 408.15414 ]\n",
      "[ 26.33768194 498.06189793] y\n",
      "[ 56.122467 390.5154  ]\n",
      "[ 26.33768194 498.06189793] y\n",
      "[105.94318 397.54242]\n",
      "[ 26.33768194 498.06189793] y\n",
      "[-2121.6494    217.20337]\n",
      "[ 26.33768194 498.06189793] y\n",
      "[127.443855 403.94284 ]\n",
      "[ 26.33768194 498.06189793] y\n",
      "[0.5584997 9.5910845]\n",
      "[ 26.33768194 498.06189793] y\n",
      "[ 92.67742 104.28934]\n",
      "[120.9 710. ] y\n",
      "[ 99.709496 651.5574  ]\n",
      "[123.3    668.1719] y\n",
      "[ 92.92465 608.88293]\n",
      "[120.9    652.8282] y\n",
      "[ 96.395676 587.2757  ]\n",
      "[129.8    732.0782] y\n",
      "[106.88263 670.2364 ]\n",
      "[122.4    654.0469] y\n",
      "[ 90.30207 585.1692 ]\n",
      "[126.9    669.1407] y\n",
      "[ 98.56628 606.2144 ]\n",
      "[135.     656.9688] y\n",
      "[171.48634 669.3687 ]\n",
      "[130.     633.3125] y\n",
      "[154.16107 636.0004 ]\n",
      "[130.     637.9375] y\n",
      "[119.62116 646.35126]\n",
      "[135.     656.5157] y\n",
      "[155.22012 663.7455 ]\n",
      "[135.     654.2969] y\n",
      "[176.91959 662.1206 ]\n",
      "[130.     635.9532] y\n",
      "[ 50.617172 641.421   ]\n",
      "[121.8    640.7813] y\n",
      "[139.47678 625.75757]\n",
      "[130.     668.3907] y\n",
      "[139.71065 656.87866]\n",
      "[-2560.     0.] y\n",
      "[-2121.6494    217.20337]\n",
      "[-2560.     0.] y\n",
      "[-2121.6494    217.20337]\n",
      "[-2560.     0.] y\n",
      "[-2121.6494    217.20337]\n",
      "[-2560.     0.] y\n",
      "[-2121.6494    217.20337]\n",
      "[-2560.     0.] y\n",
      "[-2121.6494    217.20337]\n",
      "[-2560.     0.] y\n",
      "[-2121.6494    217.20337]\n",
      "[140.     669.3282] y\n",
      "[148.29913 662.72943]\n",
      "[125.     572.7344] y\n",
      "[137.4556 557.7169]\n",
      "[155.     683.9532] y\n",
      "[183.15019 678.73706]\n",
      "[165.     621.5625] y\n",
      "[170.57709 614.16144]\n",
      "[115.     639.6875] y\n",
      "[125.906204 632.7759  ]\n",
      "[110.     638.4063] y\n",
      "[126.71144 633.05426]\n",
      "[120.     709.9063] y\n",
      "[150.61646 703.20215]\n",
      "[129.3    733.7188] y\n",
      "[160.05157 730.33276]\n",
      "[130.     665.6563] y\n",
      "[148.29108 674.10077]\n",
      "[120.     641.4219] y\n",
      "[141.2724 639.4561]\n",
      "[120.     640.6094] y\n",
      "[139.09103 631.8505 ]\n",
      "[130.     662.9844] y\n",
      "[143.2193  656.87506]\n",
      "[ 26.33768194 498.06189793] y\n",
      "[0.5670142 9.592913 ]\n",
      "[120.     709.9063] y\n",
      "[150.61646 703.20215]\n",
      "[129.3    733.7188] y\n",
      "[160.05157 730.33276]\n",
      "[130.     665.6563] y\n",
      "[148.29108 674.10077]\n",
      "[120.     641.4219] y\n",
      "[141.2724 639.4561]\n",
      "[120.     640.6094] y\n",
      "[139.09103 631.8505 ]\n",
      "[ 26.33768194 498.06189793] y\n",
      "[0.05779654 0.959459  ]\n",
      "[ 26.33768194 498.06189793] y\n",
      "[0.5653101 9.5926075]\n",
      "[130.     662.9844] y\n",
      "[143.2193  656.87506]\n",
      "[-9.1    -3.2656] y\n",
      "[-13.931057  -8.549284]\n",
      "[-9.8   -3.875] y\n",
      "[ -4.981474 -14.38446 ]\n",
      "[145.     613.7657] y\n",
      "[136.881  604.0243]\n",
      "[145.     619.2969] y\n",
      "[151.37154 618.16   ]\n",
      "[145.     620.8594] y\n",
      "[145.05095 615.975  ]\n",
      "[140.     600.6094] y\n",
      "[138.15582 595.3387 ]\n",
      "[140.     598.0625] y\n",
      "[135.20955 594.3202 ]\n",
      "[140.     596.0469] y\n",
      "[139.47998 595.79645]\n",
      "[180.     626.3907] y\n",
      "[184.79236 625.3649 ]\n",
      "[170.     610.4219] y\n",
      "[164.54382 608.276  ]\n",
      "[-99.5    363.3594] y\n",
      "[-69.05009 353.7591 ]\n",
      "[-170.      279.7813] y\n",
      "[-122.10282  269.07834]\n",
      "[ 80.    644.375] y\n",
      "[ 83.856514 644.07227 ]\n",
      "[ 76.2    623.7657] y\n",
      "[ 87.21081 618.3624 ]\n",
      "[111.8    630.7813] y\n",
      "[139.47678 625.75757]\n",
      "[120.     658.3907] y\n",
      "[139.71065 656.87866]\n",
      "[140.     590.8282] y\n",
      "[131.2429  583.82263]\n",
      "[140.     589.4219] y\n",
      "[132.74759 584.3428 ]\n",
      "[140.     592.8125] y\n",
      "[134.19278 584.8424 ]\n",
      "[140.     606.1094] y\n",
      "[133.65295 602.9084 ]\n",
      "[145. 609.] y\n",
      "[145.51044 607.0075 ]\n",
      "[145.     607.8594] y\n",
      "[148.03812 605.29803]\n",
      "[ 60.9 650. ] y\n",
      "[ 99.709496 651.5574  ]\n",
      "[ 63.3    608.1719] y\n",
      "[ 92.92465 608.88293]\n",
      "[ 60.9    592.8282] y\n",
      "[ 96.395676 587.2757  ]\n",
      "[ 69.8    672.0782] y\n",
      "[106.88263 670.2364 ]\n",
      "[ 62.4    594.0469] y\n",
      "[ 90.30207 585.1692 ]\n",
      "[ 66.9    609.1407] y\n",
      "[ 98.56628 606.2144 ]\n",
      "[0.     8.5469] y\n",
      "[0.58356345 9.595569  ]\n",
      "[0.     8.4844] y\n",
      "[0.5897558 9.596611 ]\n",
      "[0.     8.3594] y\n",
      "[0.58594763 9.595926  ]\n",
      "[0.     8.6875] y\n",
      "[0.58653235 9.596044  ]\n",
      "[0.     8.6875] y\n",
      "[0.58911264 9.596575  ]\n",
      "[0.     8.7656] y\n",
      "[0.56948006 9.593061  ]\n",
      "[129.3    706.4219] y\n",
      "[189.07866 644.1704 ]\n",
      "[120.     689.3282] y\n",
      "[183.89241 623.6018 ]\n",
      "[130.     711.8438] y\n",
      "[196.02971 645.06335]\n",
      "[120.     697.0157] y\n",
      "[173.32468 629.81824]\n",
      "[120.     688.5938] y\n",
      "[176.23329 631.4104 ]\n",
      "[130.     711.2344] y\n",
      "[180.36053 650.69324]\n",
      "[ 59.8    719.5938] y\n",
      "[ 96.70131 708.6067 ]\n",
      "[ 50.4    696.3907] y\n",
      "[100.855644 691.7903  ]\n",
      "[145.     600.5469] y\n",
      "[146.89343 595.776  ]\n",
      "[140.     579.9219] y\n",
      "[130.15651 574.32074]\n",
      "[140.     580.0313] y\n",
      "[141.45381 578.2262 ]\n",
      "[145.     596.5938] y\n",
      "[149.03568 596.51654]\n",
      "[140.     582.8125] y\n",
      "[141.60855 578.27966]\n",
      "[145.     600.4532] y\n",
      "[153.38092 598.01874]\n",
      "[-60.     502.9844] y\n",
      "[ -6.4135013 505.764    ]\n",
      "[-60.     489.0625] y\n",
      "[-52.675587 486.09848 ]\n",
      "[170.     612.2969] y\n",
      "[178.81313 605.6037 ]\n",
      "[170.4  630.75] y\n",
      "[187.52014 626.86633]\n",
      "[145.     615.8282] y\n",
      "[137.98969 613.5339 ]\n",
      "[145.     620.8125] y\n",
      "[157.55559 617.7145 ]\n",
      "[140.     595.5938] y\n",
      "[138.6687  595.51605]\n",
      "[145.     618.3282] y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[150.78915 617.9587 ]\n",
      "[140.     596.5782] y\n",
      "[137.52959 595.12225]\n",
      "[140.     597.8907] y\n",
      "[132.84344 593.50226]\n",
      "[-140.      318.9219] y\n",
      "[-162.77948  299.34357]\n",
      "[-180.      264.4531] y\n",
      "[-135.21086  251.05746]\n",
      "[-1.3    -2.0156] y\n",
      "[ 3.645624   -0.76954365]\n",
      "[-4.3   -2.375] y\n",
      "[-5.5383162 -7.9379644]\n",
      "[160.     401.3125] y\n",
      "[102.4238 395.2935]\n",
      "[159.9    401.3125] y\n",
      "[131.24045 374.23373]\n",
      "[146.9    401.3125] y\n",
      "[128.10657 406.75522]\n",
      "[141.7    401.3125] y\n",
      "[109.261215 400.24048 ]\n",
      "[160.     401.3125] y\n",
      "[113.198906 399.01843 ]\n",
      "[155.2    401.3125] y\n",
      "[127.03634 397.64423]\n",
      "[163.5    401.3125] y\n",
      "[140.87294 406.0019 ]\n",
      "[160.1    401.3125] y\n",
      "[135.97946 381.58093]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X1 = input_1_arr[:,0:10000]*1000\n",
    "Y1 = input_1_arr[:,10000:10004]\n",
    "\n",
    "X=X1\n",
    "Y=Y1[:,2:4]\n",
    "# print(Y)\n",
    "Y_new = np.zeros((Y.shape[0],2))\n",
    "for i in range(len(Y)):\n",
    "  \n",
    "    print(Y[i],\"y\")\n",
    "  \n",
    "\n",
    "    X_t= X[i].transpose()\n",
    "\n",
    "    scaler_rob_x = MinMaxScaler().fit((X_t.reshape(-1, 1)))\n",
    "                        \n",
    "    Xi = (scaler_rob_x.transform(X_t.reshape(-1, 1)))\n",
    "\n",
    "    I = factor_fit.transform(Xi.transpose())\n",
    "\n",
    "    pred = model.predict(I)\n",
    "\n",
    "  \n",
    "    Y_ti =Y[i].transpose()\n",
    "\n",
    "#     scaler_rob_y = RobustScaler().fit(Y_ti.reshape(-1, 1))\n",
    "    final_t = scaler_rob_x.inverse_transform(pred.reshape(-1, 1))\n",
    "                                          \n",
    "\n",
    "    final = final_t.transpose()\n",
    "                                          \n",
    "    print(final[0])\n",
    "\n",
    "    h = abs(final-Y[i])\n",
    "#   print(h,\"h\")\n",
    "#     o=np.divide(h,Y[i])\n",
    "#   print(o*100,\"percentage\") \n",
    "  \n",
    "    Y_new[i]=final[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "oTEoOJ1WjJ9T",
    "outputId": "183b55c6-fbfe-4a6e-f2fe-a201c83249d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150.0 121.95504760742188\n",
      "0.8157412879590379 r2 of stabilised\n",
      "0.5657677043331661 r2 of max\n"
     ]
    }
   ],
   "source": [
    "X1 = X1\n",
    "Y1 = Y1\n",
    "# print(Y1)\n",
    "\n",
    "# print(Y)\n",
    "from sklearn.metrics import r2_score\n",
    "print(Y1[0,2], Y_new[0,0])\n",
    "# print(Y_new[:,0])\n",
    "g = r2_score(Y1[:,2], Y_new[:,0])  \n",
    "g1 = r2_score(Y1[:,3], Y_new[:,1]) \n",
    "print(g,\"r2 of stabilised\")\n",
    "print(g1,\"r2 of max\")\n",
    "Y1[:,2]= Y_new[:,0]\n",
    "Y1[:,3]= Y_new[:,1]\n",
    "# print(Y1[0,2], Y_new[0,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "-z59fc0rjqqp",
    "outputId": "6c9f781f-ff8a-4fb8-b8e7-126262f4b607"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(423, 10002)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X1_new = np.concatenate((X1,Y1[:,2:4]),axis=1)\n",
    "print(X1_new.shape)\n",
    "Y1_new = Y1[:,0:2]\n",
    "# print(Y1_new)\n",
    "# X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(X1_new, Y1_new, test_size=0.20)\n",
    "X_train_c= X1_new\n",
    "y_train_c = Y1_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w18N-Ahtj3zL"
   },
   "outputs": [],
   "source": [
    "#standardise\n",
    "\n",
    "\n",
    "# ######minmax\n",
    "scaler_min_x = MinMaxScaler().fit(X_train_c)\n",
    "scaler_min_y = MinMaxScaler().fit(y_train_c)\n",
    "\n",
    "X_minmax_train = scaler_min_x.transform(X_train_c)\n",
    "Y_minmax_train = scaler_min_y.transform(y_train_c)\n",
    "\n",
    "\n",
    "# print(X)\n",
    "# print(Y)\n",
    "#####standard\n",
    "\n",
    "scaler_stan_x = StandardScaler().fit(X_train_c)\n",
    "scaler_stan_y = StandardScaler().fit(y_train_c)\n",
    "\n",
    "\n",
    "X_stan_train = scaler_stan_x.transform(X_train_c)\n",
    "Y_stan_train = scaler_stan_y.transform(y_train_c)\n",
    "\n",
    "# #######normlised\n",
    "# scaler_norm_x = Normalizer().fit(X_train_c)\n",
    "# scaler_norm_y = Normalizer().fit(y_train_c)\n",
    "\n",
    "\n",
    "# X_norm_train = scaler_norm_x.transform(X_train_c)\n",
    "# Y_norm_train = scaler_norm_y.transform(y_train_c)\n",
    "\n",
    "\n",
    "# # ################qt\n",
    "\n",
    "# scaler_qt_x =  QuantileTransformer(output_distribution='normal').fit(X_train_c)\n",
    "# scaler_qt_y =  QuantileTransformer(output_distribution='normal').fit(y_train_c)\n",
    "\n",
    "\n",
    "# X_qt_train = scaler_qt_x.transform(X_train_c)\n",
    "# Y_qt_train = scaler_qt_y.transform(y_train_c)\n",
    "\n",
    "\n",
    "##robust\n",
    "# print(X_train.shape)\n",
    "# print(y_train.shape)\n",
    "# X_train_t = X_train.transpose()\n",
    "# y_train_t = y_train.transpose()\n",
    "# print(X_train.shape,\"after\")\n",
    "# print(y_train.shape,\"after\")\n",
    "scaler_rob_x = MinMaxScaler().fit(X_train_c)\n",
    "scaler_rob_y = MinMaxScaler().fit(y_train_c)\n",
    "\n",
    "\n",
    "# X_rob_train = scaler_rob_x.transform(X_train_c)\n",
    "# Y_rob_train = scaler_rob_y.transform(y_train_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gp-_qNnYplqA"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(scaler_rob_x, open( \"./app/MODEL/scaler_rob_x_1_ON.pkl\", \"wb\" ) )\n",
    "pickle.dump(scaler_rob_y, open( \"./app/MODEL/scaler_rob_y_1_ON.pkl\", \"wb\" ) )\n",
    "X_rob_train_c = scaler_rob_x.transform(X_train_c)\n",
    "Y_rob_train_c = scaler_rob_y.transform(y_train_c)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "7CFgOiZdkHbW",
    "outputId": "cc05189c-42ff-4c34-c3e2-5632f0ea9bcb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(423, 30)\n",
      "(423, 32)\n"
     ]
    }
   ],
   "source": [
    "#apply PCA on X1_new\n",
    "transformer = FactorAnalysis(n_components=30, random_state=0)\n",
    "factor_fit = transformer.fit(X_rob_train_c[:,0:10000])\n",
    "X_new1 = factor_fit.transform(X_rob_train_c[:,0:10000])\n",
    "print(X_new1.shape)\n",
    "X_new1 = np.concatenate((X_new1,X_rob_train_c[:,10000:10002]),axis=1)\n",
    "print(X_new1.shape)\n",
    "# print((X_rob_train[:,0:10000].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d7y6ga_Ap3xd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tk0ehMK0psFc"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(factor_fit, open( \"./app/MODEL/factor_fit_1_ON.pkl\", \"wb\" ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l-vIsEvckQiI"
   },
   "outputs": [],
   "source": [
    "def baseline_model_31(optimizer='adam'):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(30, activation='relu', \n",
    "                    kernel_initializer = 'he_normal', \n",
    "                    input_shape=(32,)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "#     model.add(Dense(30, activation='relu',\n",
    "#                     kernel_initializer = 'he_normal'))\n",
    "#       model.add(BatchNormalization())\n",
    "#     model.add(Dropout(0.5))\n",
    "    model.add(Dense(12, activation='relu',\n",
    "                    kernel_initializer = 'he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "#     model.add(Dropout(0.5))\n",
    "    model.add(Dense(9, activation='relu',\n",
    "                    kernel_initializer = 'he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "#     model.add(Dropout(0.5))\n",
    "    model.add(Dense(2, activation='linear', \n",
    "                    kernel_initializer='he_normal'))\n",
    "    model.compile(loss = 'mse', optimizer=optimizer, metrics=['mae'])\n",
    "#     model.summary()\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "nXZHDnp-kTGe",
    "outputId": "fa1ed4a9-2620-4af9-b2b6-9fb859f265e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Epoch 1/400\n",
      "423/423 [==============================] - 1s 2ms/step - loss: 1.8405 - mean_absolute_error: 1.0977\n",
      "Epoch 2/400\n",
      "423/423 [==============================] - 0s 399us/step - loss: 1.0396 - mean_absolute_error: 0.7989\n",
      "Epoch 3/400\n",
      "423/423 [==============================] - 0s 406us/step - loss: 0.6961 - mean_absolute_error: 0.6570\n",
      "Epoch 4/400\n",
      "423/423 [==============================] - 0s 402us/step - loss: 0.4710 - mean_absolute_error: 0.5471\n",
      "Epoch 5/400\n",
      "423/423 [==============================] - 0s 400us/step - loss: 0.3944 - mean_absolute_error: 0.4881\n",
      "Epoch 6/400\n",
      "423/423 [==============================] - 0s 377us/step - loss: 0.3070 - mean_absolute_error: 0.4332\n",
      "Epoch 7/400\n",
      "423/423 [==============================] - 0s 411us/step - loss: 0.2100 - mean_absolute_error: 0.3627\n",
      "Epoch 8/400\n",
      "423/423 [==============================] - 0s 396us/step - loss: 0.1878 - mean_absolute_error: 0.3355\n",
      "Epoch 9/400\n",
      "423/423 [==============================] - 0s 383us/step - loss: 0.1844 - mean_absolute_error: 0.3304\n",
      "Epoch 10/400\n",
      "423/423 [==============================] - 0s 387us/step - loss: 0.1495 - mean_absolute_error: 0.3007\n",
      "Epoch 11/400\n",
      "423/423 [==============================] - 0s 386us/step - loss: 0.1489 - mean_absolute_error: 0.3042\n",
      "Epoch 12/400\n",
      "423/423 [==============================] - 0s 393us/step - loss: 0.1120 - mean_absolute_error: 0.2689\n",
      "Epoch 13/400\n",
      "423/423 [==============================] - 0s 395us/step - loss: 0.1000 - mean_absolute_error: 0.2453\n",
      "Epoch 14/400\n",
      "423/423 [==============================] - 0s 386us/step - loss: 0.0841 - mean_absolute_error: 0.2215\n",
      "Epoch 15/400\n",
      "423/423 [==============================] - 0s 385us/step - loss: 0.0848 - mean_absolute_error: 0.2288\n",
      "Epoch 16/400\n",
      "423/423 [==============================] - 0s 388us/step - loss: 0.0680 - mean_absolute_error: 0.2064\n",
      "Epoch 17/400\n",
      "423/423 [==============================] - 0s 400us/step - loss: 0.0637 - mean_absolute_error: 0.1947\n",
      "Epoch 18/400\n",
      "423/423 [==============================] - 0s 396us/step - loss: 0.0626 - mean_absolute_error: 0.1959\n",
      "Epoch 19/400\n",
      "423/423 [==============================] - 0s 340us/step - loss: 0.0573 - mean_absolute_error: 0.1852\n",
      "Epoch 20/400\n",
      "423/423 [==============================] - 0s 332us/step - loss: 0.0482 - mean_absolute_error: 0.1672\n",
      "Epoch 21/400\n",
      "423/423 [==============================] - 0s 332us/step - loss: 0.0477 - mean_absolute_error: 0.1674\n",
      "Epoch 22/400\n",
      "423/423 [==============================] - 0s 401us/step - loss: 0.0449 - mean_absolute_error: 0.1622\n",
      "Epoch 23/400\n",
      "423/423 [==============================] - 0s 402us/step - loss: 0.0440 - mean_absolute_error: 0.1549\n",
      "Epoch 24/400\n",
      "423/423 [==============================] - 0s 406us/step - loss: 0.0409 - mean_absolute_error: 0.1514\n",
      "Epoch 25/400\n",
      "423/423 [==============================] - 0s 417us/step - loss: 0.0355 - mean_absolute_error: 0.1400\n",
      "Epoch 26/400\n",
      "423/423 [==============================] - 0s 427us/step - loss: 0.0326 - mean_absolute_error: 0.1337\n",
      "Epoch 27/400\n",
      "423/423 [==============================] - 0s 422us/step - loss: 0.0317 - mean_absolute_error: 0.1301\n",
      "Epoch 28/400\n",
      "423/423 [==============================] - 0s 421us/step - loss: 0.0323 - mean_absolute_error: 0.1292\n",
      "Epoch 29/400\n",
      "423/423 [==============================] - 0s 416us/step - loss: 0.0284 - mean_absolute_error: 0.1241\n",
      "Epoch 30/400\n",
      "423/423 [==============================] - 0s 421us/step - loss: 0.0270 - mean_absolute_error: 0.1194\n",
      "Epoch 31/400\n",
      "423/423 [==============================] - 0s 390us/step - loss: 0.0268 - mean_absolute_error: 0.1150\n",
      "Epoch 32/400\n",
      "423/423 [==============================] - 0s 365us/step - loss: 0.0259 - mean_absolute_error: 0.1150\n",
      "Epoch 33/400\n",
      "423/423 [==============================] - 0s 370us/step - loss: 0.0261 - mean_absolute_error: 0.1154\n",
      "Epoch 34/400\n",
      "423/423 [==============================] - 0s 374us/step - loss: 0.0236 - mean_absolute_error: 0.1074\n",
      "Epoch 35/400\n",
      "423/423 [==============================] - 0s 376us/step - loss: 0.0234 - mean_absolute_error: 0.1097\n",
      "Epoch 36/400\n",
      "423/423 [==============================] - 0s 362us/step - loss: 0.0211 - mean_absolute_error: 0.1002\n",
      "Epoch 37/400\n",
      "423/423 [==============================] - 0s 362us/step - loss: 0.0226 - mean_absolute_error: 0.1042\n",
      "Epoch 38/400\n",
      "423/423 [==============================] - 0s 359us/step - loss: 0.0197 - mean_absolute_error: 0.0946\n",
      "Epoch 39/400\n",
      "423/423 [==============================] - 0s 349us/step - loss: 0.0203 - mean_absolute_error: 0.0945\n",
      "Epoch 40/400\n",
      "423/423 [==============================] - 0s 348us/step - loss: 0.0192 - mean_absolute_error: 0.0916\n",
      "Epoch 41/400\n",
      "423/423 [==============================] - 0s 351us/step - loss: 0.0206 - mean_absolute_error: 0.0930\n",
      "Epoch 42/400\n",
      "423/423 [==============================] - 0s 348us/step - loss: 0.0185 - mean_absolute_error: 0.0892\n",
      "Epoch 43/400\n",
      "423/423 [==============================] - 0s 340us/step - loss: 0.0171 - mean_absolute_error: 0.0849\n",
      "Epoch 44/400\n",
      "423/423 [==============================] - 0s 339us/step - loss: 0.0175 - mean_absolute_error: 0.0826\n",
      "Epoch 45/400\n",
      "423/423 [==============================] - 0s 337us/step - loss: 0.0176 - mean_absolute_error: 0.0852\n",
      "Epoch 46/400\n",
      "423/423 [==============================] - 0s 337us/step - loss: 0.0171 - mean_absolute_error: 0.0835\n",
      "Epoch 47/400\n",
      "423/423 [==============================] - 0s 354us/step - loss: 0.0177 - mean_absolute_error: 0.0823\n",
      "Epoch 48/400\n",
      "423/423 [==============================] - 0s 391us/step - loss: 0.0164 - mean_absolute_error: 0.0777\n",
      "Epoch 49/400\n",
      "423/423 [==============================] - 0s 386us/step - loss: 0.0153 - mean_absolute_error: 0.0744\n",
      "Epoch 50/400\n",
      "423/423 [==============================] - 0s 383us/step - loss: 0.0162 - mean_absolute_error: 0.0777\n",
      "Epoch 51/400\n",
      "423/423 [==============================] - 0s 352us/step - loss: 0.0157 - mean_absolute_error: 0.0766\n",
      "Epoch 52/400\n",
      "423/423 [==============================] - 0s 342us/step - loss: 0.0166 - mean_absolute_error: 0.0777\n",
      "Epoch 53/400\n",
      "423/423 [==============================] - 0s 348us/step - loss: 0.0158 - mean_absolute_error: 0.0748\n",
      "Epoch 54/400\n",
      "423/423 [==============================] - 0s 410us/step - loss: 0.0150 - mean_absolute_error: 0.0705\n",
      "Epoch 55/400\n",
      "423/423 [==============================] - 0s 420us/step - loss: 0.0161 - mean_absolute_error: 0.0745\n",
      "Epoch 56/400\n",
      "423/423 [==============================] - 0s 411us/step - loss: 0.0146 - mean_absolute_error: 0.0704\n",
      "Epoch 57/400\n",
      "423/423 [==============================] - 0s 404us/step - loss: 0.0155 - mean_absolute_error: 0.0698\n",
      "Epoch 58/400\n",
      "423/423 [==============================] - 0s 412us/step - loss: 0.0145 - mean_absolute_error: 0.0698\n",
      "Epoch 59/400\n",
      "423/423 [==============================] - 0s 375us/step - loss: 0.0147 - mean_absolute_error: 0.0695\n",
      "Epoch 60/400\n",
      "423/423 [==============================] - 0s 348us/step - loss: 0.0150 - mean_absolute_error: 0.0673\n",
      "Epoch 61/400\n",
      "423/423 [==============================] - 0s 388us/step - loss: 0.0148 - mean_absolute_error: 0.0659\n",
      "Epoch 62/400\n",
      "423/423 [==============================] - 0s 408us/step - loss: 0.0146 - mean_absolute_error: 0.0657\n",
      "Epoch 63/400\n",
      "423/423 [==============================] - 0s 411us/step - loss: 0.0141 - mean_absolute_error: 0.0645\n",
      "Epoch 64/400\n",
      "423/423 [==============================] - 0s 412us/step - loss: 0.0148 - mean_absolute_error: 0.0667\n",
      "Epoch 65/400\n",
      "423/423 [==============================] - 0s 419us/step - loss: 0.0133 - mean_absolute_error: 0.0618\n",
      "Epoch 66/400\n",
      "423/423 [==============================] - 0s 376us/step - loss: 0.0145 - mean_absolute_error: 0.0662\n",
      "Epoch 67/400\n",
      "423/423 [==============================] - 0s 431us/step - loss: 0.0148 - mean_absolute_error: 0.0656\n",
      "Epoch 68/400\n",
      "423/423 [==============================] - 0s 399us/step - loss: 0.0143 - mean_absolute_error: 0.0629\n",
      "Epoch 69/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "423/423 [==============================] - 0s 366us/step - loss: 0.0136 - mean_absolute_error: 0.0609\n",
      "Epoch 70/400\n",
      "423/423 [==============================] - 0s 434us/step - loss: 0.0142 - mean_absolute_error: 0.0632\n",
      "Epoch 71/400\n",
      "423/423 [==============================] - 0s 421us/step - loss: 0.0141 - mean_absolute_error: 0.0629\n",
      "Epoch 72/400\n",
      "423/423 [==============================] - 0s 421us/step - loss: 0.0130 - mean_absolute_error: 0.0594\n",
      "Epoch 73/400\n",
      "423/423 [==============================] - 0s 419us/step - loss: 0.0140 - mean_absolute_error: 0.0610\n",
      "Epoch 74/400\n",
      "423/423 [==============================] - 0s 423us/step - loss: 0.0132 - mean_absolute_error: 0.0597\n",
      "Epoch 75/400\n",
      "423/423 [==============================] - 0s 381us/step - loss: 0.0137 - mean_absolute_error: 0.0620\n",
      "Epoch 76/400\n",
      "423/423 [==============================] - 0s 408us/step - loss: 0.0139 - mean_absolute_error: 0.0616\n",
      "Epoch 77/400\n",
      "423/423 [==============================] - 0s 406us/step - loss: 0.0140 - mean_absolute_error: 0.0605\n",
      "Epoch 78/400\n",
      "423/423 [==============================] - 0s 407us/step - loss: 0.0138 - mean_absolute_error: 0.0596\n",
      "Epoch 79/400\n",
      "423/423 [==============================] - 0s 426us/step - loss: 0.0140 - mean_absolute_error: 0.0588\n",
      "Epoch 80/400\n",
      "423/423 [==============================] - 0s 356us/step - loss: 0.0131 - mean_absolute_error: 0.0598\n",
      "Epoch 81/400\n",
      "423/423 [==============================] - 0s 387us/step - loss: 0.0137 - mean_absolute_error: 0.0590\n",
      "Epoch 82/400\n",
      "423/423 [==============================] - 0s 410us/step - loss: 0.0137 - mean_absolute_error: 0.0573\n",
      "Epoch 83/400\n",
      "423/423 [==============================] - 0s 409us/step - loss: 0.0135 - mean_absolute_error: 0.0562\n",
      "Epoch 84/400\n",
      "423/423 [==============================] - 0s 398us/step - loss: 0.0138 - mean_absolute_error: 0.0586\n",
      "Epoch 85/400\n",
      "423/423 [==============================] - 0s 415us/step - loss: 0.0129 - mean_absolute_error: 0.0583\n",
      "Epoch 86/400\n",
      "423/423 [==============================] - 0s 402us/step - loss: 0.0136 - mean_absolute_error: 0.0574\n",
      "Epoch 87/400\n",
      "423/423 [==============================] - 0s 385us/step - loss: 0.0133 - mean_absolute_error: 0.0563\n",
      "Epoch 88/400\n",
      "423/423 [==============================] - 0s 412us/step - loss: 0.0135 - mean_absolute_error: 0.0596\n",
      "Epoch 89/400\n",
      "423/423 [==============================] - 0s 409us/step - loss: 0.0133 - mean_absolute_error: 0.0572\n",
      "Epoch 90/400\n",
      "423/423 [==============================] - 0s 408us/step - loss: 0.0136 - mean_absolute_error: 0.0590\n",
      "Epoch 91/400\n",
      "423/423 [==============================] - 0s 405us/step - loss: 0.0139 - mean_absolute_error: 0.0569\n",
      "Epoch 92/400\n",
      "423/423 [==============================] - 0s 392us/step - loss: 0.0133 - mean_absolute_error: 0.0560\n",
      "Epoch 93/400\n",
      "423/423 [==============================] - 0s 401us/step - loss: 0.0134 - mean_absolute_error: 0.0567\n",
      "Epoch 94/400\n",
      "423/423 [==============================] - 0s 400us/step - loss: 0.0134 - mean_absolute_error: 0.0550\n",
      "Epoch 95/400\n",
      "423/423 [==============================] - 0s 410us/step - loss: 0.0138 - mean_absolute_error: 0.0562\n",
      "Epoch 96/400\n",
      "423/423 [==============================] - 0s 408us/step - loss: 0.0133 - mean_absolute_error: 0.0551\n",
      "Epoch 97/400\n",
      "423/423 [==============================] - 0s 411us/step - loss: 0.0136 - mean_absolute_error: 0.0559\n",
      "Epoch 98/400\n",
      "423/423 [==============================] - 0s 424us/step - loss: 0.0136 - mean_absolute_error: 0.0556\n",
      "Epoch 99/400\n",
      "423/423 [==============================] - 0s 431us/step - loss: 0.0134 - mean_absolute_error: 0.0570\n",
      "Epoch 100/400\n",
      "423/423 [==============================] - 0s 431us/step - loss: 0.0125 - mean_absolute_error: 0.0546\n",
      "Epoch 101/400\n",
      "423/423 [==============================] - 0s 441us/step - loss: 0.0132 - mean_absolute_error: 0.0561\n",
      "Epoch 102/400\n",
      "423/423 [==============================] - 0s 397us/step - loss: 0.0132 - mean_absolute_error: 0.0547\n",
      "Epoch 103/400\n",
      "423/423 [==============================] - 0s 396us/step - loss: 0.0136 - mean_absolute_error: 0.0566\n",
      "Epoch 104/400\n",
      "423/423 [==============================] - 0s 382us/step - loss: 0.0136 - mean_absolute_error: 0.0552\n",
      "Epoch 105/400\n",
      "423/423 [==============================] - 0s 380us/step - loss: 0.0136 - mean_absolute_error: 0.0555\n",
      "Epoch 106/400\n",
      "423/423 [==============================] - 0s 376us/step - loss: 0.0134 - mean_absolute_error: 0.0546\n",
      "Epoch 107/400\n",
      "423/423 [==============================] - 0s 347us/step - loss: 0.0134 - mean_absolute_error: 0.0557\n",
      "Epoch 108/400\n",
      "423/423 [==============================] - 0s 349us/step - loss: 0.0135 - mean_absolute_error: 0.0551\n",
      "Epoch 109/400\n",
      "423/423 [==============================] - 0s 346us/step - loss: 0.0132 - mean_absolute_error: 0.0544\n",
      "Epoch 110/400\n",
      "423/423 [==============================] - 0s 348us/step - loss: 0.0130 - mean_absolute_error: 0.0550\n",
      "Epoch 111/400\n",
      "423/423 [==============================] - 0s 350us/step - loss: 0.0132 - mean_absolute_error: 0.0557\n",
      "Epoch 112/400\n",
      "423/423 [==============================] - 0s 349us/step - loss: 0.0131 - mean_absolute_error: 0.0539\n",
      "Epoch 113/400\n",
      "423/423 [==============================] - 0s 345us/step - loss: 0.0134 - mean_absolute_error: 0.0537\n",
      "Epoch 114/400\n",
      "423/423 [==============================] - 0s 340us/step - loss: 0.0131 - mean_absolute_error: 0.0548\n",
      "Epoch 115/400\n",
      "423/423 [==============================] - 0s 355us/step - loss: 0.0135 - mean_absolute_error: 0.0563\n",
      "Epoch 116/400\n",
      "423/423 [==============================] - 0s 351us/step - loss: 0.0131 - mean_absolute_error: 0.0559\n",
      "Epoch 117/400\n",
      "423/423 [==============================] - 0s 345us/step - loss: 0.0132 - mean_absolute_error: 0.0538\n",
      "Epoch 118/400\n",
      "423/423 [==============================] - 0s 347us/step - loss: 0.0131 - mean_absolute_error: 0.0533\n",
      "Epoch 119/400\n",
      "423/423 [==============================] - 0s 346us/step - loss: 0.0131 - mean_absolute_error: 0.0530\n",
      "Epoch 120/400\n",
      "423/423 [==============================] - 0s 344us/step - loss: 0.0128 - mean_absolute_error: 0.0527\n",
      "Epoch 121/400\n",
      "423/423 [==============================] - 0s 343us/step - loss: 0.0127 - mean_absolute_error: 0.0525\n",
      "Epoch 122/400\n",
      "423/423 [==============================] - 0s 348us/step - loss: 0.0128 - mean_absolute_error: 0.0531\n",
      "Epoch 123/400\n",
      "423/423 [==============================] - 0s 349us/step - loss: 0.0130 - mean_absolute_error: 0.0545\n",
      "Epoch 124/400\n",
      "423/423 [==============================] - 0s 443us/step - loss: 0.0134 - mean_absolute_error: 0.0549\n",
      "Epoch 125/400\n",
      "423/423 [==============================] - 0s 456us/step - loss: 0.0130 - mean_absolute_error: 0.0550\n",
      "Epoch 126/400\n",
      "423/423 [==============================] - 0s 387us/step - loss: 0.0125 - mean_absolute_error: 0.0531\n",
      "Epoch 127/400\n",
      "423/423 [==============================] - 0s 383us/step - loss: 0.0134 - mean_absolute_error: 0.0555\n",
      "Epoch 128/400\n",
      "423/423 [==============================] - 0s 379us/step - loss: 0.0125 - mean_absolute_error: 0.0519\n",
      "Epoch 129/400\n",
      "423/423 [==============================] - 0s 369us/step - loss: 0.0130 - mean_absolute_error: 0.0537\n",
      "Epoch 130/400\n",
      "423/423 [==============================] - 0s 442us/step - loss: 0.0129 - mean_absolute_error: 0.0540\n",
      "Epoch 131/400\n",
      "423/423 [==============================] - 0s 392us/step - loss: 0.0123 - mean_absolute_error: 0.0528\n",
      "Epoch 132/400\n",
      "423/423 [==============================] - 0s 372us/step - loss: 0.0126 - mean_absolute_error: 0.0537\n",
      "Epoch 133/400\n",
      "423/423 [==============================] - 0s 371us/step - loss: 0.0126 - mean_absolute_error: 0.0517\n",
      "Epoch 134/400\n",
      "423/423 [==============================] - 0s 376us/step - loss: 0.0122 - mean_absolute_error: 0.0514\n",
      "Epoch 135/400\n",
      "423/423 [==============================] - 0s 369us/step - loss: 0.0122 - mean_absolute_error: 0.0522\n",
      "Epoch 136/400\n",
      "423/423 [==============================] - 0s 397us/step - loss: 0.0124 - mean_absolute_error: 0.0530\n",
      "Epoch 137/400\n",
      "423/423 [==============================] - 0s 363us/step - loss: 0.0124 - mean_absolute_error: 0.0543\n",
      "Epoch 138/400\n",
      "423/423 [==============================] - 0s 374us/step - loss: 0.0125 - mean_absolute_error: 0.0537\n",
      "Epoch 139/400\n",
      "423/423 [==============================] - 0s 371us/step - loss: 0.0125 - mean_absolute_error: 0.0503\n",
      "Epoch 140/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "423/423 [==============================] - 0s 386us/step - loss: 0.0122 - mean_absolute_error: 0.0516\n",
      "Epoch 141/400\n",
      "423/423 [==============================] - 0s 361us/step - loss: 0.0123 - mean_absolute_error: 0.0519\n",
      "Epoch 142/400\n",
      "423/423 [==============================] - 0s 370us/step - loss: 0.0126 - mean_absolute_error: 0.0526\n",
      "Epoch 143/400\n",
      "423/423 [==============================] - 0s 359us/step - loss: 0.0126 - mean_absolute_error: 0.0523\n",
      "Epoch 144/400\n",
      "423/423 [==============================] - 0s 362us/step - loss: 0.0126 - mean_absolute_error: 0.0519\n",
      "Epoch 145/400\n",
      "423/423 [==============================] - 0s 371us/step - loss: 0.0118 - mean_absolute_error: 0.0504\n",
      "Epoch 146/400\n",
      "423/423 [==============================] - 0s 389us/step - loss: 0.0127 - mean_absolute_error: 0.0525\n",
      "Epoch 147/400\n",
      "423/423 [==============================] - 0s 357us/step - loss: 0.0120 - mean_absolute_error: 0.0523\n",
      "Epoch 148/400\n",
      "423/423 [==============================] - 0s 348us/step - loss: 0.0125 - mean_absolute_error: 0.0529\n",
      "Epoch 149/400\n",
      "423/423 [==============================] - 0s 356us/step - loss: 0.0126 - mean_absolute_error: 0.0524\n",
      "Epoch 150/400\n",
      "423/423 [==============================] - 0s 356us/step - loss: 0.0123 - mean_absolute_error: 0.0507\n",
      "Epoch 151/400\n",
      "423/423 [==============================] - 0s 359us/step - loss: 0.0121 - mean_absolute_error: 0.0508\n",
      "Epoch 152/400\n",
      "423/423 [==============================] - 0s 356us/step - loss: 0.0126 - mean_absolute_error: 0.0512\n",
      "Epoch 153/400\n",
      "423/423 [==============================] - 0s 365us/step - loss: 0.0120 - mean_absolute_error: 0.0516\n",
      "Epoch 154/400\n",
      "423/423 [==============================] - 0s 364us/step - loss: 0.0127 - mean_absolute_error: 0.0509\n",
      "Epoch 155/400\n",
      "423/423 [==============================] - 0s 356us/step - loss: 0.0121 - mean_absolute_error: 0.0498\n",
      "Epoch 156/400\n",
      "423/423 [==============================] - 0s 360us/step - loss: 0.0125 - mean_absolute_error: 0.0503\n",
      "Epoch 157/400\n",
      "423/423 [==============================] - 0s 349us/step - loss: 0.0120 - mean_absolute_error: 0.0513\n",
      "Epoch 158/400\n",
      "423/423 [==============================] - 0s 357us/step - loss: 0.0118 - mean_absolute_error: 0.0506\n",
      "Epoch 159/400\n",
      "423/423 [==============================] - 0s 356us/step - loss: 0.0119 - mean_absolute_error: 0.0500\n",
      "Epoch 160/400\n",
      "423/423 [==============================] - 0s 360us/step - loss: 0.0120 - mean_absolute_error: 0.0504\n",
      "Epoch 161/400\n",
      "423/423 [==============================] - 0s 356us/step - loss: 0.0115 - mean_absolute_error: 0.0493\n",
      "Epoch 162/400\n",
      "423/423 [==============================] - 0s 393us/step - loss: 0.0123 - mean_absolute_error: 0.0508\n",
      "Epoch 163/400\n",
      "423/423 [==============================] - 0s 410us/step - loss: 0.0115 - mean_absolute_error: 0.0493\n",
      "Epoch 164/400\n",
      "423/423 [==============================] - 0s 377us/step - loss: 0.0124 - mean_absolute_error: 0.0514\n",
      "Epoch 165/400\n",
      "423/423 [==============================] - 0s 406us/step - loss: 0.0122 - mean_absolute_error: 0.0493\n",
      "Epoch 166/400\n",
      "423/423 [==============================] - 0s 359us/step - loss: 0.0125 - mean_absolute_error: 0.0509\n",
      "Epoch 167/400\n",
      "423/423 [==============================] - 0s 382us/step - loss: 0.0123 - mean_absolute_error: 0.0499\n",
      "Epoch 168/400\n",
      "423/423 [==============================] - 0s 380us/step - loss: 0.0115 - mean_absolute_error: 0.0502\n",
      "Epoch 169/400\n",
      "423/423 [==============================] - 0s 398us/step - loss: 0.0117 - mean_absolute_error: 0.0509\n",
      "Epoch 170/400\n",
      "423/423 [==============================] - 0s 366us/step - loss: 0.0120 - mean_absolute_error: 0.0508\n",
      "Epoch 171/400\n",
      "423/423 [==============================] - 0s 406us/step - loss: 0.0114 - mean_absolute_error: 0.0503\n",
      "Epoch 172/400\n",
      "423/423 [==============================] - 0s 401us/step - loss: 0.0114 - mean_absolute_error: 0.0493\n",
      "Epoch 173/400\n",
      "423/423 [==============================] - 0s 415us/step - loss: 0.0116 - mean_absolute_error: 0.0482\n",
      "Epoch 174/400\n",
      "423/423 [==============================] - 0s 432us/step - loss: 0.0117 - mean_absolute_error: 0.0503\n",
      "Epoch 175/400\n",
      "423/423 [==============================] - 0s 520us/step - loss: 0.0116 - mean_absolute_error: 0.0481\n",
      "Epoch 176/400\n",
      "423/423 [==============================] - 0s 408us/step - loss: 0.0112 - mean_absolute_error: 0.0487\n",
      "Epoch 177/400\n",
      "423/423 [==============================] - 0s 410us/step - loss: 0.0121 - mean_absolute_error: 0.0502\n",
      "Epoch 178/400\n",
      "423/423 [==============================] - 0s 402us/step - loss: 0.0116 - mean_absolute_error: 0.0490\n",
      "Epoch 179/400\n",
      "423/423 [==============================] - 0s 406us/step - loss: 0.0124 - mean_absolute_error: 0.0514\n",
      "Epoch 180/400\n",
      "423/423 [==============================] - 0s 434us/step - loss: 0.0114 - mean_absolute_error: 0.0491\n",
      "Epoch 181/400\n",
      "423/423 [==============================] - 0s 414us/step - loss: 0.0115 - mean_absolute_error: 0.0496\n",
      "Epoch 182/400\n",
      "423/423 [==============================] - 0s 428us/step - loss: 0.0118 - mean_absolute_error: 0.0513\n",
      "Epoch 183/400\n",
      "423/423 [==============================] - 0s 557us/step - loss: 0.0120 - mean_absolute_error: 0.0502\n",
      "Epoch 184/400\n",
      "423/423 [==============================] - 0s 479us/step - loss: 0.0119 - mean_absolute_error: 0.0499\n",
      "Epoch 185/400\n",
      "423/423 [==============================] - 0s 421us/step - loss: 0.0118 - mean_absolute_error: 0.0486\n",
      "Epoch 186/400\n",
      "423/423 [==============================] - 0s 617us/step - loss: 0.0117 - mean_absolute_error: 0.0489\n",
      "Epoch 187/400\n",
      "423/423 [==============================] - 0s 532us/step - loss: 0.0121 - mean_absolute_error: 0.0497\n",
      "Epoch 188/400\n",
      "423/423 [==============================] - 0s 553us/step - loss: 0.0118 - mean_absolute_error: 0.0487\n",
      "Epoch 189/400\n",
      "423/423 [==============================] - 0s 452us/step - loss: 0.0115 - mean_absolute_error: 0.0486\n",
      "Epoch 190/400\n",
      "423/423 [==============================] - 0s 456us/step - loss: 0.0118 - mean_absolute_error: 0.0493\n",
      "Epoch 191/400\n",
      "423/423 [==============================] - 1s 1ms/step - loss: 0.0119 - mean_absolute_error: 0.0498\n",
      "Epoch 192/400\n",
      "423/423 [==============================] - 0s 567us/step - loss: 0.0117 - mean_absolute_error: 0.0495\n",
      "Epoch 193/400\n",
      "423/423 [==============================] - 0s 572us/step - loss: 0.0116 - mean_absolute_error: 0.0487\n",
      "Epoch 194/400\n",
      "423/423 [==============================] - 0s 485us/step - loss: 0.0119 - mean_absolute_error: 0.0498\n",
      "Epoch 195/400\n",
      "423/423 [==============================] - 0s 558us/step - loss: 0.0122 - mean_absolute_error: 0.0481\n",
      "Epoch 196/400\n",
      "423/423 [==============================] - 0s 532us/step - loss: 0.0116 - mean_absolute_error: 0.0494\n",
      "Epoch 197/400\n",
      "423/423 [==============================] - 0s 529us/step - loss: 0.0114 - mean_absolute_error: 0.0487\n",
      "Epoch 198/400\n",
      "423/423 [==============================] - 0s 560us/step - loss: 0.0113 - mean_absolute_error: 0.0479\n",
      "Epoch 199/400\n",
      "423/423 [==============================] - 0s 544us/step - loss: 0.0123 - mean_absolute_error: 0.0510\n",
      "Epoch 200/400\n",
      "423/423 [==============================] - 0s 590us/step - loss: 0.0115 - mean_absolute_error: 0.0479\n",
      "Epoch 201/400\n",
      "423/423 [==============================] - 0s 580us/step - loss: 0.0116 - mean_absolute_error: 0.0478\n",
      "Epoch 202/400\n",
      "423/423 [==============================] - 0s 615us/step - loss: 0.0119 - mean_absolute_error: 0.0481\n",
      "Epoch 203/400\n",
      "423/423 [==============================] - 0s 528us/step - loss: 0.0114 - mean_absolute_error: 0.0475\n",
      "Epoch 204/400\n",
      "423/423 [==============================] - 0s 552us/step - loss: 0.0118 - mean_absolute_error: 0.0494\n",
      "Epoch 205/400\n",
      "423/423 [==============================] - 0s 565us/step - loss: 0.0120 - mean_absolute_error: 0.0473\n",
      "Epoch 206/400\n",
      "423/423 [==============================] - 0s 535us/step - loss: 0.0112 - mean_absolute_error: 0.0481\n",
      "Epoch 207/400\n",
      "423/423 [==============================] - 0s 551us/step - loss: 0.0118 - mean_absolute_error: 0.0486\n",
      "Epoch 208/400\n",
      "423/423 [==============================] - 0s 604us/step - loss: 0.0115 - mean_absolute_error: 0.0480\n",
      "Epoch 209/400\n",
      "423/423 [==============================] - 0s 577us/step - loss: 0.0119 - mean_absolute_error: 0.0488\n",
      "Epoch 210/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "423/423 [==============================] - 0s 690us/step - loss: 0.0117 - mean_absolute_error: 0.0504\n",
      "Epoch 211/400\n",
      "423/423 [==============================] - 0s 1ms/step - loss: 0.0120 - mean_absolute_error: 0.0482\n",
      "Epoch 212/400\n",
      "423/423 [==============================] - 0s 597us/step - loss: 0.0118 - mean_absolute_error: 0.0474\n",
      "Epoch 213/400\n",
      "423/423 [==============================] - 0s 554us/step - loss: 0.0111 - mean_absolute_error: 0.0463\n",
      "Epoch 214/400\n",
      "423/423 [==============================] - 0s 585us/step - loss: 0.0115 - mean_absolute_error: 0.0479\n",
      "Epoch 215/400\n",
      "423/423 [==============================] - 0s 637us/step - loss: 0.0118 - mean_absolute_error: 0.0489\n",
      "Epoch 216/400\n",
      "423/423 [==============================] - 0s 551us/step - loss: 0.0119 - mean_absolute_error: 0.0487\n",
      "Epoch 217/400\n",
      "423/423 [==============================] - 0s 588us/step - loss: 0.0116 - mean_absolute_error: 0.0475\n",
      "Epoch 218/400\n",
      "423/423 [==============================] - 0s 727us/step - loss: 0.0109 - mean_absolute_error: 0.0473\n",
      "Epoch 219/400\n",
      "423/423 [==============================] - 0s 589us/step - loss: 0.0121 - mean_absolute_error: 0.0491\n",
      "Epoch 220/400\n",
      "423/423 [==============================] - 0s 566us/step - loss: 0.0115 - mean_absolute_error: 0.0483\n",
      "Epoch 221/400\n",
      "423/423 [==============================] - 0s 539us/step - loss: 0.0112 - mean_absolute_error: 0.0470\n",
      "Epoch 222/400\n",
      "423/423 [==============================] - 0s 597us/step - loss: 0.0116 - mean_absolute_error: 0.0491\n",
      "Epoch 223/400\n",
      "423/423 [==============================] - 0s 565us/step - loss: 0.0118 - mean_absolute_error: 0.0494\n",
      "Epoch 224/400\n",
      "423/423 [==============================] - 0s 559us/step - loss: 0.0112 - mean_absolute_error: 0.0471\n",
      "Epoch 225/400\n",
      "423/423 [==============================] - 0s 633us/step - loss: 0.0118 - mean_absolute_error: 0.0499\n",
      "Epoch 226/400\n",
      "423/423 [==============================] - 0s 575us/step - loss: 0.0116 - mean_absolute_error: 0.0477\n",
      "Epoch 227/400\n",
      "423/423 [==============================] - 0s 545us/step - loss: 0.0114 - mean_absolute_error: 0.0465\n",
      "Epoch 228/400\n",
      "423/423 [==============================] - 0s 593us/step - loss: 0.0117 - mean_absolute_error: 0.0485\n",
      "Epoch 229/400\n",
      "423/423 [==============================] - 0s 550us/step - loss: 0.0114 - mean_absolute_error: 0.0466\n",
      "Epoch 230/400\n",
      "423/423 [==============================] - 0s 659us/step - loss: 0.0118 - mean_absolute_error: 0.0475\n",
      "Epoch 231/400\n",
      "423/423 [==============================] - 0s 605us/step - loss: 0.0116 - mean_absolute_error: 0.0480\n",
      "Epoch 232/400\n",
      "423/423 [==============================] - 0s 635us/step - loss: 0.0115 - mean_absolute_error: 0.0451\n",
      "Epoch 233/400\n",
      "423/423 [==============================] - 0s 554us/step - loss: 0.0116 - mean_absolute_error: 0.0490\n",
      "Epoch 234/400\n",
      "423/423 [==============================] - 0s 556us/step - loss: 0.0114 - mean_absolute_error: 0.0474\n",
      "Epoch 235/400\n",
      "423/423 [==============================] - 0s 541us/step - loss: 0.0117 - mean_absolute_error: 0.0490\n",
      "Epoch 236/400\n",
      "423/423 [==============================] - 0s 555us/step - loss: 0.0118 - mean_absolute_error: 0.0477\n",
      "Epoch 237/400\n",
      "423/423 [==============================] - 0s 541us/step - loss: 0.0114 - mean_absolute_error: 0.0471\n",
      "Epoch 238/400\n",
      "423/423 [==============================] - 0s 542us/step - loss: 0.0111 - mean_absolute_error: 0.0474\n",
      "Epoch 239/400\n",
      "423/423 [==============================] - 0s 631us/step - loss: 0.0113 - mean_absolute_error: 0.0485\n",
      "Epoch 240/400\n",
      "423/423 [==============================] - 0s 624us/step - loss: 0.0113 - mean_absolute_error: 0.0482\n",
      "Epoch 241/400\n",
      "423/423 [==============================] - 0s 521us/step - loss: 0.0113 - mean_absolute_error: 0.0472\n",
      "Epoch 242/400\n",
      "423/423 [==============================] - 0s 551us/step - loss: 0.0119 - mean_absolute_error: 0.0484\n",
      "Epoch 243/400\n",
      "423/423 [==============================] - 0s 480us/step - loss: 0.0117 - mean_absolute_error: 0.0475\n",
      "Epoch 244/400\n",
      "423/423 [==============================] - 0s 498us/step - loss: 0.0112 - mean_absolute_error: 0.0471\n",
      "Epoch 245/400\n",
      "423/423 [==============================] - 0s 489us/step - loss: 0.0121 - mean_absolute_error: 0.0500\n",
      "Epoch 246/400\n",
      "423/423 [==============================] - 0s 453us/step - loss: 0.0109 - mean_absolute_error: 0.0474\n",
      "Epoch 247/400\n",
      "423/423 [==============================] - 0s 490us/step - loss: 0.0107 - mean_absolute_error: 0.0452\n",
      "Epoch 248/400\n",
      "423/423 [==============================] - 0s 459us/step - loss: 0.0115 - mean_absolute_error: 0.0479\n",
      "Epoch 249/400\n",
      "423/423 [==============================] - 0s 439us/step - loss: 0.0117 - mean_absolute_error: 0.0484\n",
      "Epoch 250/400\n",
      "423/423 [==============================] - 0s 446us/step - loss: 0.0114 - mean_absolute_error: 0.0465\n",
      "Epoch 251/400\n",
      "423/423 [==============================] - 0s 440us/step - loss: 0.0119 - mean_absolute_error: 0.0485\n",
      "Epoch 252/400\n",
      "423/423 [==============================] - 0s 441us/step - loss: 0.0120 - mean_absolute_error: 0.0469\n",
      "Epoch 253/400\n",
      "423/423 [==============================] - 0s 427us/step - loss: 0.0121 - mean_absolute_error: 0.0495\n",
      "Epoch 254/400\n",
      "423/423 [==============================] - 0s 419us/step - loss: 0.0110 - mean_absolute_error: 0.0462\n",
      "Epoch 255/400\n",
      "423/423 [==============================] - 0s 461us/step - loss: 0.0121 - mean_absolute_error: 0.0476\n",
      "Epoch 256/400\n",
      "423/423 [==============================] - 0s 521us/step - loss: 0.0113 - mean_absolute_error: 0.0466\n",
      "Epoch 257/400\n",
      "423/423 [==============================] - 0s 446us/step - loss: 0.0111 - mean_absolute_error: 0.0479\n",
      "Epoch 258/400\n",
      "423/423 [==============================] - 0s 410us/step - loss: 0.0119 - mean_absolute_error: 0.0482\n",
      "Epoch 259/400\n",
      "423/423 [==============================] - 0s 421us/step - loss: 0.0112 - mean_absolute_error: 0.0464\n",
      "Epoch 260/400\n",
      "423/423 [==============================] - 0s 438us/step - loss: 0.0115 - mean_absolute_error: 0.0481\n",
      "Epoch 261/400\n",
      "423/423 [==============================] - 0s 394us/step - loss: 0.0116 - mean_absolute_error: 0.0471\n",
      "Epoch 262/400\n",
      "423/423 [==============================] - 0s 390us/step - loss: 0.0112 - mean_absolute_error: 0.0474\n",
      "Epoch 263/400\n",
      "423/423 [==============================] - 0s 445us/step - loss: 0.0112 - mean_absolute_error: 0.0476\n",
      "Epoch 264/400\n",
      "423/423 [==============================] - 0s 410us/step - loss: 0.0105 - mean_absolute_error: 0.0454\n",
      "Epoch 265/400\n",
      "423/423 [==============================] - 0s 387us/step - loss: 0.0111 - mean_absolute_error: 0.0480\n",
      "Epoch 266/400\n",
      "423/423 [==============================] - 0s 394us/step - loss: 0.0104 - mean_absolute_error: 0.0466\n",
      "Epoch 267/400\n",
      "423/423 [==============================] - 0s 410us/step - loss: 0.0108 - mean_absolute_error: 0.0475\n",
      "Epoch 268/400\n",
      "423/423 [==============================] - 0s 388us/step - loss: 0.0110 - mean_absolute_error: 0.0485\n",
      "Epoch 269/400\n",
      "423/423 [==============================] - 0s 372us/step - loss: 0.0111 - mean_absolute_error: 0.0481\n",
      "Epoch 270/400\n",
      "423/423 [==============================] - 0s 411us/step - loss: 0.0112 - mean_absolute_error: 0.0477\n",
      "Epoch 271/400\n",
      "423/423 [==============================] - 0s 410us/step - loss: 0.0114 - mean_absolute_error: 0.0478\n",
      "Epoch 272/400\n",
      "423/423 [==============================] - 0s 370us/step - loss: 0.0111 - mean_absolute_error: 0.0487\n",
      "Epoch 273/400\n",
      "423/423 [==============================] - 0s 375us/step - loss: 0.0112 - mean_absolute_error: 0.0482\n",
      "Epoch 274/400\n",
      "423/423 [==============================] - 0s 405us/step - loss: 0.0108 - mean_absolute_error: 0.0467\n",
      "Epoch 275/400\n",
      "423/423 [==============================] - 0s 399us/step - loss: 0.0114 - mean_absolute_error: 0.0480\n",
      "Epoch 276/400\n",
      "423/423 [==============================] - 0s 365us/step - loss: 0.0125 - mean_absolute_error: 0.0496\n",
      "Epoch 277/400\n",
      "423/423 [==============================] - 0s 371us/step - loss: 0.0115 - mean_absolute_error: 0.0466\n",
      "Epoch 278/400\n",
      "423/423 [==============================] - 0s 385us/step - loss: 0.0113 - mean_absolute_error: 0.0467\n",
      "Epoch 279/400\n",
      "423/423 [==============================] - 0s 359us/step - loss: 0.0108 - mean_absolute_error: 0.0474\n",
      "Epoch 280/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "423/423 [==============================] - 0s 377us/step - loss: 0.0114 - mean_absolute_error: 0.0478\n",
      "Epoch 281/400\n",
      "423/423 [==============================] - 0s 367us/step - loss: 0.0109 - mean_absolute_error: 0.0465\n",
      "Epoch 282/400\n",
      "423/423 [==============================] - 0s 352us/step - loss: 0.0112 - mean_absolute_error: 0.0475\n",
      "Epoch 283/400\n",
      "423/423 [==============================] - 0s 355us/step - loss: 0.0114 - mean_absolute_error: 0.0491\n",
      "Epoch 284/400\n",
      "423/423 [==============================] - 0s 384us/step - loss: 0.0112 - mean_absolute_error: 0.0461\n",
      "Epoch 285/400\n",
      "423/423 [==============================] - 0s 387us/step - loss: 0.0112 - mean_absolute_error: 0.0474\n",
      "Epoch 286/400\n",
      "423/423 [==============================] - 0s 352us/step - loss: 0.0117 - mean_absolute_error: 0.0463\n",
      "Epoch 287/400\n",
      "423/423 [==============================] - 0s 354us/step - loss: 0.0108 - mean_absolute_error: 0.0448\n",
      "Epoch 288/400\n",
      "423/423 [==============================] - 0s 446us/step - loss: 0.0109 - mean_absolute_error: 0.0477\n",
      "Epoch 289/400\n",
      "423/423 [==============================] - 0s 358us/step - loss: 0.0114 - mean_absolute_error: 0.0499\n",
      "Epoch 290/400\n",
      "423/423 [==============================] - 0s 358us/step - loss: 0.0108 - mean_absolute_error: 0.0467\n",
      "Epoch 291/400\n",
      "423/423 [==============================] - 0s 404us/step - loss: 0.0118 - mean_absolute_error: 0.0480\n",
      "Epoch 292/400\n",
      "423/423 [==============================] - 0s 367us/step - loss: 0.0113 - mean_absolute_error: 0.0470\n",
      "Epoch 293/400\n",
      "423/423 [==============================] - 0s 362us/step - loss: 0.0119 - mean_absolute_error: 0.0488\n",
      "Epoch 294/400\n",
      "423/423 [==============================] - 0s 472us/step - loss: 0.0114 - mean_absolute_error: 0.0467\n",
      "Epoch 295/400\n",
      "423/423 [==============================] - 0s 361us/step - loss: 0.0112 - mean_absolute_error: 0.0472\n",
      "Epoch 296/400\n",
      "423/423 [==============================] - 0s 355us/step - loss: 0.0110 - mean_absolute_error: 0.0463\n",
      "Epoch 297/400\n",
      "423/423 [==============================] - 0s 353us/step - loss: 0.0113 - mean_absolute_error: 0.0485\n",
      "Epoch 298/400\n",
      "423/423 [==============================] - 0s 377us/step - loss: 0.0110 - mean_absolute_error: 0.0460\n",
      "Epoch 299/400\n",
      "423/423 [==============================] - 0s 367us/step - loss: 0.0108 - mean_absolute_error: 0.0475\n",
      "Epoch 300/400\n",
      "423/423 [==============================] - 0s 365us/step - loss: 0.0112 - mean_absolute_error: 0.0465\n",
      "Epoch 301/400\n",
      "423/423 [==============================] - 0s 368us/step - loss: 0.0117 - mean_absolute_error: 0.0468\n",
      "Epoch 302/400\n",
      "423/423 [==============================] - 0s 358us/step - loss: 0.0117 - mean_absolute_error: 0.0471\n",
      "Epoch 303/400\n",
      "423/423 [==============================] - 0s 359us/step - loss: 0.0117 - mean_absolute_error: 0.0482\n",
      "Epoch 304/400\n",
      "423/423 [==============================] - 0s 357us/step - loss: 0.0106 - mean_absolute_error: 0.0457\n",
      "Epoch 305/400\n",
      "423/423 [==============================] - 0s 371us/step - loss: 0.0109 - mean_absolute_error: 0.0478\n",
      "Epoch 306/400\n",
      "423/423 [==============================] - 0s 358us/step - loss: 0.0110 - mean_absolute_error: 0.0470\n",
      "Epoch 307/400\n",
      "423/423 [==============================] - 0s 393us/step - loss: 0.0115 - mean_absolute_error: 0.0464\n",
      "Epoch 308/400\n",
      "423/423 [==============================] - 0s 360us/step - loss: 0.0111 - mean_absolute_error: 0.0459\n",
      "Epoch 309/400\n",
      "423/423 [==============================] - 0s 355us/step - loss: 0.0096 - mean_absolute_error: 0.0459\n",
      "Epoch 310/400\n",
      "423/423 [==============================] - 0s 355us/step - loss: 0.0117 - mean_absolute_error: 0.0477\n",
      "Epoch 311/400\n",
      "423/423 [==============================] - 0s 386us/step - loss: 0.0117 - mean_absolute_error: 0.0475\n",
      "Epoch 312/400\n",
      "423/423 [==============================] - 0s 424us/step - loss: 0.0111 - mean_absolute_error: 0.0467\n",
      "Epoch 313/400\n",
      "423/423 [==============================] - 0s 387us/step - loss: 0.0117 - mean_absolute_error: 0.0467\n",
      "Epoch 314/400\n",
      "423/423 [==============================] - 0s 355us/step - loss: 0.0117 - mean_absolute_error: 0.0478\n",
      "Epoch 315/400\n",
      "423/423 [==============================] - 0s 354us/step - loss: 0.0118 - mean_absolute_error: 0.0469\n",
      "Epoch 316/400\n",
      "423/423 [==============================] - 0s 355us/step - loss: 0.0118 - mean_absolute_error: 0.0478\n",
      "Epoch 317/400\n",
      "423/423 [==============================] - 0s 386us/step - loss: 0.0114 - mean_absolute_error: 0.0476\n",
      "Epoch 318/400\n",
      "423/423 [==============================] - 0s 391us/step - loss: 0.0109 - mean_absolute_error: 0.0470\n",
      "Epoch 319/400\n",
      "423/423 [==============================] - 0s 398us/step - loss: 0.0112 - mean_absolute_error: 0.0457\n",
      "Epoch 320/400\n",
      "423/423 [==============================] - 0s 383us/step - loss: 0.0109 - mean_absolute_error: 0.0455\n",
      "Epoch 321/400\n",
      "423/423 [==============================] - 0s 372us/step - loss: 0.0107 - mean_absolute_error: 0.0463\n",
      "Epoch 322/400\n",
      "423/423 [==============================] - 0s 403us/step - loss: 0.0104 - mean_absolute_error: 0.0459\n",
      "Epoch 323/400\n",
      "423/423 [==============================] - 0s 412us/step - loss: 0.0112 - mean_absolute_error: 0.0480\n",
      "Epoch 324/400\n",
      "423/423 [==============================] - 0s 388us/step - loss: 0.0113 - mean_absolute_error: 0.0465\n",
      "Epoch 325/400\n",
      "423/423 [==============================] - 0s 411us/step - loss: 0.0106 - mean_absolute_error: 0.0468\n",
      "Epoch 326/400\n",
      "423/423 [==============================] - 0s 371us/step - loss: 0.0114 - mean_absolute_error: 0.0485\n",
      "Epoch 327/400\n",
      "423/423 [==============================] - 0s 471us/step - loss: 0.0110 - mean_absolute_error: 0.0470\n",
      "Epoch 328/400\n",
      "423/423 [==============================] - 0s 462us/step - loss: 0.0107 - mean_absolute_error: 0.0475\n",
      "Epoch 329/400\n",
      "423/423 [==============================] - 0s 442us/step - loss: 0.0102 - mean_absolute_error: 0.0465\n",
      "Epoch 330/400\n",
      "423/423 [==============================] - 0s 405us/step - loss: 0.0106 - mean_absolute_error: 0.0476\n",
      "Epoch 331/400\n",
      "423/423 [==============================] - 0s 410us/step - loss: 0.0117 - mean_absolute_error: 0.0481\n",
      "Epoch 332/400\n",
      "423/423 [==============================] - 0s 397us/step - loss: 0.0116 - mean_absolute_error: 0.0466\n",
      "Epoch 333/400\n",
      "423/423 [==============================] - 0s 413us/step - loss: 0.0107 - mean_absolute_error: 0.0478\n",
      "Epoch 334/400\n",
      "423/423 [==============================] - 0s 411us/step - loss: 0.0105 - mean_absolute_error: 0.0453\n",
      "Epoch 335/400\n",
      "423/423 [==============================] - 0s 415us/step - loss: 0.0107 - mean_absolute_error: 0.0454\n",
      "Epoch 336/400\n",
      "423/423 [==============================] - 0s 514us/step - loss: 0.0115 - mean_absolute_error: 0.0478\n",
      "Epoch 337/400\n",
      "423/423 [==============================] - 0s 436us/step - loss: 0.0105 - mean_absolute_error: 0.0453\n",
      "Epoch 338/400\n",
      "423/423 [==============================] - 0s 419us/step - loss: 0.0114 - mean_absolute_error: 0.0475\n",
      "Epoch 339/400\n",
      "423/423 [==============================] - 0s 431us/step - loss: 0.0103 - mean_absolute_error: 0.0469\n",
      "Epoch 340/400\n",
      "423/423 [==============================] - 0s 405us/step - loss: 0.0111 - mean_absolute_error: 0.0465\n",
      "Epoch 341/400\n",
      "423/423 [==============================] - 0s 398us/step - loss: 0.0111 - mean_absolute_error: 0.0490\n",
      "Epoch 342/400\n",
      "423/423 [==============================] - 0s 404us/step - loss: 0.0109 - mean_absolute_error: 0.0461\n",
      "Epoch 343/400\n",
      "423/423 [==============================] - 0s 402us/step - loss: 0.0108 - mean_absolute_error: 0.0460\n",
      "Epoch 344/400\n",
      "423/423 [==============================] - 0s 476us/step - loss: 0.0109 - mean_absolute_error: 0.0450\n",
      "Epoch 345/400\n",
      "423/423 [==============================] - 0s 443us/step - loss: 0.0111 - mean_absolute_error: 0.0477\n",
      "Epoch 346/400\n",
      "423/423 [==============================] - 0s 432us/step - loss: 0.0109 - mean_absolute_error: 0.0472\n",
      "Epoch 347/400\n",
      "423/423 [==============================] - 0s 418us/step - loss: 0.0104 - mean_absolute_error: 0.0456\n",
      "Epoch 348/400\n",
      "423/423 [==============================] - 0s 429us/step - loss: 0.0108 - mean_absolute_error: 0.0456\n",
      "Epoch 349/400\n",
      "423/423 [==============================] - 0s 431us/step - loss: 0.0101 - mean_absolute_error: 0.0451\n",
      "Epoch 350/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "423/423 [==============================] - 0s 467us/step - loss: 0.0114 - mean_absolute_error: 0.0480\n",
      "Epoch 351/400\n",
      "423/423 [==============================] - 0s 498us/step - loss: 0.0108 - mean_absolute_error: 0.0466\n",
      "Epoch 352/400\n",
      "423/423 [==============================] - 0s 531us/step - loss: 0.0109 - mean_absolute_error: 0.0475\n",
      "Epoch 353/400\n",
      "423/423 [==============================] - 0s 420us/step - loss: 0.0113 - mean_absolute_error: 0.0475\n",
      "Epoch 354/400\n",
      "423/423 [==============================] - 0s 461us/step - loss: 0.0106 - mean_absolute_error: 0.0455\n",
      "Epoch 355/400\n",
      "423/423 [==============================] - 0s 424us/step - loss: 0.0101 - mean_absolute_error: 0.0446\n",
      "Epoch 356/400\n",
      "423/423 [==============================] - 0s 475us/step - loss: 0.0103 - mean_absolute_error: 0.0451\n",
      "Epoch 357/400\n",
      "423/423 [==============================] - 0s 432us/step - loss: 0.0104 - mean_absolute_error: 0.0454\n",
      "Epoch 358/400\n",
      "423/423 [==============================] - 0s 486us/step - loss: 0.0113 - mean_absolute_error: 0.0476\n",
      "Epoch 359/400\n",
      "423/423 [==============================] - 0s 526us/step - loss: 0.0112 - mean_absolute_error: 0.0475\n",
      "Epoch 360/400\n",
      "423/423 [==============================] - 0s 447us/step - loss: 0.0111 - mean_absolute_error: 0.0454\n",
      "Epoch 361/400\n",
      "423/423 [==============================] - 0s 483us/step - loss: 0.0109 - mean_absolute_error: 0.0479\n",
      "Epoch 362/400\n",
      "423/423 [==============================] - 0s 446us/step - loss: 0.0110 - mean_absolute_error: 0.0453\n",
      "Epoch 363/400\n",
      "423/423 [==============================] - 0s 455us/step - loss: 0.0110 - mean_absolute_error: 0.0460\n",
      "Epoch 364/400\n",
      "423/423 [==============================] - 0s 466us/step - loss: 0.0110 - mean_absolute_error: 0.0473\n",
      "Epoch 365/400\n",
      "423/423 [==============================] - 0s 443us/step - loss: 0.0105 - mean_absolute_error: 0.0455\n",
      "Epoch 366/400\n",
      "423/423 [==============================] - 0s 445us/step - loss: 0.0104 - mean_absolute_error: 0.0455\n",
      "Epoch 367/400\n",
      "423/423 [==============================] - 0s 586us/step - loss: 0.0115 - mean_absolute_error: 0.0482\n",
      "Epoch 368/400\n",
      "423/423 [==============================] - 0s 505us/step - loss: 0.0111 - mean_absolute_error: 0.0465\n",
      "Epoch 369/400\n",
      "423/423 [==============================] - 0s 505us/step - loss: 0.0108 - mean_absolute_error: 0.0462\n",
      "Epoch 370/400\n",
      "423/423 [==============================] - 0s 458us/step - loss: 0.0107 - mean_absolute_error: 0.0471\n",
      "Epoch 371/400\n",
      "423/423 [==============================] - 0s 464us/step - loss: 0.0108 - mean_absolute_error: 0.0466\n",
      "Epoch 372/400\n",
      "423/423 [==============================] - 0s 472us/step - loss: 0.0116 - mean_absolute_error: 0.0464\n",
      "Epoch 373/400\n",
      "423/423 [==============================] - 0s 478us/step - loss: 0.0111 - mean_absolute_error: 0.0480\n",
      "Epoch 374/400\n",
      "423/423 [==============================] - 0s 426us/step - loss: 0.0108 - mean_absolute_error: 0.0456\n",
      "Epoch 375/400\n",
      "423/423 [==============================] - 0s 535us/step - loss: 0.0106 - mean_absolute_error: 0.0460\n",
      "Epoch 376/400\n",
      "423/423 [==============================] - 0s 494us/step - loss: 0.0105 - mean_absolute_error: 0.0452\n",
      "Epoch 377/400\n",
      "423/423 [==============================] - 0s 470us/step - loss: 0.0111 - mean_absolute_error: 0.0477\n",
      "Epoch 378/400\n",
      "423/423 [==============================] - 0s 446us/step - loss: 0.0108 - mean_absolute_error: 0.0465\n",
      "Epoch 379/400\n",
      "423/423 [==============================] - 0s 468us/step - loss: 0.0106 - mean_absolute_error: 0.0465\n",
      "Epoch 380/400\n",
      "423/423 [==============================] - 0s 477us/step - loss: 0.0107 - mean_absolute_error: 0.0458\n",
      "Epoch 381/400\n",
      "423/423 [==============================] - 0s 478us/step - loss: 0.0108 - mean_absolute_error: 0.0475\n",
      "Epoch 382/400\n",
      "423/423 [==============================] - 0s 471us/step - loss: 0.0109 - mean_absolute_error: 0.0449\n",
      "Epoch 383/400\n",
      "423/423 [==============================] - 0s 524us/step - loss: 0.0109 - mean_absolute_error: 0.0471\n",
      "Epoch 384/400\n",
      "423/423 [==============================] - 0s 500us/step - loss: 0.0108 - mean_absolute_error: 0.0454\n",
      "Epoch 385/400\n",
      "423/423 [==============================] - 0s 474us/step - loss: 0.0107 - mean_absolute_error: 0.0469\n",
      "Epoch 386/400\n",
      "423/423 [==============================] - 0s 453us/step - loss: 0.0110 - mean_absolute_error: 0.0468\n",
      "Epoch 387/400\n",
      "423/423 [==============================] - 0s 485us/step - loss: 0.0109 - mean_absolute_error: 0.0472\n",
      "Epoch 388/400\n",
      "423/423 [==============================] - 0s 538us/step - loss: 0.0113 - mean_absolute_error: 0.0471\n",
      "Epoch 389/400\n",
      "423/423 [==============================] - 0s 638us/step - loss: 0.0114 - mean_absolute_error: 0.0479\n",
      "Epoch 390/400\n",
      "423/423 [==============================] - 0s 522us/step - loss: 0.0106 - mean_absolute_error: 0.0453\n",
      "Epoch 391/400\n",
      "423/423 [==============================] - 0s 515us/step - loss: 0.0114 - mean_absolute_error: 0.0457\n",
      "Epoch 392/400\n",
      "423/423 [==============================] - 0s 578us/step - loss: 0.0109 - mean_absolute_error: 0.0454\n",
      "Epoch 393/400\n",
      "423/423 [==============================] - 0s 595us/step - loss: 0.0112 - mean_absolute_error: 0.0475\n",
      "Epoch 394/400\n",
      "423/423 [==============================] - 0s 530us/step - loss: 0.0105 - mean_absolute_error: 0.0460\n",
      "Epoch 395/400\n",
      "423/423 [==============================] - 0s 520us/step - loss: 0.0109 - mean_absolute_error: 0.0461\n",
      "Epoch 396/400\n",
      "423/423 [==============================] - 0s 447us/step - loss: 0.0105 - mean_absolute_error: 0.0449\n",
      "Epoch 397/400\n",
      "423/423 [==============================] - 0s 456us/step - loss: 0.0106 - mean_absolute_error: 0.0457\n",
      "Epoch 398/400\n",
      "423/423 [==============================] - 0s 456us/step - loss: 0.0110 - mean_absolute_error: 0.0464\n",
      "Epoch 399/400\n",
      "423/423 [==============================] - 0s 439us/step - loss: 0.0113 - mean_absolute_error: 0.0480\n",
      "Epoch 400/400\n",
      "423/423 [==============================] - 0s 475us/step - loss: 0.0110 - mean_absolute_error: 0.0451\n"
     ]
    }
   ],
   "source": [
    "model1 = baseline_model_31()\n",
    "\n",
    "# estimator1 = train_data_nn_1(X_new1, Y_rob_train)\n",
    "\n",
    "# print(X_new.shape)\n",
    "# print(y_train.shape)\n",
    "history_1 = model1.fit(X_new1,  Y_rob_train_c, epochs=400, batch_size=5,  verbose=1, validation_split=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 625
    },
    "colab_type": "code",
    "id": "O1YTEBaakaUU",
    "outputId": "da7664ff-a38e-43cd-ff9a-d6874599cf22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(423, 2)\n",
      "0.009781519908468818\n",
      "dict_keys(['loss', 'mean_absolute_error'])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3de5xdZX3v8c93X+aWhCQkkUKCJCoqiBB0pChUqVUaQMGqFaxY9dim7dFqb57C0Yqlpy1tz+lFxSJqDmoVvCA17YEiqKg9CDJoxHAPGE0ikpCQe+ay9/71j/XsPXsmeyYzIWv2kPm+X5nXrPWstfb6zTOT/dvP86z1LEUEZmZmoxXaHYCZmU1PThBmZtaSE4SZmbXkBGFmZi05QZiZWUtOEGZm1pIThNkhIOkaSf9rgvuul/Sqp/o6ZnlzgjAzs5acIMzMrCUnCJsxUtfO+yTdI2mPpE9JOkrSTZJ2SbpV0vym/c+XdK+k7ZJuk3RC07ZTJX0/HfcFoGvUuV4jaU069nZJJx9kzL8taZ2kbZJWSzomlUvSP0jaLGmnpB9JOiltO1fSfSm2TZL+5KAqzGY8Jwibad4AvBp4LvBa4CbgfwKLyP4/vAdA0nOBa4E/SNtuBP5NUoekDuBfgc8CRwJfSq9LOvZUYBXwO8AC4OPAakmdkwlU0iuBvwbeBBwN/AS4Lm0+G3h5+jnmpn22pm2fAn4nIuYAJwHfmMx5zeqcIGym+UhEPB4Rm4DvAHdGxA8ioh+4ATg17Xch8P8i4paIGAL+N9ANvAw4HSgD/xgRQxHxZeCupnOsBD4eEXdGRDUiPg0MpOMm4y3Aqoj4fkQMAJcCL5W0FBgC5gDPBxQR90fEY+m4IeBESUdExJMR8f1JntcMcIKwmefxpuV9LdZnp+VjyD6xAxARNWADsDht2xQjZ7r8SdPyccAfp+6l7ZK2A8em4yZjdAy7yVoJiyPiG8BHgSuBzZKulnRE2vUNwLnATyR9S9JLJ3leM8AJwmwsPyN7oweyPn+yN/lNwGPA4lRW98ym5Q3AX0bEvKavnoi49inGMIusy2oTQER8OCJeDJxI1tX0vlR+V0RcADyDrCvsi5M8rxngBGE2li8C50n6FUll4I/JuoluB74LVID3SCpLej1wWtOxnwB+V9IvpsHkWZLOkzRnkjFcC7xD0vI0fvFXZF1i6yW9JL1+GdgD9AO1NEbyFklzU9fYTqD2FOrBZjAnCLMWIuJB4GLgI8ATZAPar42IwYgYBF4PvB3YRjZe8ZWmY/uA3ybrAnoSWJf2nWwMtwJ/BlxP1mp5NnBR2nwEWSJ6kqwbaivwd2nbW4H1knYCv0s2lmE2afIDg8zMrBW3IMzMrCUnCDMza8kJwszMWnKCMDOzlkrtDuBQWrhwYSxdurTdYZiZPW3cfffdT0TEolbbDqsEsXTpUvr6+todhpnZ04akn4y1zV1MZmbWkhOEmZm15ARhZmYtHVZjEK0MDQ2xceNG+vv72x1Krrq6uliyZAnlcrndoZjZYeKwTxAbN25kzpw5LF26lJGTbx4+IoKtW7eyceNGli1b1u5wzOwwcdh3MfX397NgwYLDNjkASGLBggWHfSvJzKbWYZ8ggMM6OdTNhJ/RzKbWjEgQB/L4zn529Q+1Owwzs2nFCQLYsmuA3QOVXF57+/btfOxjH5v0ceeeey7bt2/PISIzs4lxgkjyeizGWAmiUhk/Id14443Mmzcvn6DMzCbgsL+KaSLy7L2/5JJLeOSRR1i+fDnlcpmuri7mz5/PAw88wEMPPcTrXvc6NmzYQH9/P+9973tZuXIlMDxtyO7duznnnHM488wzuf3221m8eDFf/epX6e7uzjFqM7MZliD+/N/u5b6f7dyvfO9ghVKhQEdp8g2qE485gste+4Ixt19xxRWsXbuWNWvWcNttt3Heeeexdu3axuWoq1at4sgjj2Tfvn285CUv4Q1veAMLFiwY8RoPP/ww1157LZ/4xCd405vexPXXX8/FF1886VjNzCZjRiWI6eC0004bca/Chz/8YW644QYANmzYwMMPP7xfgli2bBnLly8H4MUvfjHr16+fsnjNbOaaUQlirE/69/1sJ3O7Syye35N7DLNmzWos33bbbdx6661897vfpaenh7POOqvlvQydnZ2N5WKxyL59+3KP08zMg9RJTmPUzJkzh127drXctmPHDubPn09PTw8PPPAAd9xxR05RmJlNXm4tCEmrgNcAmyPipBbb3we8pSmOE4BFEbFN0npgF1AFKhHRm1ecWSz5vfaCBQs444wzOOmkk+ju7uaoo45qbFuxYgVXXXUVJ5xwAs973vM4/fTT8wvEzGySFDld3ynp5cBu4DOtEsSofV8L/GFEvDKtrwd6I+KJyZyzt7c3Rj8w6P777+eEE04Y97j7H9vJnM4SS47Mv4spTxP5Wc3Mmkm6e6wP4bl1MUXEt4FtE9z9zcC1ecVyICK/LiYzs6erto9BSOoBVgDXNxUH8DVJd0taeYDjV0rqk9S3ZcuWPEM1M5tR2p4ggNcC/z8imlsbZ0bEi4BzgHel7qqWIuLqiOiNiN5Fi1o+d5sDdqPp6d+CyKur0MxmrumQIC5iVPdSRGxK3zcDNwCnHeyLd3V1sXXr1nHfQPU0zxD150F0dXW1OxQzO4y09T4ISXOBVwAXN5XNAgoRsSstnw1cfrDnWLJkCRs3bmS87qfHd/ZTLhbYs7njYE/TdvUnypmZHSp5XuZ6LXAWsFDSRuAyoAwQEVel3X4N+FpE7Gk69CjghvR8gxLw+Yj4j4ONo1wuH/Apa7//99/iuUfN5mNvOeVgT2NmdtjJLUFExJsnsM81wDWjyh4FpvSduihRq03lGc3Mpr/pMAbRdhLUPMhrZjaCEwRQkKg5P5iZjeAEARQKbkGYmY3mBEEag3CCMDMbwQkCkLuYzMz24wQBFOQ7kc3MRnOCIBukrroJYWY2ghMEUCh4DMLMbDQnCLIuJjcgzMxGcoIg62LyGISZ2UhOEHgMwsysFScI6mMQ7Y7CzGx6cYLAl7mambXiBIHnYjIza8UJgqwF4TEIM7ORnCCotyCcIMzMmjlBUL/Mtd1RmJlNL04QeLpvM7NWcksQklZJ2ixp7Rjbz5K0Q9Ka9PXBpm0rJD0oaZ2kS/KKsel8VJ0gzMxGyLMFcQ2w4gD7fCcilqevywEkFYErgXOAE4E3SzoxxzgpuovJzGw/uSWIiPg2sO0gDj0NWBcRj0bEIHAdcMEhDW6Ugp9JbWa2n3aPQbxU0g8l3STpBalsMbChaZ+NqawlSSsl9Unq27Jly0EF4auYzMz2184E8X3guIg4BfgI8K8H8yIRcXVE9EZE76JFiw4qEEnUagd1qJnZYattCSIidkbE7rR8I1CWtBDYBBzbtOuSVJaboq9iMjPbT9sShKRfkKS0fFqKZStwF3C8pGWSOoCLgNV5xuIuJjOz/ZXyemFJ1wJnAQslbQQuA8oAEXEV8Ebg9yRVgH3ARZHNmFeR9G7gZqAIrIqIe/OKM8VK1V1MZmYj5JYgIuLNB9j+UeCjY2y7Ebgxj7ha8WyuZmb7a/dVTNNC0c+kNjPbjxMEnu7bzKwVJwhAgpozhJnZCE4QZFNtuIvJzGwkJwj8TGozs1acIEhdTG5BmJmN4ASBb5QzM2vFCYL6GES7ozAzm16cIPB032ZmrThBkE21EeG7qc3MmjlBkI1BAO5mMjNr4gRBNt03uJvJzKyZEwRZFxM4QZiZNXOCYLiLyfnBzGyYEwTZVUwAVQ9CmJk1OEGQTfcN7mIyM2vmBEHzGESbAzEzm0acIBjuYvJ9EGZmw3JLEJJWSdosae0Y298i6R5JP5J0u6RTmratT+VrJPXlFWNdfZDaYxBmZsPybEFcA6wYZ/uPgVdExAuBvwCuHrX9lyNieUT05hRfQ6HgLiYzs9FKeb1wRHxb0tJxtt/etHoHsCSvWA7EXUxmZvubLmMQ7wRualoP4GuS7pa0crwDJa2U1Cepb8uWLQd1ck+1YWa2v9xaEBMl6ZfJEsSZTcVnRsQmSc8AbpH0QER8u9XxEXE1qXuqt7f3oN7iG/dBuAVhZtbQ1haEpJOBTwIXRMTWenlEbErfNwM3AKflGUejBeEmhJlZQ9sShKRnAl8B3hoRDzWVz5I0p74MnA20vBLqUPFUG2Zm+8uti0nStcBZwEJJG4HLgDJARFwFfBBYAHws3ahWSVcsHQXckMpKwOcj4j/yihOgkNKku5jMzIbleRXTmw+w/beA32pR/ihwyv5H5Kfg2VzNzPYzXa5iaqvhLiYnCDOzOicIfJmrmVkrThB4um8zs1acIPAT5czMWnGCYPh5EM4PZmbDnCAY7mJyC8LMbJgTBJ7u28ysFScIPN23mVkrThB4um8zs1acIPB9EGZmrThBAPJ9EGZm+3GCAIqeasPMbD9OEHiQ2sysFScIfB+EmVkrThAMT7Xh50GYmQ1zgsBjEGZmrThB0HwndZsDMTObRpwgGJ6sr1pzhjAzq8s1QUhaJWmzpLVjbJekD0taJ+keSS9q2vY2SQ+nr7flGWdHKUsQQ1V3MZmZ1eXdgrgGWDHO9nOA49PXSuCfASQdCVwG/CJwGnCZpPl5BVkqZNUw5D4mM7OGXBNERHwb2DbOLhcAn4nMHcA8SUcDvwrcEhHbIuJJ4BbGTzRPSamYtSAqbkGYmTW0ewxiMbChaX1jKhurfD+SVkrqk9S3ZcuWgwqiXEwtCI9BmJk1tDtBPGURcXVE9EZE76JFiw7qNeoJwi0IM7NhE0oQkt4r6Yg0qPwpSd+XdPYhOP8m4Nim9SWpbKzyXNS7mDwGYWY2bKItiP8WETuBs4H5wFuBKw7B+VcDv5kSz+nAjoh4DLgZOFvS/DQ4fXYqy0W5MUjtFoSZWV1pgvul2Yo4F/hsRNyr+vwU4x0kXQucBSyUtJHsyqQyQERcBdyYXnMdsBd4R9q2TdJfAHell7o8IsYb7H5Khgep3YIwM6ubaIK4W9LXgGXApZLmAAd8N42INx9gewDvGmPbKmDVBON7SkoFdzGZmY020QTxTmA58GhE7E33Kbwjv7CmliTKRTHk+b7NzBomOgbxUuDBiNgu6WLgA8CO/MKaeqVCwV1MZmZNJpog/hnYK+kU4I+BR4DP5BZVG5SL8iC1mVmTiSaIShovuAD4aERcCczJL6ypVy4WPAZhZtZkomMQuyRdSnZ56y9JKpCuRjpclIryjXJmZk0m2oK4EBggux/i52Q3rv1dblG1QalQ8FQbZmZNJpQgUlL4HDBX0muA/og4rMYgOkoFj0GYmTWZ6FQbbwK+B/w68CbgTklvzDOwqVYqyFcxmZk1megYxPuBl0TEZgBJi4BbgS/nFdhUKxXdgjAzazbRMYhCPTkkWydx7NNCR1FUPAZhZtYw0RbEf0i6Gbg2rV9INo/SYaPky1zNzEaYUIKIiPdJegNwRiq6OiJuyC+sqVcq+EY5M7NmE21BEBHXA9fnGEtblYsF9g5W2h2Gmdm0MW6CkLQLaPWxWmSTsR6RS1Rt4Kk2zMxGGjdBRMRhNZ3GeDwGYWY20mF1JdJTUS6Kiqf7NjNrcIJIykVP921m1swJIikVfKOcmVmzXBOEpBWSHpS0TtIlLbb/g6Q16eshSdubtlWbtq3OM06oD1K7BWFmVjfhy1wnS1IRuBJ4NbARuEvS6oi4r75PRPxh0/6/D5za9BL7ImJ5XvGNVvIYhJnZCHm2IE4D1kXEoxExCFxH9sChsbyZ4Tu1p1y5WGCo4haEmVldngliMbChaX1jKtuPpOOAZcA3moq7JPVJukPS68Y6iaSVab++LVu2HHSw5aKfB2Fm1my6DFJfBHw5IqpNZcdFRC/wG8A/Snp2qwMj4uqI6I2I3kWLFh10ANl03+5iMjOryzNBbAKObVpfkspauYhR3UsRsSl9fxS4jZHjE4dcuVigUguyR2+bmVmeCeIu4HhJyyR1kCWB/a5GkvR8YD7w3aay+ZI60/JCskkC7xt97KFULgrAl7qamSW5XcUUERVJ7wZuBorAqoi4V9LlQF9E1JPFRcB1MfKj+wnAxyXVyJLYFc1XP+WhVMxyZaVWo2Pa9LyZmbVPbgkCICJuZNRzIyLig6PWP9TiuNuBF+YZ22jllCCGKgEdU3lmM7PpyR+Vk45SVhWDvlnOzAxwgmjoTAlioFI9wJ5mZjODE0QynCDcgjAzAyeIhs5SEYCBIScIMzNwgmjoLLuLycysmRNE4i4mM7ORnCCSRheTE4SZGeAE0dBoQQy5i8nMDJwgGrrSGES/WxBmZoATRMPwVUxuQZiZgRNEgwepzcxGcoJIPEhtZjaSE0Ti+yDMzEZygkg6ivWrmNyCMDMDJ4iGQkF0FAvuYjIzS5wgmnSWCu5iMjNLnCCadJbdgjAzq3OCaNJZKnoMwswsyTVBSFoh6UFJ6yRd0mL72yVtkbQmff1W07a3SXo4fb0tzzjr3MVkZjYst2dSSyoCVwKvBjYCd0laHRH3jdr1CxHx7lHHHglcBvQCAdydjn0yr3ghe+you5jMzDJ5tiBOA9ZFxKMRMQhcB1wwwWN/FbglIralpHALsCKnOBs6y0UnCDOzJM8EsRjY0LS+MZWN9gZJ90j6sqRjJ3ksklZK6pPUt2XLlqcUcGep4LmYzMySdg9S/xuwNCJOJmslfHqyLxARV0dEb0T0Llq06CkF0+kuJjOzhjwTxCbg2Kb1JamsISK2RsRAWv0k8OKJHpuHzpK7mMzM6vJMEHcBx0taJqkDuAhY3byDpKObVs8H7k/LNwNnS5ovaT5wdirL1ezOIrv6h/I+jZnZ00JuVzFFREXSu8ne2IvAqoi4V9LlQF9ErAbeI+l8oAJsA96ejt0m6S/IkgzA5RGxLa9Y6xbM7mTbnsG8T2Nm9rSQW4IAiIgbgRtHlX2waflS4NIxjl0FrMozvtEWzO5g72CVvYMVejpyrRozs2mv3YPU08rCWZ0AbN3tVoSZmRNEkwWzOwDY6m4mMzMniGYLZtdbEAMH2NPM7PDnBNFkYb0F4S4mMzMniGYL0hjEE3vcgjAzc4Jo0t1RZFZH0S0IMzOcIPazYHYnT3gMwszMCWK0BbM73IIwM8MJYj8LZrkFYWYGThD7WTi7w/dBmJnhBLGfBbM72LZnkFot2h2KmVlbOUGMsmBWJ9VasGOfZ3U1s5nNCWKU4ek2PA5hZjObE8QoC9N0G0/4SiYzm+GcIEaptyB8JZOZzXROEKMc2ZMliCf3egzCzGY2J4hR5vaUAdix111MZjazOUGM0lkq0tNRdAvCzGa8XBOEpBWSHpS0TtIlLbb/kaT7JN0j6euSjmvaVpW0Jn2tzjPO0eb3dPCkWxBmNsPl9uBlSUXgSuDVwEbgLkmrI+K+pt1+APRGxF5Jvwf8LXBh2rYvIpbnFd945naX2e4WhJnNcHm2IE4D1kXEoxExCFwHXNC8Q0R8MyL2ptU7gCU5xjNh82eV2e4WhJnNcHkmiMXAhqb1jalsLO8Ebmpa75LUJ+kOSa8b6yBJK9N+fVu2bHlqESfzejrcgjCzGS+3LqbJkHQx0Au8oqn4uIjYJOlZwDck/SgiHhl9bERcDVwN0Nvbe0gmUJrXXfYYhJnNeHm2IDYBxzatL0llI0h6FfB+4PyIaNydFhGb0vdHgduAU3OMdYT5PR3s2DfkCfvMbEbLM0HcBRwvaZmkDuAiYMTVSJJOBT5Olhw2N5XPl9SZlhcCZwDNg9u5mtdTphawq78yVac0M5t2cksQEVEB3g3cDNwPfDEi7pV0uaTz025/B8wGvjTqctYTgD5JPwS+CVwx6uqnXB0zrxuAhzbvmqpTmplNO7mOQUTEjcCNo8o+2LT8qjGOux14YZ6xjefM4xdSLoqv3ftzXrL0yHaFYWbWVr6TuoUjusqc8ZyFfP7On3LLfY+3Oxwzs7ZwghjD5eefxJGzO/jkdx5tdyhmZm3hBDGGZy7o4Zef9wzWbtrhq5nMbEZyghjHCxfPZc9glUef2NPuUMzMppwTxDhOXjIPgNd85DueesPMZhwniHE896jZnH/KMfQP1ehb/2S7wzEzm1JOEOOQxF+//oVIcO/PdrY7HDOzKeUEcQCzOkssWziLe3+2o92hmJlNKSeICXjBMXP54cbtVKq1dodiZjZlnCAm4LUnH83jOwf4lzt+0u5QzMymjBPEBLz6xKM4/VlH8rHbHmGw4laEmc0MThATIInffcWz2bxrgOd+4CYe3bK73SGZmeXOCWKCXvHcRfz2Ly0D4Jrb17c3GDOzKTAtnij3dCCJ9593Ilv3DHLd9zbQP1Tl4tOPa9xMZ2Z2uHELYpI+cN6JvObko7npRz/n9R+7nW8/dGieg21mNt0o4vCZiK63tzf6+vqm5Fzb9w5y4cfv4MHHd/H8X5jDGc9ZyAXLj3GLwsyeViTdHRG9Lbc5QRy8x3bs4/N3/pTbH9nK2k07GKjUePvLlnL2C46iq1zk1GPnIWnK4jEzmywniCmwq3+Iv7rxAb5w10+pzw7+nGfMZumCWfR0FDl6XhenLJnHsxfNpqNUYNnCWQBEhJOImbVN2xKEpBXAPwFF4JMRccWo7Z3AZ4AXA1uBCyNifdp2KfBOoAq8JyJuPtD52pkg6jbv7Gfd5t08smU3X7vvcZ7YPci+wQqbtu9jqDpc1x3FAj2dRfYOVjn12HksmN1BpRoUJI7oLrF4Xg8DlSoDlRqzO0t0lAqUi6IgMa+ng3pKKRZEEMztLtM/VGP3QIWOYoFysUBB2eC6BAUprWdlBQkxXE5jn2x/gFZ/GgXBEd1l9g5W2TtYIYIsFoHIjhXD582Wsx0KjXM37du0XGjEmu3fKEuvUUiB1SKo1IKejiL9QzU6SwUGKjUElIqiWBB7B6uUCqKzVKRUFOVCgWJR7B2oUC4W2D1QoVgQpYIojP6u7PtgtUb/UI3+oSrd5SIdpQKValCp1bKfL9UfKWZJ1CLYN1ilWBA9HdnvtxZBd7lILaBaCwTM6SpRqQWD1RpD6d6acqlAuZD9nosFMVCpsXewypyuEkPpLv5SoUClli3X662uXpc06jyVH+Bv9kAfUAQUCiP3iQjGekxK8/4RwVA1GvH3dBSp1oIA9g5WGz+rRv2+63VTLma/w2b7Up0WC9mxRWm/+OrnjoBg+PcD2e9gqFqjq1xs7FepBaWCxq2L+s9cLIhaLVqeMw/VWvaz1r8fauMliNyuYpJUBK4EXg1sBO6StDoi7mva7Z3AkxHxHEkXAX8DXCjpROAi4AXAMcCtkp4bEdW84j1UnnFEF884oouXPWchb33p0kb5jn1D/HTrXu7/+U527hvi5zv62TNYpbNU4Ac/fZKHH99NsSAqteDJPYNs3TNIsSA6igX6K9WWb9ZmU6W7XCQIysUCg5UaAwe4YVSCorK/59HlEcPfD6Sg7NxDtaBSrTG3u8yTe4da7tucMEpF0T9UpRbZB4qCxOzOErUIdvVXAOgqFyhoeL9ZHUWqEQxUasMfnMiScndHkYGhKntS8q9FML+ng1J6466k+CppefQH79GJRyO2jaq7pq31D0MdxUIjYXaVitQiGnUCsHB2J997/6sOXKGTlOdlrqcB6yLiUQBJ1wEXAM0J4gLgQ2n5y8BHldXkBcB1ETEA/FjSuvR6380x3lzN7S7zwiVzeeGSuRPaf6BSpaNYQBKDlRpD1VrjU/LO/uw/iBCVWo0Atu0ZZHZnidmd2afNoWoQBLVa9kcG2fdaDH8Sisg+ydVqaT3t32z0H2+lFuzcN8SsziLd5RIFZZ/QIh2f/jXWo7Eew9+DEedv/qRXa2zPYq4vN28vpTeCXf0VustFBqtZK6IeX6UajU+qA5UalVpWH5VqjZ6OIgOVGkd0lxufHGvpP3W1/hVBtRoUi6K7XKSrnL05DFRqlIoFSoXhlkxzrPU3ou507r3pA0CpWGDfYIViodB4Q9nVX6Fcyj4A1F+vUotGnEPVGsVCgSO6S+zur9BRKjTiKqeftf4eVK/nuuY3pwO9CU/kc0e1FuweqDQ+2XeWC3QWCxQLhf3+Pur1UK/LcrHQaP1G0Gi51WrBEd3lRr2P/hsoFURHqcDugSp7ByoUi1mrbsuuAY6e2539fmP4d1er/95qUE2/7+6OIoXUKqknhoLE3O4yHaVC4xkvnaWsdbhtzyAdpQJdpULW2oto/Mz1VuH8ng4GKtnytj2DVGtBqShKhULWIi0Ot0LH+h0EY/9+Rv8+BHSUCuwbrGZJqlJrxFJvGUvQ05HPW3meCWIxsKFpfSPwi2PtExEVSTuABan8jlHHLm51EkkrgZUAz3zmMw9J4NNBc7O6o5T9J5vVma3Pn9Wx3/7PXjRVkZnZTPG0vw8iIq6OiN6I6F20yO+SZmaHSp4JYhNwbNP6klTWch9JJWAu2WD1RI41M7Mc5Zkg7gKOl7RMUgfZoPPqUfusBt6Wlt8IfCOyDtTVwEWSOiUtA44HvpdjrGZmNkpuYxBpTOHdwM1kl7muioh7JV0O9EXEauBTwGfTIPQ2siRC2u+LZAPaFeBdT4crmMzMDie+Uc7MbAYb7z6Ip/0gtZmZ5cMJwszMWnKCMDOzlg6rMQhJW4CfHOThC4EnDmE4h4rjmhzHNTnTNS6YvrEdbnEdFxEtbyI7rBLEUyGpb6yBmnZyXJPjuCZnusYF0ze2mRSXu5jMzKwlJwgzM2vJCWLY1e0OYAyOa3Ic1+RM17hg+sY2Y+LyGISZmbXkFoSZmbXkBGFmZi3N+AQhaYWkByWtk3RJm2NZL+lHktZI6ktlR0q6RdLD6fv8KYpllaTNktY2lbWMRZkPpzq8R9KLpjiuD0nalOptjaRzm7ZdmuJ6UNKv5hjXsZK+Kek+SfdKem8qb2udjRNXW+tMUpek70n6YYrrz1P5Mkl3pvN/Ic0ETZrZ+Qup/E5JS6c4rmsk/bipvpan8in720/nK0r6gaR/T+v51lf2qL+Z+UU2y+wjwLOADuCHwIltjGc9sHBU2d8Cl6TlS4C/maJYXg68CFh7oFiAc4GbyJ6QeDpw5xTH9SHgT1rse2L6nXYCy9LvuphTXEcDL0rLc4CH0vnbWmfjxNXWOks/9+y0XAbuTNX8KkcAAAT9SURBVPXwReCiVH4V8Htp+b8DV6Xli4Av5FRfY8V1DfDGFvtP2d9+Ot8fAZ8H/j2t51pfM70F0XhudkQMAvXnZk8nFwCfTsufBl43FSeNiG+TTcE+kVguAD4TmTuAeZKOnsK4xtJ4tnlE/BioP9s8j7gei4jvp+VdwP1kj8lta52NE9dYpqTO0s+9O62W01cAryR7Pj3sX1/1evwy8CtSqydi5xbXWKbsb1/SEuA84JNpXeRcXzM9QbR6bvZ4/3nyFsDXJN2t7FnbAEdFxGNp+efAUe0JbdxYpkM9vjs18Vc1dcO1Ja7UnD+V7NPntKmzUXFBm+ssdZesATYDt5C1VrZHRKXFuUc8vx6oP78+97giol5ff5nq6x8kdY6Oq0XMh9o/Av8DqKX1BeRcXzM9QUw3Z0bEi4BzgHdJennzxsjai9PiuuTpFAvwz8CzgeXAY8D/aVcgkmYD1wN/EBE7m7e1s85axNX2OouIakQsJ3uk8GnA86c6hlZGxyXpJOBSsvheAhwJ/OlUxiTpNcDmiLh7Ks870xPEtHr2dURsSt83AzeQ/ad5vN5kTd83tyu+cWJpaz1GxOPpP3UN+ATDXSJTGpekMtmb8Oci4iupuO111iqu6VJnKZbtwDeBl5J10dSfdNl87rGeXz8Vca1IXXUREQPA/2Xq6+sM4HxJ68m6wl8J/BM519dMTxATeW72lJA0S9Kc+jJwNrCWkc/tfhvw1XbEl4wVy2rgN9MVHacDO5q6VXI3qs/318jqrR7XlDzbPPXvfgq4PyL+vmlTW+tsrLjaXWeSFkmal5a7gVeTjY98k+z59LB/fbV6fv1UxPVAU5IXWT9/c33l/nuMiEsjYklELCV7n/pGRLyFvOvrUI6wPx2/yK5CeIis//P9bYzjWWRXj/wQuLceC1m/4deBh4FbgSOnKJ5ryboehsj6Nt85VixkV3BcmerwR0DvFMf12XTee9J/jKOb9n9/iutB4Jwc4zqTrPvoHmBN+jq33XU2TlxtrTPgZOAH6fxrgQ82/T/4Htng+JeAzlTeldbXpe3PmuK4vpHqay3wLwxf6TRlf/tNMZ7F8FVMudaXp9owM7OWZnoXk5mZjcEJwszMWnKCMDOzlpwgzMysJScIMzNryQnCbBqQdFZ9hk6z6cIJwszMWnKCMJsESRen5wWskfTxNLHb7jSB272Svi5pUdp3uaQ70gRvN2j4WRDPkXSrsmcOfF/Ss9PLz5b0ZUkPSPpcHrOVmk2GE4TZBEk6AbgQOCOyydyqwFuAWUBfRLwA+BZwWTrkM8CfRsTJZHfZ1ss/B1wZEacALyO7MxyymVb/gOyZDM8im3/HrG1KB97FzJJfAV4M3JU+3HeTTb5XA76Q9vkX4CuS5gLzIuJbqfzTwJfSfFuLI+IGgIjoB0iv972I2JjW1wBLgf/M/8cya80JwmziBHw6Ii4dUSj92aj9Dnb+moGm5Sr+/2lt5i4ms4n7OvBGSc+AxvOmjyP7f1SfUfM3gP+MiB3Ak5J+KZW/FfhWZE912yjpdek1OiX1TOlPYTZB/oRiNkERcZ+kD5A99a9ANqPsu4A9ZA+W+QBZl9OF6ZC3AVelBPAo8I5U/lbg45IuT6/x61P4Y5hNmGdzNXuKJO2OiNntjsPsUHMXk5mZteQWhJmZteQWhJmZteQEYWZmLTlBmJlZS04QZmbWkhOEmZm19F8QiO/cqPV05QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "import math\n",
    "# from sklearn.metrics import max_error\n",
    "\n",
    "pred_c = model1.predict((X_new1))\n",
    "print(pred_c.shape)\n",
    "\n",
    "mse = (mean_squared_error(Y_rob_train_c,pred_c))\n",
    "\n",
    "print(mse)\n",
    "visualize_learning_curve(history_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "gXSgtNLckt4p",
    "outputId": "5a8d75e1-039a-4ec9-969d-35b75b4b4d4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.92 42.137985\n",
      "0.30369932072710615 stabilization time\n"
     ]
    }
   ],
   "source": [
    "Final = []\n",
    "# print(y_train_c)\n",
    "for i in range(len(y_train_c)):\n",
    "  \n",
    "#     print(y_train_c[i],\"ytest[i]\")\n",
    "#     print(X_train_c[i])\n",
    "    \n",
    "    X_c = (scaler_rob_x.transform(X_train_c[i].reshape(1, -1)))\n",
    "    k = []\n",
    "\n",
    "#     print(X_c)\n",
    "    I = factor_fit.transform(X_c[:,0:10000])\n",
    "    I = np.concatenate((I,X_c[:,10000:10002]),axis=1)\n",
    "#   print(I.shape,\"I shape\")\n",
    "\n",
    "    pred_c = model1.predict(I)\n",
    "#     print(pred_c,\"pred_c.shape\")\n",
    "  \n",
    " \n",
    "\n",
    "  \n",
    "    final = scaler_rob_y.inverse_transform(pred_c.reshape(1, -1))\n",
    "#     print(final,\"final\")                               \n",
    "    final[0][0]= np.abs(np.round(final[0][0]))\n",
    "                                          \n",
    "#     print(final[0],\"final\")\n",
    "    k.append(final[0][0])\n",
    "    k.append(final[0][1])\n",
    "    Final.append(k)\n",
    "\n",
    "    h = abs(final[0]-y_train_c[i])\n",
    "Final_np = np.asarray(Final, dtype=np.float32)    \n",
    "# print(Final)\n",
    "print(y_train_c[100,1], Final_np[100,1])\n",
    "r2_time = r2_score(y_train_c[:,1], Final_np[:,1]) \n",
    "print(r2_time,\"stabilization time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "mc1vcYm9k37j",
    "outputId": "7e978f24-b2ff-416d-98b6-d6f3120736d3"
   },
   "outputs": [],
   "source": [
    "\n",
    "from keras.backend import manual_variable_initialization \n",
    "manual_variable_initialization(True)\n",
    "model.save (\"./app/MODEL/my_model_ON.h5\")\n",
    "model1.save (\"./app/MODEL/my_model_1_ON.h5\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(model.get_weights())\n",
    "\n",
    "# print (model1.get_weights())\n",
    "model1.save_weights(\"on_1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jBGZMwMHlLXw"
   },
   "outputs": [],
   "source": [
    "# from keras.models import load_model\n",
    "# new_model = load_model('my_model_ON.h5')\n",
    "# new_model_1 = load_model('my_model_1_ON.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uqP6qSVglPrH"
   },
   "outputs": [],
   "source": [
    "# pred = new_model_1.predict((X_new1))\n",
    "# print(pred.shape)\n",
    "\n",
    "# mse = (mean_squared_error(Y_rob_train,pred))\n",
    "\n",
    "# print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MPxe7WHNlSVb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g05oiTETLRCg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "perpec_ON.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
